{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b3139d-1ac0-4486-80f0-e54d08259ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipywidgets import IntSlider\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "id": "ee726465-0b88-46f7-877f-5aee84616ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import shap\n",
    "import numpy as np\n",
    "import ZCA as zca\n",
    "import statsmodels.api as sm\n",
    "import matplotlib as plt\n",
    "\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import IPython\n",
    "\n",
    "import os\n",
    "os.environ['R_HOME'] = '/mnt/distvol/R/4.0.5/lib64/R/'\n",
    "import rpy2.robjects as R\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import arange\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import shap\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import seaborn as sns\n",
    "from ModelDiagnostics import Plot\n",
    "from sklearn.cluster import DBSCAN\n",
    "from clustergram import Clustergram\n",
    "import urbangrammar_graphics as ugg\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy import stats\n",
    "from scipy.special import boxcox, inv_boxcox\n",
    "from scipy.stats import f\n",
    "\n",
    "import dtale\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1657,
   "id": "78bf8827-4f34-413b-9a4d-bd6565e33372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "def testNormal (x):    \n",
    "    \n",
    "    k2, p = stats.normaltest(x)\n",
    "    alpha = .001\n",
    "    #print(\"p = {:g}\".format(p))    \n",
    "    if p < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "        #print(p)\n",
    "        #print(alpha)\n",
    "        print(\"The null hypothesis can be rejected\")\n",
    "        xt, _ = stats.yeojohnson(x)\n",
    "        #xt, _ = stats.boxcox(x)        \n",
    "        print(_)\n",
    "        xt = pd.DataFrame(xt)\n",
    "        \n",
    "        return _, pd.DataFrame(xt).set_index(x.index)\n",
    "    else:\n",
    "        print(\"The null hypothesis cannot be rejected\")    \n",
    "        return 1, pd.DataFrame(x)\n",
    "\n",
    "def inverse_boxcox (data, lambdas):\n",
    "    power = PowerTransformer(method='yeo-johnson')\n",
    "    power.lambdas_ = lambdas.values\n",
    "    return(power.inverse_transform([data]))\n",
    "    #return inv_boxcox(data, lambdas.values)\n",
    "    \n",
    "def transform_boxcox_l(data, l_):\n",
    "    transformed = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data.columns)):\n",
    "        #print(i)\n",
    "        if l_.iloc[i].values == 1:\n",
    "            inner_scale = data.iloc[:,i]            \n",
    "        else:\n",
    "            inner_scale = pd.DataFrame(stats.yeojohnson((data.iloc[:,i]), lmbda=l_.iloc[i].values))\n",
    "            \n",
    "        inner_scale.index = data.index\n",
    "        transformed = pd.concat([transformed,inner_scale],axis=1)\n",
    "        \n",
    "    transformed.columns = data.columns\n",
    "    return transformed\n",
    "\n",
    "def transform_boxcox (data):\n",
    "    transformed = pd.DataFrame()\n",
    "    transformed_lambdas = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data.columns)):\n",
    "        l, inner_scale = testNormal(data.iloc[:,i])\n",
    "        inner_scale.set_index(data.index)\n",
    "\n",
    "        transformed_lambdas = pd.concat([transformed_lambdas,pd.DataFrame(pd.Series(l))],axis=0)\n",
    "        transformed = pd.concat([transformed,inner_scale],axis=1)\n",
    "        \n",
    "    transformed.columns = data.columns\n",
    "    return transformed, transformed_lambdas\n",
    "\n",
    "def inverse_yeo(og, data_, lambda_):\n",
    "    values = []\n",
    "    for i in range(0,len(og)):\n",
    "        X = og[i]\n",
    "        X_trans = data_[i]\n",
    "        if X >= 0 and lambda_ == 0:\n",
    "            X = exp(X_trans) - 1\n",
    "        elif X >= 0 and lambda_ != 0:\n",
    "            X = (X_trans * lambda_ + 1) ** (1 / lambda_) - 1\n",
    "        elif X < 0 and lambda_ != 2:\n",
    "            X = 1 - (-(2 - lambda_) * X_trans + 1) ** (1 / (2 - lambda_))\n",
    "        elif X < 0 and lambda_ == 2:\n",
    "            X = 1 - exp(-X_trans)\n",
    "        \n",
    "        values.append(X)\n",
    "    return(pd.DataFrame(values))\n",
    "\n",
    "\n",
    "def revert_yeo (og, data_, lambdas):\n",
    "    reverted = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data_.columns)):        \n",
    "        if lambdas.iloc[i].values == 1 :\n",
    "            revert = data_.iloc[:,i]\n",
    "        else:\n",
    "            p#ower = PowerTransformer(method='yeo-johnson')\n",
    "            #power.lambdas_ = lambdas.iloc[i].values\n",
    "            #revert = pd.DataFrame(power.inverse_transform([data.iloc[:,i].values]))\n",
    "            #return inv_boxcox(data, lambdas.values)\n",
    "            revert = pd.DataFrame(inverse_yeo(og.iloc[:,i].values,data_.iloc[:,i].values, lambdas.iloc[i].values))            \n",
    "        revert.index = data_.index\n",
    "        reverted = pd.concat([reverted,revert],axis=1)\n",
    "        \n",
    "    reverted.columns = data_.columns\n",
    "    return reverted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1532,
   "id": "2ec9d431-186e-4171-8a8a-378ab2ab2e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_deltas(data):\n",
    "\n",
    "    R.r('''\n",
    "               f <- function(values) {\n",
    "                        #system(\"which openssl\")\n",
    "\n",
    "                        library(snpEnrichment)\n",
    "                        library(arfima)\n",
    "                        library(parallel)\n",
    "                        library(forecast)                    \n",
    "\n",
    "                        dset <- lapply(1:ncol(values),function(x)\n",
    "                        {\n",
    "                            column = values[,x]\n",
    "\n",
    "\n",
    "                            #tryCatch(invisible(capture.output(suppressMessages(suppressWarnings(\n",
    "                            #{\n",
    "                              varvefd = arfima(column)\n",
    "                              d = summary(varvefd)$coef[[1]][1]\n",
    "                              \n",
    "                              r = residuals(varvefd, reg = TRUE)\n",
    "                              #print(r)\n",
    "                              return(d)\n",
    "                            #}\n",
    "                           #)\n",
    "                           #))),\n",
    "                            #error=function(e)\n",
    "                              #{\n",
    "                                #d = 1\n",
    "                                #return(d)\n",
    "                              #})\n",
    "\n",
    "                        })    \n",
    "\n",
    "                        unlist(dset)\n",
    "\n",
    "                }\n",
    "                ''')\n",
    "\n",
    "    r_f = R.globalenv['f']\n",
    "    d=R.conversion.rpy2py((r_f(R.conversion.py2rpy(data.dropna()))))\n",
    "    return(d)\n",
    "\n",
    "def get_residuals(data):\n",
    "\n",
    "    R.r('''\n",
    "               f <- function(values) {\n",
    "                        #system(\"which openssl\")\n",
    "\n",
    "                        library(snpEnrichment)\n",
    "                        library(arfima)\n",
    "                        library(parallel)\n",
    "                        library(forecast)                    \n",
    "\n",
    "                        dset <- lapply(1:ncol(values),function(x)\n",
    "                        {\n",
    "                            column = values[,x]\n",
    "\n",
    "\n",
    "                            #tryCatch(invisible(capture.output(suppressMessages(suppressWarnings(\n",
    "                            #{\n",
    "                              varvefd = arfima(column)\n",
    "                              d = summary(varvefd)$coef[[1]][1]\n",
    "                              \n",
    "                              #return(d)\n",
    "                              r = residuals(varvefd, reg = TRUE)\n",
    "                              #print(r)\n",
    "                              return(r)\n",
    "                            #}\n",
    "                           #)\n",
    "                           #))),\n",
    "                            #error=function(e)\n",
    "                              #{\n",
    "                                #d = 1\n",
    "                                #return(d)\n",
    "                              #})\n",
    "\n",
    "                        })    \n",
    "\n",
    "                        unlist(dset)\n",
    "\n",
    "                }\n",
    "                ''')\n",
    "\n",
    "    r_f = R.globalenv['f']\n",
    "    d=R.conversion.rpy2py((r_f(R.conversion.py2rpy(data.dropna()))))\n",
    "    return(d)\n",
    "\n",
    "def arfima_predict(data_, ahead):\n",
    "\n",
    "    R.r('''\n",
    "               f_ <- function(values, ahead) {\n",
    "                        #system(\"which openssl\")\n",
    "                        print(nrow(values))\n",
    "\n",
    "                        library(snpEnrichment)\n",
    "                        library(arfima)\n",
    "                        library(parallel)\n",
    "                        library(forecast)                    \n",
    "\n",
    "                        dset <- lapply(1:ncol(values),function(x)\n",
    "                        {\n",
    "                            column = values[,x,drop=FALSE]\n",
    "\n",
    "\n",
    "                            #tryCatch(invisible(capture.output(suppressMessages(suppressWarnings(\n",
    "                            #{\n",
    "                              varvefd = arfima(column)\n",
    "                              d = summary(varvefd)$coef[[1]][1]\n",
    "                              \n",
    "                              #return(d)\n",
    "                              r = residuals(varvefd, reg = TRUE)\n",
    "                              #print(r)\n",
    "                              #return(r)\n",
    "                              \n",
    "                              pred <- predict(varvefd, ahead)\n",
    "                              #print(ahead)\n",
    "                              #print(pred)\n",
    "                              #print(pred)\n",
    "                              return(as.data.frame(pred)[,1,drop=TRUE])\n",
    "                            #}\n",
    "                           #)\n",
    "                           #))),\n",
    "                            #error=function(e)\n",
    "                              #{\n",
    "                                #d = 1\n",
    "                                #return(d)\n",
    "                              #})\n",
    "\n",
    "                        })    \n",
    "\n",
    "                        unlist(dset)\n",
    "\n",
    "                }\n",
    "                ''')\n",
    "\n",
    "    r_f_ = R.globalenv['f_']\n",
    "    d_=R.conversion.rpy2py((r_f_(R.conversion.py2rpy(data_),ahead)))\n",
    "    return(d_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1446,
   "id": "e43598e7-17dd-4ced-b588-e8870d3df933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "def arima_adjust(y_train, y_test, train_predicted, test_predicted):\n",
    "    \n",
    "    #arima residual adjusted\n",
    "    \n",
    "    window = 15\n",
    "    train_resid = y_train - pd.DataFrame(train_predicted).set_index(y_train.index)\n",
    "\n",
    "    model = AutoReg(train_resid.values, lags=15)\n",
    "    model_fit = model.fit()\n",
    "    coef = model_fit.params\n",
    "    # walk forward over time steps in test\n",
    "    history = train_resid[len(train_resid)-window:]\n",
    "    history = [history.loc[history.index[i]] for i in range(len(history))]\n",
    "    predictions = list()\n",
    "    for t in range(len(y_test)):\n",
    "        # persistence\n",
    "        yhat = pd.DataFrame(test_predicted).set_index(y_test.index).loc[y_test.index[t]]    \n",
    "        error = y_test.loc[y_test.index[t]] - yhat\n",
    "        # predict error\n",
    "        length = len(history)\n",
    "        lag = [history[i] for i in range(length-window,length)]\n",
    "        pred_error = coef[0]\n",
    "        for d in range(window):\n",
    "            pred_error += coef[d+1] * lag[window-d-1]\n",
    "        # correct the prediction\n",
    "        yhat = yhat + pred_error\n",
    "        #print(yhat)\n",
    "        predictions.append(np.round(yhat,0).astype(int))\n",
    "        history.append(error)\n",
    "        #print('predicted=%f, expected=%f' % ((np.round(yhat,0)), y_test.loc[y_test.index[t]]))\n",
    "\n",
    "    print(metrics.classification_report(y_test,predictions))\n",
    "    print(metrics.confusion_matrix(y_test,predictions))\n",
    "    \n",
    "    return(pd.DataFrame(predictions).set_index(y_test.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3af9904-08a5-4d5f-90f7-1b4c5d4652df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb9bb80-d23a-4a60-964b-41dad96d6411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1448,
   "id": "1235085d-f98a-4b9d-a118-29a6f154af93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom statsmodels.tsa.ar_model import AutoReg\\n\\nresiduals_train = y_train - pd.DataFrame(clf.predict(X_train)).set_index(y_train.index)\\n\\ny_adjusted = predicteds.copy()\\n\\nfor i in range(0,len(y_test)):    \\n    \\n    if i == 0:\\n        forecast_r = arfima_predict(residuals_train.values)\\n        \\n    else:\\n        residuals_test = y_test.loc[y_test.index[0:i]] - pd.DataFrame(predicteds).set_index(y_test.index).loc[y_test.index[0:i]]\\n        \\n        residuals = pd.concat([residuals_train,residuals_test],axis=0)\\n        \\n        forecast_r = arfima_predict(residuals.values)\\n        \\n    print(forecast_r)\\n    adjusted = pd.DataFrame(y_adjusted).set_index(y_test.index).loc[y_test.index[i]]\\n    #print(adjusted)\\n    \\n    \\n    \\n    #y_test.loc[0:i]-pd.DataFrame(predicteds).set_index(y_test.loc[0:i].index)\\n    #ar_s_model = AutoReg(residuals, lags=15)\\n    #model_fit = model.fit()\\n    #plt.plot(np.round(arfima_predict(residuals.values, len(y_test)),0))\\n\\n    #improved_forecast = forecast + estimated error\\n\\n    #print('Coef=%s' % (model_fit.params))\\n\""
      ]
     },
     "execution_count": 1448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#arfima residual adjusted\n",
    "def arfima_adjust(y_train, y_test, train_predicted, test_predicted):\n",
    "    \n",
    "    #train_resid = get_deltas(y_train)\n",
    "    train_resid = y_train - pd.DataFrame(train_predicted).set_index(y_train.index)\n",
    "\n",
    "    y_adjusted = predicted.copy()\n",
    "\n",
    "    forecast_r = arfima_predict(train_resid.values, len(y_test))  \n",
    "    print(len(forecast_r))\n",
    "    \n",
    "    # walk forward over time steps in test\n",
    "    #history = train_resid[len(train_resid):-1]\n",
    "    #history = [history.loc[history.index[i]] for i in range(len(history))]\n",
    "    predictions = list()\n",
    "    for t in range(len(y_test)):\n",
    "        # persistence\n",
    "        yhat = pd.DataFrame(test_predicted).set_index(y_test.index).loc[y_test.index[t]]\n",
    "        #error = y_test.loc[y_test.index[t]] - yhat\n",
    "        # predict error\n",
    "        #length = len(history)\n",
    "        #lag = [history[i] for i in range(length-window,length)]\n",
    "        #pred_error = coef[0]\n",
    "        #for d in range(window):\n",
    "            #pred_error += coef[d+1] * lag[window-d-1]\n",
    "        # correct the prediction\n",
    "        #print(yhat)\n",
    "        #print(pd.DataFrame(forecast_r).set_index(y_test.index).loc[y_test.index[t]] )\n",
    "        yhat = yhat + pd.DataFrame(forecast_r).set_index(y_test.index).loc[y_test.index[t]] \n",
    "        #print(yhat)\n",
    "        predictions.append(np.round(yhat,0).astype(int))\n",
    "        #history.append(error)\n",
    "        #print('predicted=%f, expected=%f' % ((np.round(yhat,0)), y_test.loc[y_test.index[t]]))\n",
    "\n",
    "    print(metrics.classification_report(y_test,predictions))\n",
    "    print(metrics.confusion_matrix(y_test,predictions))\n",
    "    \n",
    "    return(pd.DataFrame(predictions).set_index(y_test.index))\n",
    "\n",
    "'''\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "residuals_train = y_train - pd.DataFrame(clf.predict(X_train)).set_index(y_train.index)\n",
    "\n",
    "y_adjusted = predicteds.copy()\n",
    "\n",
    "for i in range(0,len(y_test)):    \n",
    "    \n",
    "    if i == 0:\n",
    "        forecast_r = arfima_predict(residuals_train.values)\n",
    "        \n",
    "    else:\n",
    "        residuals_test = y_test.loc[y_test.index[0:i]] - pd.DataFrame(predicteds).set_index(y_test.index).loc[y_test.index[0:i]]\n",
    "        \n",
    "        residuals = pd.concat([residuals_train,residuals_test],axis=0)\n",
    "        \n",
    "        forecast_r = arfima_predict(residuals.values)\n",
    "        \n",
    "    print(forecast_r)\n",
    "    adjusted = pd.DataFrame(y_adjusted).set_index(y_test.index).loc[y_test.index[i]]\n",
    "    #print(adjusted)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #y_test.loc[0:i]-pd.DataFrame(predicteds).set_index(y_test.loc[0:i].index)\n",
    "    #ar_s_model = AutoReg(residuals, lags=15)\n",
    "    #model_fit = model.fit()\n",
    "    #plt.plot(np.round(arfima_predict(residuals.values, len(y_test)),0))\n",
    "\n",
    "    #improved_forecast = forecast + estimated error\n",
    "\n",
    "    #print('Coef=%s' % (model_fit.params))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a133da3-b0fd-4741-a0aa-db8cc75f878d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_weights(d, num_k):\n",
    "    r\"\"\"Calculate weights ($w$) for each lag ($k$) through\n",
    "    $w_k = -w_{k-1} \\frac{d - k + 1}{k}$.\n",
    "    \n",
    "    Args:\n",
    "        d (int): differencing value.\n",
    "        num_k (int): number of lags (typically length of timeseries) to calculate w.\n",
    "    \"\"\"\n",
    "    w_k = np.array([1])\n",
    "    \n",
    "    for k in range(1, num_k):\n",
    "        w_k = np.append(w_k, -w_k[-1] * ((d - k + 1)) / k)\n",
    "        \n",
    "    w_k = w_k.reshape(-1, 1) \n",
    "    \n",
    "    return w_k\n",
    "\n",
    "def get_weights_floored(d, num_k, floor=1e-3):\n",
    "    r\"\"\"Calculate weights ($w$) for each lag ($k$) through\n",
    "    $w_k = -w_{k-1} \\frac{d - k + 1}{k}$ provided weight above a minimum value\n",
    "    (floor) for the weights to prevent computation of weights for the entire\n",
    "    time series.\n",
    "    \n",
    "    Args:\n",
    "        d (int): differencing value.\n",
    "        num_k (int): number of lags (typically length of timeseries) to calculate w.\n",
    "        floor (float): minimum value for the weights for computational efficiency.\n",
    "    \"\"\"\n",
    "    w_k = np.array([1])\n",
    "    k = 1\n",
    "    \n",
    "    while k < num_k:\n",
    "        w_k_latest = -w_k[-1] * ((d - k + 1)) / k\n",
    "        if abs(w_k_latest) <= floor:\n",
    "            break\n",
    "\n",
    "        w_k = np.append(w_k, w_k_latest)\n",
    "        \n",
    "        k += 1\n",
    "\n",
    "    w_k = w_k.reshape(-1, 1) \n",
    "    \n",
    "    return w_k\n",
    "\n",
    "def frac_diff(df, d, floor=1e-3):\n",
    "    r\"\"\"Fractionally difference time series via CPU.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe of raw time series values.\n",
    "        d (float): differencing value from 0 to 1 where > 1 has no FD.\n",
    "        floor (float): minimum value of weights, ignoring anything smaller.\n",
    "    \"\"\"\n",
    "    # Get weights window\n",
    "    weights = get_weights_floored(d=d, num_k=len(df), floor=floor)\n",
    "    weights_window_size = len(weights)\n",
    "    \n",
    "    # Reverse weights\n",
    "    weights = weights[::-1]\n",
    "    \n",
    "    # Blank fractionally differenced series to be filled\n",
    "    df_fd = []\n",
    "\n",
    "    # Slide window of time series, to calculated fractionally differenced values\n",
    "    # per window\n",
    "    for idx in range(weights_window_size, df.shape[0]):\n",
    "        # Dot product of weights and original values\n",
    "        # to get fractionally differenced values\n",
    "        date_idx = df.index[idx]\n",
    "        df_fd.append(np.dot(weights.T, df.iloc[idx - weights_window_size:idx]).item())\n",
    "    \n",
    "    # Return FD values and weights\n",
    "    df_fd = pd.DataFrame(df_fd)\n",
    "    \n",
    "    return df_fd, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e53d3-2864-4d69-a45a-ce48217e4fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "id": "d949ef06-ae96-4828-b02b-21a92a11b29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxl = 5\n",
    "train_size = .7\n",
    "t_size = 1-train_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1512,
   "id": "62e6233b-8abf-4f78-83f5-a3e7a2e26fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_data = pd.read_csv('/mnt/distvol/combined_set.csv')\n",
    "all_data.index = all_data.iloc[:,0]\n",
    "all_data = all_data.iloc[:,1:]\n",
    "\n",
    "filter_ = all_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "id": "ca4d80c7-99c2-4070-b6f4-1b19d28520f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003-06-29\n",
      "2005-04-17\n",
      "2007-02-04\n",
      "2008-11-23\n",
      "2010-09-12\n",
      "2012-07-01\n",
      "2014-04-20\n",
      "2016-02-07\n",
      "2017-11-26\n",
      "2019-09-15\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1513,
   "id": "8b2b9636-4857-4aaa-b13d-e2077e957c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose Y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0faf97c2c0d418193f2ca420d2516cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Y', options=('DGS10', 'DTB3', 'DGS3MO', 'MORTGAGE30US', 'DFII10', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f3(Y):\n",
    "    \n",
    "    #Y = x\n",
    "    #output_slider_variable.value\n",
    "    internalFilter = filter_.copy()\n",
    "    internalFilter.remove(Y)\n",
    "    all_data_ = pd.concat([all_data[Y],all_data[internalFilter]], axis=1)    \n",
    "    #print(all_data_.describe())\n",
    "    display(all_data_.describe())\n",
    "    #x_ticks = all_data_.index[np.arange(0, len(all_data.index), int(len(internalFilter)/5))]\n",
    "    x_ticks  = []\n",
    "    for index, element in enumerate(all_data_.index):\n",
    "        if index % int(np.round(len(all_data_.index)/10)) == 0:\n",
    "            x_ticks.append(element)\n",
    "    plt.plot(all_data_[Y])\n",
    "    plt.xticks(x_ticks, rotation = 45)\n",
    "    plt.show()        \n",
    "    plt.hist(all_data_[Y], bins='auto')\n",
    "    plt.show()\n",
    "    diff = pd.DataFrame((all_data_[Y].pct_change())).dropna()\n",
    "    plt.hist(diff, bins='auto')\n",
    "    plt.show()\n",
    "    return(all_data_)\n",
    "    \n",
    "out = interactive(f3, Y=filter_)\n",
    "\n",
    "#output_slider_variable.observe(f4, 'value')\n",
    "\n",
    "print(\"choose Y\")\n",
    "display(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1514,
   "id": "4ee2cc18-8baf-4f8a-bcd2-9562b62237fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 02:22:07,108 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:12,387 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:13,367 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:13,551 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:15,762 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:16,589 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:16,758 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:17,216 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:18,142 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:18,361 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:18,987 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:19,640 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:20,630 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:20,887 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:22,128 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:22,665 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(out.result, test_size=tsize, shuffle=False)\n",
    "\n",
    "d = get_deltas(train)\n",
    "#differenced = pd.DataFrame(np.transpose(d.reshape(len(out.result.columns),len(out.result))))\n",
    "#differenced = pd.DataFrame(np.transpose(d.reshape(len(out.result.columns),len(out.result))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1487,
   "id": "2d87fad8-9555-4fe1-a82f-18243715d650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "748"
      ]
     },
     "execution_count": 1487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1489,
   "id": "2ed2b0f5-1e32-4e6a-8e54-ea4dbe225df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1516,
   "id": "33e1c5c4-9718-4cbb-a820-9fd94e3fc482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import concurrent.futures\n",
    "from concurrent.futures import wait, ALL_COMPLETED\n",
    "from fracdiff import fdiff\n",
    "\n",
    "cores = int(len(os.sched_getaffinity(0)))\n",
    "\n",
    "def getDifferenced(i, data):\n",
    "    #v = d[[i]]\n",
    "    #gquant_gpu, weights = frac_diff(all_data.iloc[:, i], d=d[[i]], floor=5e-5)\n",
    "    #print(i)\n",
    "    a = np.array(data.iloc[:, i])\n",
    "    \n",
    "    return fdiff(a, n=d[i], axis=0)\n",
    "    #gquant_gpu, weights = frac_diff(all_data.iloc[:, i]), d=v, floor=5e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1517,
   "id": "2070d863-3329-4f28-8b4e-a74b5480cc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndifferenced = pd.DataFrame()\\nfor f in range(0,len(futures01)):\\n    value = pd.DataFrame(futures01[f].result())\\n    differenced = pd.concat([differenced,value],axis=1)\\n    \\ndifferenced.columns = train.columns\\ndifferenced.index = train.index\\n'"
      ]
     },
     "execution_count": 1517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "differenced = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(d)):\n",
    "    value = pd.DataFrame(getDifferenced(i, out.result))\n",
    "    #print(value)\n",
    "    differenced = pd.concat([differenced,value],axis=1)\n",
    "    \n",
    "differenced.columns = out.result.columns\n",
    "differenced.index = out.result.index    \n",
    "\n",
    "'''\n",
    "\n",
    "differenced_train = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(d)):\n",
    "    value = pd.DataFrame(getDifferenced(i, train))\n",
    "    #print(value)\n",
    "    differenced_train = pd.concat([differenced_train,value],axis=1)\n",
    "    \n",
    "differenced_train.columns = train.columns\n",
    "differenced_train.index = train.index    \n",
    "\n",
    "differenced_test = pd.DataFrame()\n",
    "for i in range(0,len(d)):\n",
    "    value = pd.DataFrame(getDifferenced(i, test))\n",
    "    differenced_test = pd.concat([differenced_test,value],axis=1)\n",
    "\n",
    "differenced_test.columns = test.columns\n",
    "differenced_test.index = test.index\n",
    "\n",
    "differenced = pd.DataFrame()\n",
    "differenced = pd.concat([differenced_train,differenced_test],axis=0)\n",
    "'''\n",
    "differenced = pd.concat([out.result.iloc[:,0],differenced.iloc[:,1:]],axis=1)\n",
    "\n",
    "#pool01 = concurrent.futures.ProcessPoolExecutor(cores)\n",
    "\n",
    "#futures01 = [pool01.submit(getDifferenced, args) for args in (range(0,len(d)))]\n",
    "\n",
    "#wait(futures01, timeout=None, return_when=ALL_COMPLETED)\n",
    "#'''\n",
    "\n",
    "'''\n",
    "differenced = pd.DataFrame()\n",
    "for f in range(0,len(futures01)):\n",
    "    value = pd.DataFrame(futures01[f].result())\n",
    "    differenced = pd.concat([differenced,value],axis=1)\n",
    "    \n",
    "differenced.columns = train.columns\n",
    "differenced.index = train.index\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc2d32f-b9a1-4196-9d43-1359b65f1c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "id": "f492f94d-cba1-455a-b1d4-157a346f6d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://slurmw01:40000'"
      ]
     },
     "execution_count": 928,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_ = dtale.show(out.result)\n",
    "d_.open_browser()\n",
    "d_._url  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "4273fdd8-d805-4928-b7dd-bda427cf51fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport concurrent.futures\\nfrom concurrent.futures import wait, ALL_COMPLETED\\nfrom fracdiff import fdiff\\n\\ncores = int(len(os.sched_getaffinity(0)))\\n\\ndef getDifferenced(i):\\n    #v = d[[i]]\\n    #gquant_gpu, weights = frac_diff(all_data.iloc[:, i], d=d[[i]], floor=5e-5)\\n    \\n    a = np.array(out.result.iloc[:, i])\\n    \\n    return fdiff(a, n=d[i], axis=0)\\n    #gquant_gpu, weights = frac_diff(all_data.iloc[:, i]), d=v, floor=5e-5)\\n\\npool01 = concurrent.futures.ProcessPoolExecutor(cores)\\n\\nfutures01 = [pool01.submit(getDifferenced, args) for args in range(0,len(d))]\\n\\nwait(futures01, timeout=None, return_when=ALL_COMPLETED)\\n'"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbfa758-3cf3-4410-bfc6-85105b37a19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0e2820-110a-4786-9035-98543c301b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for f in range(0,len(futures01)):\n",
    "        #print(f)\n",
    "        #print(len(futures01[f].result()))\n",
    "        plt.hist(Differenced_Set.iloc[:,f], bins='auto')  # arguments are passed to np.histogram\n",
    "        plt.show()\n",
    "        Differenced_Set.iloc[:,1].plot()\n",
    "        plt.show()\n",
    "        plt.hist(all_data.iloc[:,f], bins='auto')  # arguments are passed to np.histogram\n",
    "        plt.show()\n",
    "        all_data.iloc[:,1].plot()\n",
    "        plt.show()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce862ad-f7fc-4f0b-b376-c29d32d01281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b6b7d-d0c5-4077-b822-d79e626067b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "id": "3d49f670-bbdb-42a8-b9e3-e75e1b60e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = out.result.corr()\n",
    "#.abs()\n",
    "s = c.unstack()\n",
    "so = s.sort_values(kind=\"quicksort\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0016982-6857-424e-868a-da44b16ff66b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece4be0-8244-434e-b66e-9c1f39a7c2c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1534,
   "id": "4d4a92b7-e5b3-49ed-b31f-5959f90e8fca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "def critical_r(n, alpha = .05 ):\n",
    "    df = n - 2\n",
    "    critical_t = scipy.stats.t.isf(alpha / 2, df)\n",
    "    critical_r = np.sqrt( (critical.t^2) / ( (critical.t^2) + df ) )\n",
    "    return(critical_r)\n",
    "\n",
    "def xcorr(x, y, maxlags=10):\n",
    "    Nx = len(x)\n",
    "    if Nx != len(y):\n",
    "        raise ValueError('x and y must be equal length')\n",
    "\n",
    "    c = np.correlate(x, y, mode=2)\n",
    "\n",
    "    if maxlags is None:\n",
    "        maxlags = Nx - 1\n",
    "\n",
    "    if maxlags >= Nx or maxlags < 1:\n",
    "        raise ValueError('maxlags must be None or strictly positive < %d' % Nx)\n",
    "\n",
    "    c = c[Nx - 1 - maxlags:Nx + maxlags]\n",
    "\n",
    "    return c\n",
    "\n",
    "def getLagged_Set(set_, og):\n",
    "\n",
    "    train, test = train_test_split(set_, test_size=tsize, shuffle=False)\n",
    "    \n",
    "    residuals = pd.DataFrame(np.transpose(get_residuals(train).reshape(len(train.columns),len(train))))\n",
    "    #print(residuals)\n",
    "\n",
    "    residuals.columns = train.columns\n",
    "    residuals.index = train.index\n",
    "\n",
    "    #print(len(train))\n",
    "    #set_.index = all_data.index\n",
    "    \n",
    "    Lagged_Differenced_Set = pd.DataFrame()\n",
    "    Lagged_Set = pd.DataFrame()\n",
    "    lags = []\n",
    "    lagcorrs = []\n",
    "    ogcorrs = []\n",
    "\n",
    "    for f in range(1,len(train.columns)):\n",
    "        #print(f)\n",
    "        #print(len(futures01[f].result()))\n",
    "\n",
    "        data_1 = residuals.iloc[:,0]\n",
    "        data_2 = residuals.iloc[:,f]\n",
    "\n",
    "        ogc = np.array(pd.concat([data_1 - np.mean(data_1),data_2 - np.mean(data_2)],axis=1).corr())[1,0]    \n",
    "        ogcorrs.append(ogc)\n",
    "\n",
    "        #corr = xcorr(data_1 - np.mean(data_1), data_2 - np.mean(data_2),maxlags=5)\n",
    "\n",
    "        set1 = data_1 - np.mean(data_1)\n",
    "        set2 = data_2 - np.mean(data_2)\n",
    "\n",
    "        corrs_ = []\n",
    "        for i in range(0,maxl):\n",
    "            c = np.array((pd.concat([set1,set2.shift(i)],axis=1).dropna()).corr())[0,1]\n",
    "            corrs_.append(c)\n",
    "\n",
    "        #corr = np.correlate(data_1 - np.mean(data_1), data_2 - np.mean(data_2),mode='full')\n",
    "        #plt.plot(corr)\n",
    "        #plt.show()\n",
    "\n",
    "        #lag = corr.argmax() - (len(data_1) - 1)\n",
    "        lag = abs(pd.Series(corrs_)).idxmax()\n",
    "\n",
    "        #print(corr)\n",
    "        lagc = np.array(pd.concat([data_1 - np.mean(data_1),(data_2 - np.mean(data_2)).shift(lag)],axis=1).corr())[1,0]\n",
    "\n",
    "        #print(lag)\n",
    "\n",
    "        #print(ogc)\n",
    "        #print(lagc)\n",
    "\n",
    "        #print(lag)\n",
    "        #plt.plot(data_1, 'r*')\n",
    "        #plt.plot(data_2, 'b*')\n",
    "\n",
    "        lag_merged = pd.concat([data_1 - np.mean(data_1),(data_2 - np.mean(data_2)).shift(lag)],axis=1)\n",
    "\n",
    "        #x_ticks = all_data.index[np.arange(0, len(all_data.index), 5)]\n",
    "        #plt.xticks(x_ticks, rotation = 45)    \n",
    "        #plt.show()\n",
    "\n",
    "        #plt.scatter(data_2.shift(lag),data_1)\n",
    "        #plt.show()\n",
    "\n",
    "        #plot_acf(data_2.shift(lag))\n",
    "        #plt.show()\n",
    "\n",
    "        #plot_pacf(data_2.shift(lag))\n",
    "        #plt.show()\n",
    "\n",
    "        #y = data_1\n",
    "        #X = data_2\n",
    "        #reg = LinearRegression().fit(X, y)\n",
    "\n",
    "        #print(reg.score(X, y),reg.coef_,reg.intercept_)\n",
    "\n",
    "        #model = sm.OLS(y,X)\n",
    "        #results = model.fit()\n",
    "        #print(results.summary())\n",
    "\n",
    "        #Lagged_Differenced_Set = pd.concat([Lagged_Differenced_Set,data_2.shift(lag)],axis=1)\n",
    "        #TrainO_Lagged_Set = pd.concat([TrainO_Lagged_Set,all_data.iloc[:,f].shift(lag)],axis=1)\n",
    "        #if lag>0:\n",
    "            #lag = 0\n",
    "\n",
    "        Lagged_Set = pd.concat([Lagged_Set,og.iloc[:,f].shift(lag)],axis=1)\n",
    "\n",
    "        lagcorrs.append(lagc)\n",
    "\n",
    "        lags.append(lag)\n",
    "\n",
    "    Lagged_Set.index = set_.index\n",
    "    #stats = pd.concat([pd.DataFrame(set_.columns[1:]),pd.DataFrame(lags),pd.DataFrame(lagcorrs),pd.DataFrame(ogcorrs)],axis=1)\n",
    "    stats = pd.concat([pd.DataFrame(set_.columns[1:]),pd.DataFrame(lags),pd.DataFrame(ogcorrs)],axis=1)\n",
    "    \n",
    "    #print(Lagged_Set)\n",
    "    #return stats, pd.concat([data_1,Lagged_Set],axis=1),  pd.concat([data_1,Lagged_Differenced_Set],axis=1)\n",
    "    return stats, pd.concat([set_.iloc[:,0],Lagged_Set],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1497,
   "id": "23eb26a0-bb46-4fd9-b9b8-2de6a3a7f875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['^SP500TR', 'DGS10', 'DTB3', 'DGS3MO', 'MORTGAGE30US', 'DFII10',\n",
       "       'T5YIFR', 'BAMLHYH0A0HYM2TRIV', 'BAMLCC0A1AAATRIV', 'DGS1',\n",
       "       'BAMLCC0A4BBBTRIV', 'IC4WSA', 'WILLMICROCAPPR', 'WILLLRGCAPVAL',\n",
       "       'T5YIE', 'WTB3MS', 'WGS3MO', 'TWEXB', 'DEXCHUS', 'DEXUSUK', 'TEDRATE',\n",
       "       'VIXCLS', 'NFCI', 'BAA10Y', 'BAMLC0A0CM', 'BAMLH0A3HYC', 'DCOILBRENTEU',\n",
       "       'DCOILWTICO', 'DFF', 'DGS1MO', 'DGS30', 'DGS5', 'ICSA', 'M1', 'STLFSI2',\n",
       "       'T10Y2Y', 'T10Y3M', 'TREAST', 'QQQ', 'DIA', 'IYR', 'EWG', 'EWU', 'EWJ',\n",
       "       'EZU', 'EWZ', 'ILF', 'EWW', 'LQD', 'SHY', 'IEF', 'TLT', 'ETH', 'BCH',\n",
       "       'LTC', 'XLY', 'XLP', 'XLE', 'XLF', 'XLV', 'XLI', 'XLB', 'XLK', 'XLU',\n",
       "       'MMM', 'AXP', 'AMGN', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'GS',\n",
       "       'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE',\n",
       "       'PG', 'TRV', 'UNH', 'VZ', 'WMT', 'WBA', 'DIS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1560,
   "id": "3e80173c-962f-4b0e-b170-8186d5f9b635",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lagged_Set = pd.DataFrame()\n",
    "Lagged_Differenced_Set = pd.DataFrame()\n",
    "\n",
    "#'''\n",
    "#Lagged_Differenced_Set_offset = pd.concat([out.result.iloc[:,0].pct_change().shift(-1),out.result.iloc[:,1:].pct_change()],axis=1)\n",
    "differenced_set = out.result.pct_change()\n",
    "differenced_set = differenced_set.replace([np.inf, -np.inf, np.NaN], 0)\n",
    "\n",
    "ls_stats, Lagged_Differenced_Set= getLagged_Set(differenced_set, out.result)\n",
    "lso_stats, Lagged_Differenced_Set_offset= getLagged_Set(pd.concat([differenced_set.iloc[:,0].shift(-1),differenced_set.iloc[:,1:]],axis=1), out.result)\n",
    "\n",
    "#Lagged_Set_offset.index = out.result.index\n",
    "Lagged_Differenced_Set.dropna(inplace= True)\n",
    "#Lagged_Set_offset.columns = out.result.columns\n",
    "\n",
    "Lagged_Differenced_Set_offset.dropna(inplace= True)\n",
    "\n",
    "#Lagged_Differenced_Set.dropna(inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "id": "57b19b33-dfd6-4233-8e3c-4f266a9ce8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0\n",
       "2003-09-30    0.060820\n",
       "2003-12-31    0.076878\n",
       "2004-03-31   -0.004395\n",
       "2004-06-30   -0.012870\n",
       "2004-09-30    0.057999\n",
       "2004-12-31    0.029813\n",
       "2005-03-31   -0.003927\n",
       "2005-06-30    0.040415\n",
       "2005-09-30    0.009843\n",
       "2005-12-31    0.048335\n",
       "Name: ^SP500TR, dtype: float64"
      ]
     },
     "execution_count": 917,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541e943c-2c5b-4cc8-86ca-87a1dab05a44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1535,
   "id": "29c83e18-ed0b-446d-89a3-86ea42e5672c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "^SP500TR        0\n",
       "AXP             0\n",
       "MMM             0\n",
       "XLU             0\n",
       "XLK             0\n",
       "               ..\n",
       "DCOILBRENTEU    0\n",
       "BAMLH0A3HYC     0\n",
       "BAMLC0A0CM      0\n",
       "NFCI            0\n",
       "DIS             0\n",
       "Length: 91, dtype: int64"
      ]
     },
     "execution_count": 1535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "temp = pd.DataFrame()\n",
    "temp = pd.concat([out.result.iloc[:,0].pct_change().shift(-1),Lagged_Set_offset.iloc[:,1:].pct_change()],axis=1).copy()\n",
    "Lagged_Differenced_Set_offset = pd.DataFrame()\n",
    "Lagged_Differenced_Set_offset = temp.copy()\n",
    "Lagged_Differenced_Set_offset.dropna(inplace= True)\n",
    "Lagged_Differenced_Set_offset\n",
    "Lagged_Differenced_Set_offset = Lagged_Differenced_Set_offset.replace([np.inf, -np.inf, np.NaN], 0)\n",
    "#Lagged_Differenced_Set_offset.fillna(0)\n",
    "#preprocessing.StandardScaler().fit(Lagged_Differenced_Set_offset)\n",
    "'''\n",
    "np.sum(Lagged_Differenced_Set_offset.isin([np.inf, -np.inf, np.NaN])).sort_values(kind=\"quicksort\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1536,
   "id": "8cfbc252-b567-48e9-86f9-9e57df0ac45c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0  0         0\n",
      "0          DGS10  0  0.293900\n",
      "1           DTB3  1 -0.003070\n",
      "2         DGS3MO  0  0.112961\n",
      "3   MORTGAGE30US  0  0.080523\n",
      "4         DFII10  0  0.052994\n",
      "..           ... ..       ...\n",
      "85           UNH  0  0.544979\n",
      "86            VZ  0  0.511754\n",
      "87           WMT  0  0.407511\n",
      "88           WBA  0  0.457171\n",
      "89           DIS  0  0.730196\n",
      "\n",
      "[90 rows x 3 columns]\n",
      "               0  0         0\n",
      "0          DGS10  3 -0.042244\n",
      "1           DTB3  3 -0.089426\n",
      "2         DGS3MO  3 -0.088654\n",
      "3   MORTGAGE30US  3 -0.145695\n",
      "4         DFII10  2  0.041021\n",
      "..           ... ..       ...\n",
      "85           UNH  0  0.273665\n",
      "86            VZ  3  0.080712\n",
      "87           WMT  1 -0.086052\n",
      "88           WBA  3  0.151340\n",
      "89           DIS  1 -0.092398\n",
      "\n",
      "[90 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(ls_stats)\n",
    "print(lso_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1654,
   "id": "53aa28e7-3712-466f-96fd-7bbf115714ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^SP500TR</th>\n",
       "      <th>DGS10</th>\n",
       "      <th>DTB3</th>\n",
       "      <th>DGS3MO</th>\n",
       "      <th>MORTGAGE30US</th>\n",
       "      <th>DFII10</th>\n",
       "      <th>T5YIFR</th>\n",
       "      <th>BAMLHYH0A0HYM2TRIV</th>\n",
       "      <th>BAMLCC0A1AAATRIV</th>\n",
       "      <th>DGS1</th>\n",
       "      <th>...</th>\n",
       "      <th>MRK</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NKE</th>\n",
       "      <th>PG</th>\n",
       "      <th>TRV</th>\n",
       "      <th>UNH</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WMT</th>\n",
       "      <th>WBA</th>\n",
       "      <th>DIS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-09-30</th>\n",
       "      <td>0.069088</td>\n",
       "      <td>1.541751</td>\n",
       "      <td>0.915645</td>\n",
       "      <td>0.935161</td>\n",
       "      <td>0.794281</td>\n",
       "      <td>1.692419</td>\n",
       "      <td>2.458548</td>\n",
       "      <td>41.996715</td>\n",
       "      <td>352.547879</td>\n",
       "      <td>1.775484</td>\n",
       "      <td>...</td>\n",
       "      <td>24.940498</td>\n",
       "      <td>0.966422</td>\n",
       "      <td>7.378963</td>\n",
       "      <td>1.252715</td>\n",
       "      <td>22.987969</td>\n",
       "      <td>27.550304</td>\n",
       "      <td>12.984091</td>\n",
       "      <td>39.046941</td>\n",
       "      <td>1.623533</td>\n",
       "      <td>2.482302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-12-31</th>\n",
       "      <td>0.032607</td>\n",
       "      <td>1.495879</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.933710</td>\n",
       "      <td>0.788597</td>\n",
       "      <td>2.045645</td>\n",
       "      <td>2.634194</td>\n",
       "      <td>43.029175</td>\n",
       "      <td>362.683636</td>\n",
       "      <td>2.075000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.109538</td>\n",
       "      <td>0.965952</td>\n",
       "      <td>7.352318</td>\n",
       "      <td>1.252347</td>\n",
       "      <td>24.251518</td>\n",
       "      <td>33.238478</td>\n",
       "      <td>14.858189</td>\n",
       "      <td>36.890209</td>\n",
       "      <td>1.620360</td>\n",
       "      <td>2.447742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-31</th>\n",
       "      <td>-0.003881</td>\n",
       "      <td>1.590695</td>\n",
       "      <td>1.078871</td>\n",
       "      <td>1.096129</td>\n",
       "      <td>0.797332</td>\n",
       "      <td>1.893750</td>\n",
       "      <td>2.481250</td>\n",
       "      <td>43.544771</td>\n",
       "      <td>354.851562</td>\n",
       "      <td>2.472742</td>\n",
       "      <td>...</td>\n",
       "      <td>16.016526</td>\n",
       "      <td>0.968542</td>\n",
       "      <td>7.595334</td>\n",
       "      <td>1.252234</td>\n",
       "      <td>27.052105</td>\n",
       "      <td>37.703203</td>\n",
       "      <td>14.630292</td>\n",
       "      <td>37.523092</td>\n",
       "      <td>1.619811</td>\n",
       "      <td>2.533420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-06-30</th>\n",
       "      <td>0.045642</td>\n",
       "      <td>1.544377</td>\n",
       "      <td>1.488281</td>\n",
       "      <td>1.513906</td>\n",
       "      <td>0.793859</td>\n",
       "      <td>1.690484</td>\n",
       "      <td>2.410484</td>\n",
       "      <td>43.206397</td>\n",
       "      <td>363.761045</td>\n",
       "      <td>3.072459</td>\n",
       "      <td>...</td>\n",
       "      <td>16.911974</td>\n",
       "      <td>0.971730</td>\n",
       "      <td>8.632519</td>\n",
       "      <td>1.253729</td>\n",
       "      <td>27.104700</td>\n",
       "      <td>41.275508</td>\n",
       "      <td>15.591040</td>\n",
       "      <td>36.719812</td>\n",
       "      <td>1.632797</td>\n",
       "      <td>2.586150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-30</th>\n",
       "      <td>0.010137</td>\n",
       "      <td>1.523840</td>\n",
       "      <td>2.011613</td>\n",
       "      <td>2.047419</td>\n",
       "      <td>0.791116</td>\n",
       "      <td>1.717705</td>\n",
       "      <td>2.453279</td>\n",
       "      <td>44.018290</td>\n",
       "      <td>370.418636</td>\n",
       "      <td>3.337344</td>\n",
       "      <td>...</td>\n",
       "      <td>18.243953</td>\n",
       "      <td>0.970402</td>\n",
       "      <td>8.825318</td>\n",
       "      <td>1.254591</td>\n",
       "      <td>23.588805</td>\n",
       "      <td>44.026221</td>\n",
       "      <td>16.741129</td>\n",
       "      <td>33.769871</td>\n",
       "      <td>1.638542</td>\n",
       "      <td>2.558298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>-0.003958</td>\n",
       "      <td>1.220122</td>\n",
       "      <td>2.388361</td>\n",
       "      <td>2.438525</td>\n",
       "      <td>0.760357</td>\n",
       "      <td>0.515873</td>\n",
       "      <td>1.944921</td>\n",
       "      <td>73.572146</td>\n",
       "      <td>637.862812</td>\n",
       "      <td>1.845000</td>\n",
       "      <td>...</td>\n",
       "      <td>79.716758</td>\n",
       "      <td>1.018707</td>\n",
       "      <td>82.613387</td>\n",
       "      <td>1.310248</td>\n",
       "      <td>117.868538</td>\n",
       "      <td>255.783684</td>\n",
       "      <td>51.443717</td>\n",
       "      <td>109.754493</td>\n",
       "      <td>1.769093</td>\n",
       "      <td>3.600235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31</th>\n",
       "      <td>-0.032009</td>\n",
       "      <td>1.140147</td>\n",
       "      <td>2.304921</td>\n",
       "      <td>2.354762</td>\n",
       "      <td>0.749156</td>\n",
       "      <td>0.154219</td>\n",
       "      <td>1.834531</td>\n",
       "      <td>73.014092</td>\n",
       "      <td>662.025846</td>\n",
       "      <td>1.575806</td>\n",
       "      <td>...</td>\n",
       "      <td>82.250245</td>\n",
       "      <td>1.019433</td>\n",
       "      <td>84.411047</td>\n",
       "      <td>1.309857</td>\n",
       "      <td>121.248230</td>\n",
       "      <td>269.978145</td>\n",
       "      <td>52.873113</td>\n",
       "      <td>115.861732</td>\n",
       "      <td>1.736154</td>\n",
       "      <td>3.605762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-30</th>\n",
       "      <td>0.208827</td>\n",
       "      <td>0.980938</td>\n",
       "      <td>1.983594</td>\n",
       "      <td>2.026094</td>\n",
       "      <td>0.736517</td>\n",
       "      <td>0.153387</td>\n",
       "      <td>1.755806</td>\n",
       "      <td>71.316802</td>\n",
       "      <td>704.624478</td>\n",
       "      <td>1.067742</td>\n",
       "      <td>...</td>\n",
       "      <td>79.254899</td>\n",
       "      <td>1.019993</td>\n",
       "      <td>93.038666</td>\n",
       "      <td>1.309202</td>\n",
       "      <td>137.445766</td>\n",
       "      <td>282.275764</td>\n",
       "      <td>53.411418</td>\n",
       "      <td>112.660589</td>\n",
       "      <td>1.738538</td>\n",
       "      <td>3.557512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-30</th>\n",
       "      <td>0.094300</td>\n",
       "      <td>0.978977</td>\n",
       "      <td>1.576935</td>\n",
       "      <td>1.607581</td>\n",
       "      <td>0.738111</td>\n",
       "      <td>-0.063226</td>\n",
       "      <td>1.572903</td>\n",
       "      <td>74.017057</td>\n",
       "      <td>714.379538</td>\n",
       "      <td>0.174286</td>\n",
       "      <td>...</td>\n",
       "      <td>76.548235</td>\n",
       "      <td>1.020851</td>\n",
       "      <td>92.050876</td>\n",
       "      <td>1.313030</td>\n",
       "      <td>142.459886</td>\n",
       "      <td>304.001915</td>\n",
       "      <td>56.515780</td>\n",
       "      <td>121.245848</td>\n",
       "      <td>1.749870</td>\n",
       "      <td>3.486990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>0.121361</td>\n",
       "      <td>0.827040</td>\n",
       "      <td>1.081613</td>\n",
       "      <td>1.104032</td>\n",
       "      <td>0.731042</td>\n",
       "      <td>-0.478889</td>\n",
       "      <td>1.483175</td>\n",
       "      <td>75.440865</td>\n",
       "      <td>733.438923</td>\n",
       "      <td>0.134687</td>\n",
       "      <td>...</td>\n",
       "      <td>80.272736</td>\n",
       "      <td>1.021529</td>\n",
       "      <td>91.585849</td>\n",
       "      <td>1.314522</td>\n",
       "      <td>131.167868</td>\n",
       "      <td>333.177687</td>\n",
       "      <td>54.170968</td>\n",
       "      <td>131.581336</td>\n",
       "      <td>1.733090</td>\n",
       "      <td>3.551627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ^SP500TR     DGS10      DTB3    DGS3MO  MORTGAGE30US    DFII10  \\\n",
       "Unnamed: 0                                                                   \n",
       "2004-09-30  0.069088  1.541751  0.915645  0.935161      0.794281  1.692419   \n",
       "2004-12-31  0.032607  1.495879  0.916129  0.933710      0.788597  2.045645   \n",
       "2005-03-31 -0.003881  1.590695  1.078871  1.096129      0.797332  1.893750   \n",
       "2005-06-30  0.045642  1.544377  1.488281  1.513906      0.793859  1.690484   \n",
       "2005-09-30  0.010137  1.523840  2.011613  2.047419      0.791116  1.717705   \n",
       "...              ...       ...       ...       ...           ...       ...   \n",
       "2019-12-31 -0.003958  1.220122  2.388361  2.438525      0.760357  0.515873   \n",
       "2020-03-31 -0.032009  1.140147  2.304921  2.354762      0.749156  0.154219   \n",
       "2020-06-30  0.208827  0.980938  1.983594  2.026094      0.736517  0.153387   \n",
       "2020-09-30  0.094300  0.978977  1.576935  1.607581      0.738111 -0.063226   \n",
       "2020-12-31  0.121361  0.827040  1.081613  1.104032      0.731042 -0.478889   \n",
       "\n",
       "              T5YIFR  BAMLHYH0A0HYM2TRIV  BAMLCC0A1AAATRIV      DGS1  ...  \\\n",
       "Unnamed: 0                                                            ...   \n",
       "2004-09-30  2.458548           41.996715        352.547879  1.775484  ...   \n",
       "2004-12-31  2.634194           43.029175        362.683636  2.075000  ...   \n",
       "2005-03-31  2.481250           43.544771        354.851562  2.472742  ...   \n",
       "2005-06-30  2.410484           43.206397        363.761045  3.072459  ...   \n",
       "2005-09-30  2.453279           44.018290        370.418636  3.337344  ...   \n",
       "...              ...                 ...               ...       ...  ...   \n",
       "2019-12-31  1.944921           73.572146        637.862812  1.845000  ...   \n",
       "2020-03-31  1.834531           73.014092        662.025846  1.575806  ...   \n",
       "2020-06-30  1.755806           71.316802        704.624478  1.067742  ...   \n",
       "2020-09-30  1.572903           74.017057        714.379538  0.174286  ...   \n",
       "2020-12-31  1.483175           75.440865        733.438923  0.134687  ...   \n",
       "\n",
       "                  MRK      MSFT        NKE        PG         TRV         UNH  \\\n",
       "Unnamed: 0                                                                     \n",
       "2004-09-30  24.940498  0.966422   7.378963  1.252715   22.987969   27.550304   \n",
       "2004-12-31  24.109538  0.965952   7.352318  1.252347   24.251518   33.238478   \n",
       "2005-03-31  16.016526  0.968542   7.595334  1.252234   27.052105   37.703203   \n",
       "2005-06-30  16.911974  0.971730   8.632519  1.253729   27.104700   41.275508   \n",
       "2005-09-30  18.243953  0.970402   8.825318  1.254591   23.588805   44.026221   \n",
       "...               ...       ...        ...       ...         ...         ...   \n",
       "2019-12-31  79.716758  1.018707  82.613387  1.310248  117.868538  255.783684   \n",
       "2020-03-31  82.250245  1.019433  84.411047  1.309857  121.248230  269.978145   \n",
       "2020-06-30  79.254899  1.019993  93.038666  1.309202  137.445766  282.275764   \n",
       "2020-09-30  76.548235  1.020851  92.050876  1.313030  142.459886  304.001915   \n",
       "2020-12-31  80.272736  1.021529  91.585849  1.314522  131.167868  333.177687   \n",
       "\n",
       "                   VZ         WMT       WBA       DIS  \n",
       "Unnamed: 0                                             \n",
       "2004-09-30  12.984091   39.046941  1.623533  2.482302  \n",
       "2004-12-31  14.858189   36.890209  1.620360  2.447742  \n",
       "2005-03-31  14.630292   37.523092  1.619811  2.533420  \n",
       "2005-06-30  15.591040   36.719812  1.632797  2.586150  \n",
       "2005-09-30  16.741129   33.769871  1.638542  2.558298  \n",
       "...               ...         ...       ...       ...  \n",
       "2019-12-31  51.443717  109.754493  1.769093  3.600235  \n",
       "2020-03-31  52.873113  115.861732  1.736154  3.605762  \n",
       "2020-06-30  53.411418  112.660589  1.738538  3.557512  \n",
       "2020-09-30  56.515780  121.245848  1.749870  3.486990  \n",
       "2020-12-31  54.170968  131.581336  1.733090  3.551627  \n",
       "\n",
       "[66 rows x 91 columns]"
      ]
     },
     "execution_count": 1654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6fb84f-111c-44f6-8fcc-7519b387e5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed, lambdas = transform_boxcox(Lagged_Differenced_Set_offset.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1658,
   "id": "abb40926-6979-4f9f-ad09-ed1f93c25a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^SP500TR</th>\n",
       "      <th>DGS10</th>\n",
       "      <th>DTB3</th>\n",
       "      <th>DGS3MO</th>\n",
       "      <th>MORTGAGE30US</th>\n",
       "      <th>DFII10</th>\n",
       "      <th>T5YIFR</th>\n",
       "      <th>BAMLHYH0A0HYM2TRIV</th>\n",
       "      <th>BAMLCC0A1AAATRIV</th>\n",
       "      <th>DGS1</th>\n",
       "      <th>...</th>\n",
       "      <th>MRK</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NKE</th>\n",
       "      <th>PG</th>\n",
       "      <th>TRV</th>\n",
       "      <th>UNH</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WMT</th>\n",
       "      <th>WBA</th>\n",
       "      <th>DIS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-09-30</th>\n",
       "      <td>0.057999</td>\n",
       "      <td>4.285161</td>\n",
       "      <td>0.915645</td>\n",
       "      <td>0.935161</td>\n",
       "      <td>5.919286</td>\n",
       "      <td>1.692419</td>\n",
       "      <td>2.458548</td>\n",
       "      <td>471.486567</td>\n",
       "      <td>352.547879</td>\n",
       "      <td>1.775484</td>\n",
       "      <td>...</td>\n",
       "      <td>24.940498</td>\n",
       "      <td>17.041861</td>\n",
       "      <td>7.378963</td>\n",
       "      <td>34.063519</td>\n",
       "      <td>22.987969</td>\n",
       "      <td>27.550304</td>\n",
       "      <td>12.984091</td>\n",
       "      <td>39.046941</td>\n",
       "      <td>24.984413</td>\n",
       "      <td>19.556695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-12-31</th>\n",
       "      <td>0.029813</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.933710</td>\n",
       "      <td>5.597500</td>\n",
       "      <td>2.045645</td>\n",
       "      <td>2.634194</td>\n",
       "      <td>493.799545</td>\n",
       "      <td>362.683636</td>\n",
       "      <td>2.075000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.109538</td>\n",
       "      <td>16.901527</td>\n",
       "      <td>7.352318</td>\n",
       "      <td>33.884191</td>\n",
       "      <td>24.251518</td>\n",
       "      <td>33.238478</td>\n",
       "      <td>14.858189</td>\n",
       "      <td>36.890209</td>\n",
       "      <td>24.579924</td>\n",
       "      <td>18.519040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-31</th>\n",
       "      <td>-0.003927</td>\n",
       "      <td>4.597097</td>\n",
       "      <td>1.078871</td>\n",
       "      <td>1.096129</td>\n",
       "      <td>6.106154</td>\n",
       "      <td>1.893750</td>\n",
       "      <td>2.481250</td>\n",
       "      <td>505.133968</td>\n",
       "      <td>354.851562</td>\n",
       "      <td>2.472742</td>\n",
       "      <td>...</td>\n",
       "      <td>16.016526</td>\n",
       "      <td>17.702574</td>\n",
       "      <td>7.595334</td>\n",
       "      <td>33.829297</td>\n",
       "      <td>27.052105</td>\n",
       "      <td>37.703203</td>\n",
       "      <td>14.630292</td>\n",
       "      <td>37.523092</td>\n",
       "      <td>24.510839</td>\n",
       "      <td>21.208334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-06-30</th>\n",
       "      <td>0.040415</td>\n",
       "      <td>4.301406</td>\n",
       "      <td>1.488281</td>\n",
       "      <td>1.513906</td>\n",
       "      <td>5.894286</td>\n",
       "      <td>1.690484</td>\n",
       "      <td>2.410484</td>\n",
       "      <td>497.681061</td>\n",
       "      <td>363.761045</td>\n",
       "      <td>3.072459</td>\n",
       "      <td>...</td>\n",
       "      <td>16.911974</td>\n",
       "      <td>18.790922</td>\n",
       "      <td>8.632519</td>\n",
       "      <td>34.566107</td>\n",
       "      <td>27.104700</td>\n",
       "      <td>41.275508</td>\n",
       "      <td>15.591040</td>\n",
       "      <td>36.719812</td>\n",
       "      <td>26.221627</td>\n",
       "      <td>23.071799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-30</th>\n",
       "      <td>0.009843</td>\n",
       "      <td>4.175806</td>\n",
       "      <td>2.011613</td>\n",
       "      <td>2.047419</td>\n",
       "      <td>5.736154</td>\n",
       "      <td>1.717705</td>\n",
       "      <td>2.453279</td>\n",
       "      <td>515.655821</td>\n",
       "      <td>370.418636</td>\n",
       "      <td>3.337344</td>\n",
       "      <td>...</td>\n",
       "      <td>18.243953</td>\n",
       "      <td>18.322877</td>\n",
       "      <td>8.825318</td>\n",
       "      <td>35.003092</td>\n",
       "      <td>23.588805</td>\n",
       "      <td>44.026221</td>\n",
       "      <td>16.741129</td>\n",
       "      <td>33.769871</td>\n",
       "      <td>27.033593</td>\n",
       "      <td>22.066300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>-0.004005</td>\n",
       "      <td>2.652951</td>\n",
       "      <td>2.388361</td>\n",
       "      <td>2.438525</td>\n",
       "      <td>4.373846</td>\n",
       "      <td>0.515873</td>\n",
       "      <td>1.944921</td>\n",
       "      <td>1384.913846</td>\n",
       "      <td>637.862812</td>\n",
       "      <td>1.845000</td>\n",
       "      <td>...</td>\n",
       "      <td>79.716758</td>\n",
       "      <td>123.989471</td>\n",
       "      <td>82.613387</td>\n",
       "      <td>117.793996</td>\n",
       "      <td>117.868538</td>\n",
       "      <td>255.783684</td>\n",
       "      <td>51.443717</td>\n",
       "      <td>109.754493</td>\n",
       "      <td>62.453910</td>\n",
       "      <td>137.410347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31</th>\n",
       "      <td>-0.035486</td>\n",
       "      <td>2.338889</td>\n",
       "      <td>2.304921</td>\n",
       "      <td>2.354762</td>\n",
       "      <td>4.010769</td>\n",
       "      <td>0.154219</td>\n",
       "      <td>1.834531</td>\n",
       "      <td>1364.631385</td>\n",
       "      <td>662.025846</td>\n",
       "      <td>1.575806</td>\n",
       "      <td>...</td>\n",
       "      <td>82.250245</td>\n",
       "      <td>134.769845</td>\n",
       "      <td>84.411047</td>\n",
       "      <td>116.213096</td>\n",
       "      <td>121.248230</td>\n",
       "      <td>269.978145</td>\n",
       "      <td>52.873113</td>\n",
       "      <td>115.861732</td>\n",
       "      <td>48.962003</td>\n",
       "      <td>138.907687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-30</th>\n",
       "      <td>0.137470</td>\n",
       "      <td>1.797969</td>\n",
       "      <td>1.983594</td>\n",
       "      <td>2.026094</td>\n",
       "      <td>3.658462</td>\n",
       "      <td>0.153387</td>\n",
       "      <td>1.755806</td>\n",
       "      <td>1303.857231</td>\n",
       "      <td>704.624478</td>\n",
       "      <td>1.067742</td>\n",
       "      <td>...</td>\n",
       "      <td>79.254899</td>\n",
       "      <td>144.430752</td>\n",
       "      <td>93.038666</td>\n",
       "      <td>113.641568</td>\n",
       "      <td>137.445766</td>\n",
       "      <td>282.275764</td>\n",
       "      <td>53.411418</td>\n",
       "      <td>112.660589</td>\n",
       "      <td>49.787525</td>\n",
       "      <td>126.429677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-30</th>\n",
       "      <td>0.075139</td>\n",
       "      <td>1.791935</td>\n",
       "      <td>1.576935</td>\n",
       "      <td>1.607581</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>-0.063226</td>\n",
       "      <td>1.572903</td>\n",
       "      <td>1401.190606</td>\n",
       "      <td>714.379538</td>\n",
       "      <td>0.174286</td>\n",
       "      <td>...</td>\n",
       "      <td>76.548235</td>\n",
       "      <td>162.182739</td>\n",
       "      <td>92.050876</td>\n",
       "      <td>130.226242</td>\n",
       "      <td>142.459886</td>\n",
       "      <td>304.001915</td>\n",
       "      <td>56.515780</td>\n",
       "      <td>121.245848</td>\n",
       "      <td>54.004437</td>\n",
       "      <td>110.398254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>0.091881</td>\n",
       "      <td>1.365000</td>\n",
       "      <td>1.081613</td>\n",
       "      <td>1.104032</td>\n",
       "      <td>3.521538</td>\n",
       "      <td>-0.478889</td>\n",
       "      <td>1.483175</td>\n",
       "      <td>1453.914697</td>\n",
       "      <td>733.438923</td>\n",
       "      <td>0.134687</td>\n",
       "      <td>...</td>\n",
       "      <td>80.272736</td>\n",
       "      <td>179.525844</td>\n",
       "      <td>91.585849</td>\n",
       "      <td>137.858893</td>\n",
       "      <td>131.167868</td>\n",
       "      <td>333.177687</td>\n",
       "      <td>54.170968</td>\n",
       "      <td>131.581336</td>\n",
       "      <td>47.930033</td>\n",
       "      <td>124.996250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ^SP500TR     DGS10      DTB3    DGS3MO  MORTGAGE30US    DFII10  \\\n",
       "Unnamed: 0                                                                   \n",
       "2004-09-30  0.057999  4.285161  0.915645  0.935161      5.919286  1.692419   \n",
       "2004-12-31  0.029813  4.010000  0.916129  0.933710      5.597500  2.045645   \n",
       "2005-03-31 -0.003927  4.597097  1.078871  1.096129      6.106154  1.893750   \n",
       "2005-06-30  0.040415  4.301406  1.488281  1.513906      5.894286  1.690484   \n",
       "2005-09-30  0.009843  4.175806  2.011613  2.047419      5.736154  1.717705   \n",
       "...              ...       ...       ...       ...           ...       ...   \n",
       "2019-12-31 -0.004005  2.652951  2.388361  2.438525      4.373846  0.515873   \n",
       "2020-03-31 -0.035486  2.338889  2.304921  2.354762      4.010769  0.154219   \n",
       "2020-06-30  0.137470  1.797969  1.983594  2.026094      3.658462  0.153387   \n",
       "2020-09-30  0.075139  1.791935  1.576935  1.607581      3.700000 -0.063226   \n",
       "2020-12-31  0.091881  1.365000  1.081613  1.104032      3.521538 -0.478889   \n",
       "\n",
       "              T5YIFR  BAMLHYH0A0HYM2TRIV  BAMLCC0A1AAATRIV      DGS1  ...  \\\n",
       "Unnamed: 0                                                            ...   \n",
       "2004-09-30  2.458548          471.486567        352.547879  1.775484  ...   \n",
       "2004-12-31  2.634194          493.799545        362.683636  2.075000  ...   \n",
       "2005-03-31  2.481250          505.133968        354.851562  2.472742  ...   \n",
       "2005-06-30  2.410484          497.681061        363.761045  3.072459  ...   \n",
       "2005-09-30  2.453279          515.655821        370.418636  3.337344  ...   \n",
       "...              ...                 ...               ...       ...  ...   \n",
       "2019-12-31  1.944921         1384.913846        637.862812  1.845000  ...   \n",
       "2020-03-31  1.834531         1364.631385        662.025846  1.575806  ...   \n",
       "2020-06-30  1.755806         1303.857231        704.624478  1.067742  ...   \n",
       "2020-09-30  1.572903         1401.190606        714.379538  0.174286  ...   \n",
       "2020-12-31  1.483175         1453.914697        733.438923  0.134687  ...   \n",
       "\n",
       "                  MRK        MSFT        NKE          PG         TRV  \\\n",
       "Unnamed: 0                                                             \n",
       "2004-09-30  24.940498   17.041861   7.378963   34.063519   22.987969   \n",
       "2004-12-31  24.109538   16.901527   7.352318   33.884191   24.251518   \n",
       "2005-03-31  16.016526   17.702574   7.595334   33.829297   27.052105   \n",
       "2005-06-30  16.911974   18.790922   8.632519   34.566107   27.104700   \n",
       "2005-09-30  18.243953   18.322877   8.825318   35.003092   23.588805   \n",
       "...               ...         ...        ...         ...         ...   \n",
       "2019-12-31  79.716758  123.989471  82.613387  117.793996  117.868538   \n",
       "2020-03-31  82.250245  134.769845  84.411047  116.213096  121.248230   \n",
       "2020-06-30  79.254899  144.430752  93.038666  113.641568  137.445766   \n",
       "2020-09-30  76.548235  162.182739  92.050876  130.226242  142.459886   \n",
       "2020-12-31  80.272736  179.525844  91.585849  137.858893  131.167868   \n",
       "\n",
       "                   UNH         VZ         WMT        WBA         DIS  \n",
       "Unnamed: 0                                                            \n",
       "2004-09-30   27.550304  12.984091   39.046941  24.984413   19.556695  \n",
       "2004-12-31   33.238478  14.858189   36.890209  24.579924   18.519040  \n",
       "2005-03-31   37.703203  14.630292   37.523092  24.510839   21.208334  \n",
       "2005-06-30   41.275508  15.591040   36.719812  26.221627   23.071799  \n",
       "2005-09-30   44.026221  16.741129   33.769871  27.033593   22.066300  \n",
       "...                ...        ...         ...        ...         ...  \n",
       "2019-12-31  255.783684  51.443717  109.754493  62.453910  137.410347  \n",
       "2020-03-31  269.978145  52.873113  115.861732  48.962003  138.907687  \n",
       "2020-06-30  282.275764  53.411418  112.660589  49.787525  126.429677  \n",
       "2020-09-30  304.001915  56.515780  121.245848  54.004437  110.398254  \n",
       "2020-12-31  333.177687  54.170968  131.581336  47.930033  124.996250  \n",
       "\n",
       "[66 rows x 91 columns]"
      ]
     },
     "execution_count": 1658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "revert_yeo(Lagged_Differenced_Set_offset, transformed, lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1422b2e-d8e4-43aa-a691-8c54392a6291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c72722f-fbff-4bff-92b8-26b19888e415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "8cc90237-f851-4afb-86f8-2dca0b41123d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cbd = True\n",
    "ic = True\n",
    "\n",
    "# evaluate an elastic net model on the dataset\n",
    "#tsize = .20\n",
    "#train, test = train_test_split(Lagged_Differenced_Set_offset.iloc[:,0:], test_size=tsize, shuffle=False)\n",
    "train, test = train_test_split(transformed.iloc[:,0:], test_size=tsize, shuffle=False)\n",
    "\n",
    "interaction = PolynomialFeatures(degree=2, include_bias=False, interaction_only=ic)\n",
    "\n",
    "#train_t, lambdas_t = transform_boxcox(train)\n",
    "\n",
    "#disabled boxcox\n",
    "if cbd:\n",
    "    train_t = train\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(train_t)\n",
    "\n",
    "#\n",
    "train_s = pd.DataFrame(scaler.transform(train_t))\n",
    "train_s.columns = train.columns\n",
    "train_s.index = train.index  \n",
    "\n",
    "train_t = train_s\n",
    "\n",
    "#test_t = transform_boxcox_l(test, lambdas_t)\n",
    "\n",
    "#disabled boxcox\n",
    "if cbd:\n",
    "    test_t = test\n",
    "\n",
    "test_s = pd.DataFrame(scaler.transform(test_t))\n",
    "test_s.columns = test.columns\n",
    "test_s.index = test.index\n",
    "\n",
    "test_t = test_s\n",
    "\n",
    "y_train = pd.DataFrame(train_t.iloc[:,0])\n",
    "\n",
    "#exclude y\n",
    "\n",
    "X_inter_train = pd.DataFrame(interaction.fit_transform(train_t.iloc[:,1:]), columns=interaction.get_feature_names(input_features=pd.DataFrame(train_t.iloc[:,1:]).columns))\n",
    "\n",
    "    #apply ZCA each time a set of factors are removed (i.e. iteratively)\n",
    " #trf = zca.ZCA().fit(X_inter_train)\n",
    "  #trf = zca.ZCA().fit(X_train)\n",
    "\n",
    " #X_train = pd.DataFrame(trf.transform(X_inter_train))\n",
    "  #X_train = pd.DataFrame(trf.transform(X_train))\n",
    " #X_train.columns=X_inter_train.columns\n",
    "  #X_train.columns=X_train.columns\n",
    "  #X_train.index = train.index\n",
    "\n",
    "#X_inter_alt = X_train.iloc[:, np.array(range(0,len(all_data.iloc[:,2:].columns)))]\n",
    "#print(X_inter_alt.head(3))\n",
    "\n",
    "y_test = pd.DataFrame(test_t.iloc[:,0])\n",
    "\n",
    "X_inter_test = pd.DataFrame(interaction.fit_transform(test_t.iloc[:,1:]), columns=interaction.get_feature_names(input_features=pd.DataFrame(test_t.iloc[:,1:]).columns))\n",
    "\n",
    " #X_test = pd.DataFrame(trf.transform(X_inter_test))\n",
    "  #X_test = pd.DataFrame(trf.transform(X_test))\n",
    "\n",
    " #X_test.columns=X_inter_test.columns\n",
    "  #X_test.columns=X_test.columns\n",
    "  #X_test.index = test.index\n",
    "\n",
    "#X_inter_t_alt = X_test.iloc[:, np.array(range(0,len(all_data.iloc[:,2:].columns)))]\n",
    "#X_inter_t_alt.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcf46d0-1162-46d6-a166-0461b321e0c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define model evaluation method\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define model\n",
    "ratios = arange(0, 1, 0.01)\n",
    "alphas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.0, 1.0, 10.0, 100.0]\n",
    "\n",
    " #model = ElasticNetCV(l1_ratio=ratios, alphas=alphas, cv=cv, n_jobs=4, verbose=0, precompute='auto')\n",
    "\n",
    "model = ElasticNet()\n",
    "grid = dict()\n",
    "# fit model\n",
    "\n",
    "grid['alpha'] = alphas\n",
    "grid['l1_ratio'] = ratios\n",
    "\n",
    "#search = HalvingRandomSearchCV(model, grid,resource='n_samples',max_resources=10,random_state=0)\n",
    "\n",
    "search = GridSearchCV(model, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    " #results = search.fit(X_inter_train, y_train)\n",
    "#results = search.fit(X_train, y_train)\n",
    "\n",
    "results = search.fit(X_inter_train, y_train)\n",
    "\n",
    " #model.fit(X_inter_train, y_train)\n",
    "# summarize chosen configuration\n",
    "\n",
    "print('MAE: %.3f' % results.best_score_)\n",
    "print('Config: %s' % results.best_params_)\n",
    "\n",
    "print(results.best_estimator_)\n",
    "best_model = ElasticNet(alpha=results.best_estimator_.alpha, l1_ratio = results.best_estimator_.l1_ratio)\n",
    "\n",
    "#pd.concat([all_data[Y],all_data_int],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebb7965-c50b-4f1e-bd5e-05504a69192f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model.fit(X_inter_train,train_t.iloc[:,0])\n",
    "\n",
    "trainScore = best_model.score(X_inter_train, y_train, sample_weight=None)\n",
    "testScore = best_model.score(X_inter_test, y_test, sample_weight=None)\n",
    "print(trainScore)\n",
    "print(testScore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb694fa2-0e07-4a01-8648-2d6615a70b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "093a64f9-522d-4761-adf1-f55d566a1b70",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922b12fd-2b69-4243-909a-6f828aa43b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "id": "0e86999a-16ba-4505-b5ec-843d219ac62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.538462\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1067,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367906e7-5aec-4529-8f29-42040e9ac43d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1552,
   "id": "14400790-a56a-4084-8c56-cf73697546e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03928334382719691\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.8323698710372744, pvalue=0.4152951008847169)\n",
      "0.026389773294391506\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.9656230696732769, pvalue=0.34336454282654105)\n"
     ]
    }
   ],
   "source": [
    "#classification transforms\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "interaction = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import random\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SVMSMOTE \n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "#set_ = Lagged_Differenced_Set_offset.copy()\n",
    "#set_ = transformed.copy()\n",
    "#DF_list = list()\n",
    "\n",
    "sets = list()\n",
    "sets.append(transformed.copy())\n",
    "sets.append(Lagged_Differenced_Set_offset.copy())\n",
    "\n",
    "def return_sets(sets):    \n",
    "    \n",
    "    sets_outer = list()\n",
    "    \n",
    "    for i in sets:\n",
    "        \n",
    "        sets_multiple = list()\n",
    "        \n",
    "        set_ = pd.DataFrame()\n",
    "        set_ = i\n",
    "\n",
    "        X, y = set_.iloc[:,1:],  set_.iloc[:,0]\n",
    "        \n",
    "        print(mean(y))\n",
    "\n",
    "        y = pd.DataFrame(np.where(y > mean(y), 1, 0))\n",
    "        y.index = set_.index\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tsize, shuffle=False)\n",
    "\n",
    "        a = set_.iloc[:,0].loc[X_train.index]\n",
    "        b = set_.iloc[:,0].loc[X_test.index]\n",
    "        plt.hist(a)\n",
    "        plt.show()\n",
    "        plt.hist(b)\n",
    "        plt.show()\n",
    "        print(stats.ttest_ind(a,b, equal_var = False))\n",
    "\n",
    "        one = y_train[y_train==0].dropna().sample(int(len(X_train)*2), replace=True, random_state=1)\n",
    "        two = y_train[y_train==1].dropna().sample(int(len(X_train)*2), replace=True, random_state=1)\n",
    "\n",
    "        train_index = np.append(one.index,two.index)\n",
    "\n",
    "        #destroyed my data\n",
    "        #smote = SVMSMOTE(random_state=42)\n",
    "            #smote = SMOTE()\n",
    "        #Xsm_train, ysm_train = smote.fit_sample(np.array(X_train),np.array(y_train))\n",
    "\n",
    "        Xsm_train = X_train.copy()\n",
    "        ysm_train = y_train.copy()\n",
    "        \n",
    "        #use with optimal lags\n",
    "        #y_test = y_test.loc[y_test.index>y_test.index[maxl]]\n",
    "        #X_test = X_test.loc[X_test.index>X_test.index[maxl]]\n",
    "\n",
    "        scaler = preprocessing.StandardScaler().fit(Xsm_train)\n",
    "\n",
    "        X_train_transformed = pd.DataFrame(scaler.transform(Xsm_train))\n",
    "        X_train_transformed.columns = X_train.columns\n",
    "\n",
    "        X_inter_train = X_train_transformed.copy()\n",
    "\n",
    "        #X_inter_train = pd.DataFrame(interaction.fit_transform(X_train_transformed), columns=interaction.get_feature_names(input_features=pd.DataFrame(X_train_transformed).columns))\n",
    "\n",
    "        trf = zca.ZCA().fit(X_inter_train)\n",
    "\n",
    "        #X_inter_train = pd.DataFrame(trf.transform(X_inter_train))\n",
    "        X_inter_train.columns=pd.DataFrame(X_inter_train).columns\n",
    "        #X_inter_train.index = X_train.loc[train_index].index\n",
    "\n",
    "        X_test_transformed = pd.DataFrame(scaler.transform(X_test))\n",
    "        X_test_transformed.columns = X_test.columns\n",
    "        X_test_transformed.index = X_test.index\n",
    "\n",
    "        X_inter_test = X_test_transformed\n",
    "\n",
    "        #X_inter_test = pd.DataFrame(interaction.fit_transform(X_test_transformed), columns=interaction.get_feature_names(input_features=pd.DataFrame(X_test_transformed).columns))\n",
    "\n",
    "        #X_inter_test = pd.DataFrame(trf.transform(X_inter_test))\n",
    "\n",
    "        sets_multiple.append(X_inter_train)\n",
    "        sets_multiple.append(y_train)\n",
    "        sets_multiple.append(X_inter_test)\n",
    "        sets_multiple.append(y_test)        \n",
    "    \n",
    "        sets_outer.append(sets_multiple)\n",
    "        \n",
    "    return(sets_outer)\n",
    "\n",
    "values = return_sets(sets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568baa66-4a53-4f23-ba8a-c5f9408f1591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "id": "73ec310d-7f86-4154-be9b-11c927a6a4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1553,
   "id": "e560215f-9b7d-4d76-ac61-dbf96d2cfd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.52 accuracy with a standard deviation of 0.12\n",
      "0.42857142857142855\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60         6\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.21      0.50      0.30        14\n",
      "weighted avg       0.18      0.43      0.26        14\n",
      "\n",
      "[[6 0]\n",
      " [8 0]]\n",
      "[1] 52\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60         6\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.21      0.50      0.30        14\n",
      "weighted avg       0.18      0.43      0.26        14\n",
      "\n",
      "[[6 0]\n",
      " [8 0]]\n",
      "0.46 accuracy with a standard deviation of 0.20\n",
      "0.6428571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.64      1.00      0.78         9\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.32      0.50      0.39        14\n",
      "weighted avg       0.41      0.64      0.50        14\n",
      "\n",
      "[[0 5]\n",
      " [0 9]]\n",
      "[1] 52\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.64      1.00      0.78         9\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.32      0.50      0.39        14\n",
      "weighted avg       0.41      0.64      0.50        14\n",
      "\n",
      "[[0 5]\n",
      " [0 9]]\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "#works best\n",
    "#class balanced, no zca\n",
    "from sklearn import svm\n",
    "\n",
    "for i in range(0,len(sets)):\n",
    "    \n",
    "    X_train = values[i][0]\n",
    "    y_train = values[i][1]\n",
    "    X_test = values[i][2]\n",
    "    y_test = values[i][3]\n",
    "\n",
    "    clf = svm.SVC(kernel='rbf', C=1, random_state=42)\n",
    "\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=10)\n",
    "\n",
    "    print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "    clf = svm.SVC(C=1).fit(X_train, y_train)\n",
    "\n",
    "    train_predict = clf.predict(X_train)\n",
    "    predicteds = clf.predict(X_test)\n",
    "    #predicted.index = y_test.index\n",
    "\n",
    "    print(clf.score(X_test, y_test))\n",
    "\n",
    "    #clf.predict(X_test)\n",
    "    #print(predicteds)\n",
    "    print(metrics.classification_report(y_test,predicteds))\n",
    "    print(metrics.confusion_matrix(y_test,predicteds))\n",
    "\n",
    "    predictions_s = arfima_adjust(y_train, y_test, train_predict, predicteds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "id": "ec38a51f-ede1-47bb-9af7-ee25b6106160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25944973-ee0b-4b74-be6c-f59463229bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c39fe4e-d604-4fa9-ad81-ee7a53a06784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "3909eb8a-645f-47c5-933a-98d61f3d6ab3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('svc', svm.SVC(kernel='sigmoid', C=1, random_state=42))])\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)\n",
    "'''\n",
    "#search = cross_val_score(pipe, X_inter_train, y_train.loc[train_index], cv=10)\n",
    "#GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "#search.fit(X_digits, y_digits)\n",
    "#print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "#print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "id": "d83b6ec4-6148-41ba-9d1b-3765f913ee93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0]"
      ]
     },
     "execution_count": 1045,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1554,
   "id": "b49b4466-cd31-4f19-85e0-c32db62dbe01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60         6\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.21      0.50      0.30        14\n",
      "weighted avg       0.18      0.43      0.26        14\n",
      "\n",
      "[[6 0]\n",
      " [8 0]]\n",
      "[1] 52\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60         6\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.21      0.50      0.30        14\n",
      "weighted avg       0.18      0.43      0.26        14\n",
      "\n",
      "[[6 0]\n",
      " [8 0]]\n",
      "LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.64      1.00      0.78         9\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.32      0.50      0.39        14\n",
      "weighted avg       0.41      0.64      0.50        14\n",
      "\n",
      "[[0 5]\n",
      " [0 9]]\n",
      "[1] 52\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.64      1.00      0.78         9\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.32      0.50      0.39        14\n",
      "weighted avg       0.41      0.64      0.50        14\n",
      "\n",
      "[[0 5]\n",
      " [0 9]]\n"
     ]
    }
   ],
   "source": [
    "#Logistic1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "for i in range(0,len(sets)):\n",
    "    \n",
    "    X_train = values[i][0]\n",
    "    y_train = values[i][1]\n",
    "    X_test = values[i][2]\n",
    "    y_test = values[i][3]\n",
    "\n",
    "    modell = LogisticRegression()\n",
    "    modell.fit(X_train, y_train)\n",
    "    print(modell)\n",
    "\n",
    "    #expected = y_test\n",
    "    train_predict = modell.predict(X_train)\n",
    "    predictedl = modell.predict(X_test)\n",
    "\n",
    "    print(metrics.classification_report(y_test,predictedl))\n",
    "    print(metrics.confusion_matrix(y_test,predictedl))\n",
    "    \n",
    "    predictions_l = arfima_adjust(y_train, y_test, train_predict, predictedl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1555,
   "id": "7672895b-f442-45b4-8cb1-3257e8c830a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.83      0.67         6\n",
      "           1       0.80      0.50      0.62         8\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.68      0.67      0.64        14\n",
      "weighted avg       0.70      0.64      0.64        14\n",
      "\n",
      "[[5 1]\n",
      " [4 4]]\n",
      "[1] 52\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.83      0.67         6\n",
      "           1       0.80      0.50      0.62         8\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.68      0.67      0.64        14\n",
      "weighted avg       0.70      0.64      0.64        14\n",
      "\n",
      "[[5 1]\n",
      " [4 4]]\n",
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.64      1.00      0.78         9\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.32      0.50      0.39        14\n",
      "weighted avg       0.41      0.64      0.50        14\n",
      "\n",
      "[[0 5]\n",
      " [0 9]]\n",
      "[1] 52\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.64      1.00      0.78         9\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.32      0.50      0.39        14\n",
      "weighted avg       0.41      0.64      0.50        14\n",
      "\n",
      "[[0 5]\n",
      " [0 9]]\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "for i in range(0,len(sets)):\n",
    "    \n",
    "    X_train = values[i][0]\n",
    "    y_train = values[i][1]\n",
    "    X_test = values[i][2]\n",
    "    y_test = values[i][3]\n",
    "\n",
    "    modeln = GaussianNB()\n",
    "    modeln.fit(X_train, y_train)\n",
    "    print(modeln)\n",
    "\n",
    "    #expected = y_test\n",
    "    train_predict = modeln.predict(X_train)\n",
    "    predictedn = modeln.predict(X_test)\n",
    "\n",
    "    print(metrics.classification_report(y_test,predictedn))\n",
    "    print(metrics.confusion_matrix(y_test,predictedn))\n",
    "    \n",
    "    predictions_n = arfima_adjust(y_train, y_test, train_predict, predictedn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1556,
   "id": "644b63d8-9f6e-453e-b896-0ee262d1242e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60         6\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.21      0.50      0.30        14\n",
      "weighted avg       0.18      0.43      0.26        14\n",
      "\n",
      "[[6 0]\n",
      " [8 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60         6\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.21      0.50      0.30        14\n",
      "weighted avg       0.18      0.43      0.26        14\n",
      "\n",
      "[[6 0]\n",
      " [8 0]]\n",
      "DecisionTreeClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      1.00      0.53         5\n",
      "           1       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.36        14\n",
      "   macro avg       0.18      0.50      0.26        14\n",
      "weighted avg       0.13      0.36      0.19        14\n",
      "\n",
      "[[5 0]\n",
      " [9 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      1.00      0.53         5\n",
      "           1       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.36        14\n",
      "   macro avg       0.18      0.50      0.26        14\n",
      "weighted avg       0.13      0.36      0.19        14\n",
      "\n",
      "[[5 0]\n",
      " [9 0]]\n"
     ]
    }
   ],
   "source": [
    "#DecisionTreeClassifier\n",
    "#works best with transformed\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "for i in range(0,len(sets)):\n",
    "    \n",
    "    X_train = values[i][0]\n",
    "    y_train = values[i][1]\n",
    "    X_test = values[i][2]\n",
    "    y_test = values[i][3]\n",
    "\n",
    "    modeld = DecisionTreeClassifier()\n",
    "    modeld.fit(X_train, y_train)\n",
    "    print(modeld)\n",
    "\n",
    "    #expected = y_test\n",
    "    train_predict = modeld.predict(X_train)\n",
    "    predictedd = modeld.predict(X_test)\n",
    "\n",
    "    print(metrics.classification_report(y_test,predictedd))\n",
    "    print(metrics.confusion_matrix(y_test,predictedd))\n",
    "        \n",
    "    predictions_d = arima_adjust(y_train, y_test, train_predict, predictedd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1557,
   "id": "6ce0671f-8931-4f7e-936b-51adcb52dab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 14}\n",
      "0.5381818181818182\n",
      "[[6 0]\n",
      " [8 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60         6\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.21      0.50      0.30        14\n",
      "weighted avg       0.18      0.43      0.26        14\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60         6\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.21      0.50      0.30        14\n",
      "weighted avg       0.18      0.43      0.26        14\n",
      "\n",
      "[[6 0]\n",
      " [8 0]]\n",
      "{'n_neighbors': 1}\n",
      "0.5327272727272728\n",
      "[[0 5]\n",
      " [0 9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.64      1.00      0.78         9\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.32      0.50      0.39        14\n",
      "weighted avg       0.41      0.64      0.50        14\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.64      1.00      0.78         9\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.32      0.50      0.39        14\n",
      "weighted avg       0.41      0.64      0.50        14\n",
      "\n",
      "[[0 5]\n",
      " [0 9]]\n"
     ]
    }
   ],
   "source": [
    "#knn\n",
    "#works best with transformed\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV#create new a knn model\n",
    "\n",
    "for i in range(0,len(sets)):\n",
    "    \n",
    "    X_train = values[i][0]\n",
    "    y_train = values[i][1]\n",
    "    X_test = values[i][2]\n",
    "    y_test = values[i][3]\n",
    "    \n",
    "    knn2 = KNeighborsClassifier(metric='euclidean',weights='distance')#create a dictionary of all values we want to test for n_neighbors\n",
    "    param_grid = {'n_neighbors': np.arange(1, 25)}#use gridsearch to test all values for n_neighbors\n",
    "    knn_gscv = GridSearchCV(knn2, param_grid, cv=5)#fit model to data\n",
    "    knn_gscv.fit(X_train, y_train)\n",
    "    #check top performing n_neighbors value\n",
    "    print(knn_gscv.best_params_)\n",
    "    #check mean score for the top performing value of n_neighbors\n",
    "    print(knn_gscv.best_score_)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors = knn_gscv.best_params_['n_neighbors'],metric='euclidean',weights='distance')\n",
    "    knn.fit(X_train,y_train)\n",
    "    train_predict = knn.predict(X_train)\n",
    "    predictedk = knn.predict(X_test)\n",
    "    knn.score(X_test, y_test)\n",
    "\n",
    "    print(confusion_matrix(y_test, predictedk))\n",
    "    print(classification_report(y_test, predictedk))\n",
    "    \n",
    "    predictions_k = arima_adjust(y_train, y_test, train_predict, predictedk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43107e46-54bb-4837-a798-af32efaccadb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "e55c7caf-0c3b-4911-ba58-8313a7ba85ff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-771-d7e137a3e15d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0msearch_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_absolute_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mresults_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_inter_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mysm_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m  \u001b[0;31m#model.fit(X_inter_train, y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Elastic logistic\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
    "# define model\n",
    "ratios = arange(0, 1, 0.01)\n",
    "alphas = (10 ** np.linspace(-1, 1, 10))/10\n",
    "alphas = np.append(alphas,[10.0, 100.0])\n",
    "\n",
    "model = SGDClassifier(loss=\"log\", penalty=\"elasticnet\")\n",
    "grid = dict()\n",
    "# fit model\n",
    "\n",
    "grid['alpha'] = alphas\n",
    "grid['l1_ratio'] = ratios\n",
    "\n",
    "search_l = GridSearchCV(model, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "results_l = search_l.fit(X_inter_train, ysm_train)\n",
    "\n",
    " #model.fit(X_inter_train, y_train)\n",
    "# summarize chosen configuration\n",
    "\n",
    "print('MAE: %.3f' % results_l.best_score_)\n",
    "print('Config: %s' % results_l.best_params_)\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "print(results_l.best_estimator_)\n",
    "best_model_l = SGDClassifier(alpha=results_l.best_estimator_.alpha, l1_ratio = results_l.best_estimator_.l1_ratio)\n",
    "\n",
    "#calibrator = CalibratedClassifierCV(best_model_l, cv='prefit')\n",
    "#model=calibrator.fit(X_inter_train, y_train)\n",
    "\n",
    "best_model_l.fit(X_inter_train,ysm_train)\n",
    "\n",
    "#sgd = SGDClassifier()\n",
    "\n",
    "#sgd.partial_fit(X_inter_train,y_train, classes=[0,1])\n",
    "\n",
    "print(pd.DataFrame(np.transpose(best_model_l.coef_)).set_index(X_inter_train.columns))\n",
    "\n",
    "trainScore_l = best_model_l.score(X_inter_train, ysm_train, sample_weight=None)\n",
    "testScore_l = best_model_l.score(X_inter_test, y_test, sample_weight=None)\n",
    "print(trainScore_l)\n",
    "print(testScore_l)\n",
    "\n",
    "#print(help(KNeighborsClassifier))\n",
    "predictedl = best_model_l.predict(X_inter_test)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4b9087-fe22-4d54-b152-a40e48784774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1559,
   "id": "7015d3fd-f35c-4f6c-b8e9-f66c92514715",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.642857\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1558,
   "id": "a6dd1212-7817-4f74-95d6-0493d68c9658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            s  k  d  l  n\n",
      "Unnamed: 0               \n",
      "2017-09-30  1  1  0  1  1\n",
      "2017-12-31  1  1  0  1  1\n",
      "2018-03-31  1  1  0  1  1\n",
      "2018-06-30  1  1  0  1  1\n",
      "2018-09-30  1  1  0  1  1\n",
      "2018-12-31  1  1  0  1  1\n",
      "2019-03-31  1  1  0  1  1\n",
      "2019-06-30  1  1  0  1  1\n",
      "2019-09-30  1  1  0  1  1\n",
      "2019-12-31  1  1  0  1  1\n",
      "2020-03-31  1  1  0  1  1\n",
      "2020-06-30  1  1  0  1  1\n",
      "2020-09-30  1  1  0  1  1\n",
      "2020-12-31  1  1  0  1  1\n",
      "[[0 5]\n",
      " [0 9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.64      1.00      0.78         9\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.32      0.50      0.39        14\n",
      "weighted avg       0.41      0.64      0.50        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "#predictedf = pd.concat([pd.DataFrame(predicteds),pd.DataFrame(predictedk),pd.DataFrame(predictedl)],axis=1)\n",
    "predictedf = pd.concat([pd.DataFrame(predictions_s),pd.DataFrame(predictions_k),pd.DataFrame(predictions_d),pd.DataFrame(predictions_l),pd.DataFrame(predictions_n)],axis=1)\n",
    "predictedf.columns = [\"s\",\"k\",\"d\",\"l\",\"n\"]\n",
    "predictedf.index = y_test.index\n",
    "print(predictedf)\n",
    "print(confusion_matrix(y_test, predictedf.mode(axis=1).iloc[:,0]))\n",
    "#print(confusion_matrix(y_test, predictedf.median(axis=1)))\n",
    "print(classification_report(y_test, predictedf.mode(axis=1).iloc[:,0]))\n",
    "#print(classification_report(y_test, predictedf.median(axis=1)))\n",
    "\n",
    "print(mean(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1587,
   "id": "0e4dfc37-ab80-427f-bc37-edb9a212c4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The null hypothesis can be rejected\n",
      "6.8571923164665565\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.9204818738934394\n",
      "The null hypothesis can be rejected\n",
      "-0.7898842707686613\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.4877305718960252\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.44311306479792595\n",
      "The null hypothesis can be rejected\n",
      "-8.971378904843366\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "2.255106795619879\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.9172406911608825\n",
      "The null hypothesis can be rejected\n",
      "-8.971378904843366\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-3.923292120762976\n",
      "The null hypothesis can be rejected\n",
      "-1.2490704681396876\n",
      "The null hypothesis can be rejected\n",
      "-1.7127195803200987\n",
      "The null hypothesis can be rejected\n",
      "-1.33886882830031\n",
      "The null hypothesis can be rejected\n",
      "-2.091773391680359\n",
      "The null hypothesis can be rejected\n",
      "-0.8700477267109975\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.7670704271114449\n",
      "The null hypothesis can be rejected\n",
      "-0.8744240579374699\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-8.971378904843366\n",
      "The null hypothesis can be rejected\n",
      "-8.971378904843366\n",
      "The null hypothesis can be rejected\n",
      "-0.5265849228961135\n",
      "The null hypothesis can be rejected\n",
      "0.8292444353075392\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.41854309431093656\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.35339678717132234\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.11935013549100779\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.6508661355274881\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.24005749756499173\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.04382275669698245\n",
      "The null hypothesis can be rejected\n",
      "-0.41992512052098335\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.888762938824054\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "1.654784745604463\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.591869887346348\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.8461224870906359\n",
      "The null hypothesis can be rejected\n",
      "-0.14984839690751842\n",
      "The null hypothesis can be rejected\n",
      "-0.7385822356946687\n",
      "The null hypothesis can be rejected\n",
      "-0.029368031331773223\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.026476512677382383\n",
      "The null hypothesis can be rejected\n",
      "-0.8574804716548347\n",
      "The null hypothesis can be rejected\n",
      "-0.3193225144825856\n",
      "The null hypothesis cannot be rejected\n",
      "67\n",
      "33\n",
      "34\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# multivariate output multi-step 1d cnn example\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Dense, SimpleRNN, GRU, LSTM\n",
    "from keras.optimizers import SGD\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Lagged_Differenced_Set = (all_data - all_data.shift(-1)).dropna()\n",
    "\n",
    "transformed_, lambdas_ = transform_boxcox(Lagged_Differenced_Set.dropna())\n",
    "\n",
    "choice = Lagged_Differenced_Set\n",
    "\n",
    "train, test = train_test_split(choice, test_size=tsize, shuffle=False)\n",
    "\n",
    "#train_t, lambdas_t = transform_boxcox(train)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(train)\n",
    "\n",
    "train_s = pd.DataFrame(scaler.transform(train))\n",
    "test_s = pd.DataFrame(scaler.transform(test))\n",
    "\n",
    "combined = pd.concat([train_s,test_s],axis=0)\n",
    "combined.index = Lagged_Differenced_Set.index\n",
    "combined.columns = Lagged_Differenced_Set.columns\n",
    "\n",
    "set_ = combined\n",
    "\n",
    "def plot_learning_curves(loss, val_loss):\n",
    "    plt.plot(np.arange(len(loss)) + 0.5, loss, \"b.\", label=\"Training loss\")\n",
    "    plt.plot(np.arange(len(val_loss)) + 1, val_loss, \"r-\", label=\"Validation loss\")\n",
    "    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out, xcolumns, ycolumns):\n",
    "    \n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, xcolumns], sequences[end_ix:out_end_ix, ycolumns]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    \n",
    "    return array(X), array(y)\n",
    "\n",
    "#n_steps_in = int(np.floor(len(train)*.8))\n",
    "print(len(set_))\n",
    "n_steps_in = int(np.round(len(set_)/2))\n",
    "print(len(set_) - n_steps_in)\n",
    "print(n_steps_in)\n",
    "#n_steps_out = int(len(train)-n_steps_in)\n",
    "n_steps_out = 1\n",
    "print(n_steps_out)\n",
    "\n",
    "#ycolumns = range(0,len(transformed.columns))\n",
    "ycolumns = range(0,len(set_.columns[0:1].values))\n",
    "xcolumns = range(1,len(set_.columns[1:]))\n",
    "\n",
    "#trainInner, valid = train_test_split(trainOuter, test_size=0.15, shuffle=False)\n",
    "#trainInner_whitened = pd.DataFrame(trf.transform(trainInner.iloc[:,1:])).set_index(trainInner.index)\n",
    "#valid_whitened = pd.DataFrame(trf.transform(valid.iloc[:,1:])).set_index(valid.index)\n",
    "#test_whitened = pd.DataFrame(trf.transform(test.iloc[:,1:])).set_index(test.index)\n",
    "\n",
    "#trainOuter_whitened=pd.DataFrame(trf.transform(trainOuter.iloc[:,1:])).set_index(trainOuter.index)\n",
    "\n",
    "X, y = split_sequences(np.array(set_), n_steps_in, n_steps_out, xcolumns, ycolumns)\n",
    "\n",
    "#for i in range(len(X)):\n",
    "#    print(X[i], y[i])\n",
    "    \n",
    "#flatten output\n",
    "\n",
    "if len(ycolumns) > 0:\n",
    "    n_output = y.shape[1] * y.shape[2]\n",
    "    y = y.reshape((y.shape[0], n_output))\n",
    "\n",
    "n_features = X.shape[2]\n",
    "\n",
    "# define model\n",
    "modelCNN = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.MaxPooling1D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(50, activation='relu'),\n",
    "    keras.layers.Dense(n_output)\n",
    "])\n",
    "\n",
    "# fit model\n",
    "#model.fit(X, y, epochs=7000, verbose=0)\n",
    "\n",
    "epochs_ = 2000\n",
    "batch_size_ = 25\n",
    "\n",
    "#np.random.seed(42)\n",
    "#tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "#model.compile(optimizer='adam', loss='mse')\n",
    "modelCNN.compile(loss=\"MAPE\", optimizer=\"rmsprop\",metrics=['MAPE'])\n",
    "\n",
    "#model6.compile(loss=\"MAPE\", optimizer=\"rmsprop\",metrics=['MAPE'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=tsize,\n",
    "                                                    shuffle = False)\n",
    "                                                    #random_state=42)\n",
    "#scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "#X_train_transformed = pd.DataFrame(scaler.transform(X_train))\n",
    "#X_train_transformed.columns = X_train.columns\n",
    "\n",
    "#X_test_transformed = pd.DataFrame(scaler.transform(X_test))\n",
    "#X_test_transformed.columns = X_test.columns\n",
    "#X_test_transformed.index = X_test.index\n",
    "\n",
    "    #new_series = pd.DataFrame(ts_train_scaled).append(pd.DataFrame(ts_valid_scaled)).append(pd.DataFrame(ts_test_scaled))\n",
    "\n",
    "    #series_reshaped = np.array([new_series[i:i + (n_steps+n_ahead)].copy() for i in range(len(data) - (n_steps+n_ahead))])  \n",
    "    \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train,\n",
    "                                                    test_size=tsize,\n",
    "                                                    shuffle = False)\n",
    "                                                    #random_state=42)    \n",
    "\n",
    "#model6.compile(loss=\"MAPE\", optimizer=\"rmsprop\",metrics=['MAPE'])\n",
    "historyCNN = modelCNN.fit(X_train, y_train, epochs=epochs_,batch_size=batch_size_,validation_data=(X_valid, y_valid), verbose=0)\n",
    "#history6 = model6.fit(X_train, y_train, epochs=epochs_,batch_size=batch_size_,validation_data=(X_valid, y_valid), verbose=0)\n",
    "#history = model.fit(X_train, y_train, epochs=epochs_,batch_size=batch_size_,verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1603,
   "id": "d2d1ce87-6c86-4308-8788-b01aa8256fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^SP500TR</th>\n",
       "      <th>DGS10</th>\n",
       "      <th>DTB3</th>\n",
       "      <th>DGS3MO</th>\n",
       "      <th>MORTGAGE30US</th>\n",
       "      <th>DFII10</th>\n",
       "      <th>T5YIFR</th>\n",
       "      <th>BAMLHYH0A0HYM2TRIV</th>\n",
       "      <th>BAMLCC0A1AAATRIV</th>\n",
       "      <th>DGS1</th>\n",
       "      <th>...</th>\n",
       "      <th>MRK</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NKE</th>\n",
       "      <th>PG</th>\n",
       "      <th>TRV</th>\n",
       "      <th>UNH</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WMT</th>\n",
       "      <th>WBA</th>\n",
       "      <th>DIS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-09-30</th>\n",
       "      <td>-0.012870</td>\n",
       "      <td>4.301406</td>\n",
       "      <td>1.488281</td>\n",
       "      <td>1.513906</td>\n",
       "      <td>5.597500</td>\n",
       "      <td>1.893750</td>\n",
       "      <td>2.481250</td>\n",
       "      <td>471.486567</td>\n",
       "      <td>347.606716</td>\n",
       "      <td>2.075000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.109538</td>\n",
       "      <td>17.702574</td>\n",
       "      <td>7.595334</td>\n",
       "      <td>34.063519</td>\n",
       "      <td>23.588805</td>\n",
       "      <td>27.550304</td>\n",
       "      <td>15.591040</td>\n",
       "      <td>39.411029</td>\n",
       "      <td>26.221627</td>\n",
       "      <td>18.519040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-12-31</th>\n",
       "      <td>0.057999</td>\n",
       "      <td>4.175806</td>\n",
       "      <td>2.011613</td>\n",
       "      <td>2.047419</td>\n",
       "      <td>6.106154</td>\n",
       "      <td>1.690484</td>\n",
       "      <td>2.410484</td>\n",
       "      <td>493.799545</td>\n",
       "      <td>352.547879</td>\n",
       "      <td>2.472742</td>\n",
       "      <td>...</td>\n",
       "      <td>16.016526</td>\n",
       "      <td>18.790922</td>\n",
       "      <td>8.632519</td>\n",
       "      <td>33.884191</td>\n",
       "      <td>23.633433</td>\n",
       "      <td>33.238478</td>\n",
       "      <td>16.741129</td>\n",
       "      <td>39.046941</td>\n",
       "      <td>27.033593</td>\n",
       "      <td>21.208334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-31</th>\n",
       "      <td>0.029813</td>\n",
       "      <td>4.303607</td>\n",
       "      <td>2.543607</td>\n",
       "      <td>2.589180</td>\n",
       "      <td>5.894286</td>\n",
       "      <td>1.717705</td>\n",
       "      <td>2.453279</td>\n",
       "      <td>505.133968</td>\n",
       "      <td>362.683636</td>\n",
       "      <td>3.072459</td>\n",
       "      <td>...</td>\n",
       "      <td>16.911974</td>\n",
       "      <td>18.322877</td>\n",
       "      <td>8.825318</td>\n",
       "      <td>33.829297</td>\n",
       "      <td>25.325401</td>\n",
       "      <td>37.703203</td>\n",
       "      <td>15.067529</td>\n",
       "      <td>36.890209</td>\n",
       "      <td>31.015902</td>\n",
       "      <td>23.071799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-06-30</th>\n",
       "      <td>-0.003927</td>\n",
       "      <td>4.158594</td>\n",
       "      <td>2.866719</td>\n",
       "      <td>2.926719</td>\n",
       "      <td>5.736154</td>\n",
       "      <td>1.677812</td>\n",
       "      <td>2.389219</td>\n",
       "      <td>497.681061</td>\n",
       "      <td>354.851562</td>\n",
       "      <td>3.337344</td>\n",
       "      <td>...</td>\n",
       "      <td>18.243953</td>\n",
       "      <td>18.077632</td>\n",
       "      <td>8.410524</td>\n",
       "      <td>34.566107</td>\n",
       "      <td>25.137430</td>\n",
       "      <td>41.275508</td>\n",
       "      <td>14.588157</td>\n",
       "      <td>37.523092</td>\n",
       "      <td>32.133305</td>\n",
       "      <td>22.066300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-30</th>\n",
       "      <td>0.040415</td>\n",
       "      <td>4.215156</td>\n",
       "      <td>3.363437</td>\n",
       "      <td>3.438281</td>\n",
       "      <td>5.768462</td>\n",
       "      <td>1.822813</td>\n",
       "      <td>2.339375</td>\n",
       "      <td>515.655821</td>\n",
       "      <td>363.761045</td>\n",
       "      <td>3.791094</td>\n",
       "      <td>...</td>\n",
       "      <td>16.680745</td>\n",
       "      <td>18.919080</td>\n",
       "      <td>8.474308</td>\n",
       "      <td>35.003092</td>\n",
       "      <td>29.196517</td>\n",
       "      <td>44.026221</td>\n",
       "      <td>14.105960</td>\n",
       "      <td>36.719812</td>\n",
       "      <td>33.187636</td>\n",
       "      <td>20.419871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31</th>\n",
       "      <td>-0.004005</td>\n",
       "      <td>1.365000</td>\n",
       "      <td>1.081613</td>\n",
       "      <td>1.104032</td>\n",
       "      <td>3.658462</td>\n",
       "      <td>-0.063226</td>\n",
       "      <td>1.572903</td>\n",
       "      <td>1364.631385</td>\n",
       "      <td>637.862812</td>\n",
       "      <td>1.067742</td>\n",
       "      <td>...</td>\n",
       "      <td>79.254899</td>\n",
       "      <td>162.182739</td>\n",
       "      <td>92.050876</td>\n",
       "      <td>116.213096</td>\n",
       "      <td>120.553566</td>\n",
       "      <td>269.978145</td>\n",
       "      <td>54.170968</td>\n",
       "      <td>109.754493</td>\n",
       "      <td>47.930033</td>\n",
       "      <td>126.429677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-30</th>\n",
       "      <td>-0.035486</td>\n",
       "      <td>0.687619</td>\n",
       "      <td>0.142222</td>\n",
       "      <td>0.142222</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>-0.478889</td>\n",
       "      <td>1.483175</td>\n",
       "      <td>1303.857231</td>\n",
       "      <td>662.025846</td>\n",
       "      <td>0.174286</td>\n",
       "      <td>...</td>\n",
       "      <td>76.548235</td>\n",
       "      <td>179.525844</td>\n",
       "      <td>91.585849</td>\n",
       "      <td>113.641568</td>\n",
       "      <td>102.873246</td>\n",
       "      <td>282.275764</td>\n",
       "      <td>53.825355</td>\n",
       "      <td>115.861732</td>\n",
       "      <td>40.506450</td>\n",
       "      <td>110.398254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-30</th>\n",
       "      <td>0.137470</td>\n",
       "      <td>0.650625</td>\n",
       "      <td>0.113437</td>\n",
       "      <td>0.113437</td>\n",
       "      <td>3.521538</td>\n",
       "      <td>-0.938594</td>\n",
       "      <td>1.715469</td>\n",
       "      <td>1401.190606</td>\n",
       "      <td>704.624478</td>\n",
       "      <td>0.134687</td>\n",
       "      <td>...</td>\n",
       "      <td>80.272736</td>\n",
       "      <td>208.256990</td>\n",
       "      <td>106.779949</td>\n",
       "      <td>130.226242</td>\n",
       "      <td>112.663497</td>\n",
       "      <td>304.001915</td>\n",
       "      <td>56.228699</td>\n",
       "      <td>112.660589</td>\n",
       "      <td>37.713145</td>\n",
       "      <td>124.996250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>0.075139</td>\n",
       "      <td>0.864516</td>\n",
       "      <td>0.092903</td>\n",
       "      <td>0.092903</td>\n",
       "      <td>3.239231</td>\n",
       "      <td>-0.917097</td>\n",
       "      <td>1.874516</td>\n",
       "      <td>1453.914697</td>\n",
       "      <td>714.379538</td>\n",
       "      <td>0.114516</td>\n",
       "      <td>...</td>\n",
       "      <td>78.958120</td>\n",
       "      <td>213.740980</td>\n",
       "      <td>132.040460</td>\n",
       "      <td>137.858893</td>\n",
       "      <td>127.132947</td>\n",
       "      <td>333.177687</td>\n",
       "      <td>58.090774</td>\n",
       "      <td>121.245848</td>\n",
       "      <td>37.808995</td>\n",
       "      <td>143.534063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-31</th>\n",
       "      <td>0.091881</td>\n",
       "      <td>1.335902</td>\n",
       "      <td>0.051148</td>\n",
       "      <td>0.051148</td>\n",
       "      <td>2.952308</td>\n",
       "      <td>-0.849344</td>\n",
       "      <td>2.053934</td>\n",
       "      <td>1508.204769</td>\n",
       "      <td>733.438923</td>\n",
       "      <td>0.082459</td>\n",
       "      <td>...</td>\n",
       "      <td>76.785190</td>\n",
       "      <td>231.228145</td>\n",
       "      <td>138.849439</td>\n",
       "      <td>129.482420</td>\n",
       "      <td>146.417223</td>\n",
       "      <td>345.573742</td>\n",
       "      <td>55.800131</td>\n",
       "      <td>131.581336</td>\n",
       "      <td>48.772338</td>\n",
       "      <td>184.415573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ^SP500TR     DGS10      DTB3    DGS3MO  MORTGAGE30US    DFII10  \\\n",
       "Unnamed: 0                                                                   \n",
       "2004-09-30 -0.012870  4.301406  1.488281  1.513906      5.597500  1.893750   \n",
       "2004-12-31  0.057999  4.175806  2.011613  2.047419      6.106154  1.690484   \n",
       "2005-03-31  0.029813  4.303607  2.543607  2.589180      5.894286  1.717705   \n",
       "2005-06-30 -0.003927  4.158594  2.866719  2.926719      5.736154  1.677812   \n",
       "2005-09-30  0.040415  4.215156  3.363437  3.438281      5.768462  1.822813   \n",
       "...              ...       ...       ...       ...           ...       ...   \n",
       "2020-03-31 -0.004005  1.365000  1.081613  1.104032      3.658462 -0.063226   \n",
       "2020-06-30 -0.035486  0.687619  0.142222  0.142222      3.700000 -0.478889   \n",
       "2020-09-30  0.137470  0.650625  0.113437  0.113437      3.521538 -0.938594   \n",
       "2020-12-31  0.075139  0.864516  0.092903  0.092903      3.239231 -0.917097   \n",
       "2021-03-31  0.091881  1.335902  0.051148  0.051148      2.952308 -0.849344   \n",
       "\n",
       "              T5YIFR  BAMLHYH0A0HYM2TRIV  BAMLCC0A1AAATRIV      DGS1  ...  \\\n",
       "Unnamed: 0                                                            ...   \n",
       "2004-09-30  2.481250          471.486567        347.606716  2.075000  ...   \n",
       "2004-12-31  2.410484          493.799545        352.547879  2.472742  ...   \n",
       "2005-03-31  2.453279          505.133968        362.683636  3.072459  ...   \n",
       "2005-06-30  2.389219          497.681061        354.851562  3.337344  ...   \n",
       "2005-09-30  2.339375          515.655821        363.761045  3.791094  ...   \n",
       "...              ...                 ...               ...       ...  ...   \n",
       "2020-03-31  1.572903         1364.631385        637.862812  1.067742  ...   \n",
       "2020-06-30  1.483175         1303.857231        662.025846  0.174286  ...   \n",
       "2020-09-30  1.715469         1401.190606        704.624478  0.134687  ...   \n",
       "2020-12-31  1.874516         1453.914697        714.379538  0.114516  ...   \n",
       "2021-03-31  2.053934         1508.204769        733.438923  0.082459  ...   \n",
       "\n",
       "                  MRK        MSFT         NKE          PG         TRV  \\\n",
       "Unnamed: 0                                                              \n",
       "2004-09-30  24.109538   17.702574    7.595334   34.063519   23.588805   \n",
       "2004-12-31  16.016526   18.790922    8.632519   33.884191   23.633433   \n",
       "2005-03-31  16.911974   18.322877    8.825318   33.829297   25.325401   \n",
       "2005-06-30  18.243953   18.077632    8.410524   34.566107   25.137430   \n",
       "2005-09-30  16.680745   18.919080    8.474308   35.003092   29.196517   \n",
       "...               ...         ...         ...         ...         ...   \n",
       "2020-03-31  79.254899  162.182739   92.050876  116.213096  120.553566   \n",
       "2020-06-30  76.548235  179.525844   91.585849  113.641568  102.873246   \n",
       "2020-09-30  80.272736  208.256990  106.779949  130.226242  112.663497   \n",
       "2020-12-31  78.958120  213.740980  132.040460  137.858893  127.132947   \n",
       "2021-03-31  76.785190  231.228145  138.849439  129.482420  146.417223   \n",
       "\n",
       "                   UNH         VZ         WMT        WBA         DIS  \n",
       "Unnamed: 0                                                            \n",
       "2004-09-30   27.550304  15.591040   39.411029  26.221627   18.519040  \n",
       "2004-12-31   33.238478  16.741129   39.046941  27.033593   21.208334  \n",
       "2005-03-31   37.703203  15.067529   36.890209  31.015902   23.071799  \n",
       "2005-06-30   41.275508  14.588157   37.523092  32.133305   22.066300  \n",
       "2005-09-30   44.026221  14.105960   36.719812  33.187636   20.419871  \n",
       "...                ...        ...         ...        ...         ...  \n",
       "2020-03-31  269.978145  54.170968  109.754493  47.930033  126.429677  \n",
       "2020-06-30  282.275764  53.825355  115.861732  40.506450  110.398254  \n",
       "2020-09-30  304.001915  56.228699  112.660589  37.713145  124.996250  \n",
       "2020-12-31  333.177687  58.090774  121.245848  37.808995  143.534063  \n",
       "2021-03-31  345.573742  55.800131  131.581336  48.772338  184.415573  \n",
       "\n",
       "[67 rows x 91 columns]"
      ]
     },
     "execution_count": 1603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need to apply to test\n",
    "#revert_boxcox(pd.DataFrame(transformed_.iloc[:,0]),pd.DataFrame(lambdas[0]))\n",
    "#Lagged_Differenced_Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1588,
   "id": "0b8f7e2d-3603-4ba1-8457-4fd9918498a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "plot_learning_curves(historyCNN.history[\"loss\"], historyCNN.history[\"val_loss\"])\n",
    "plt.show()\n",
    "#plot_learning_curves(history6.history[\"loss\"], history.history[\"val_loss\"])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1576,
   "id": "799f6d94-9757-4baa-b095-8937fbba5857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.403554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.472922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.395263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.648622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.333758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-12.124576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25.782852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0   0.403554\n",
       "1  -1.472922\n",
       "2  -2.395263\n",
       "3  -2.648622\n",
       "4  -2.333758\n",
       "5 -12.124576\n",
       "6  25.782852"
      ]
     },
     "execution_count": 1576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1573,
   "id": "bee4c952-450d-43d4-86c1-2a37673a58d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1573-3bb2feae7f87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'values'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1589,
   "id": "c2cbc3da-fa1f-4e57-9d84-f4e5f8872af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.048163</td>\n",
       "      <td>0.031267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.044359</td>\n",
       "      <td>0.047498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039392</td>\n",
       "      <td>-0.004005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.038825</td>\n",
       "      <td>-0.035486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.042503</td>\n",
       "      <td>0.137470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.032046</td>\n",
       "      <td>0.075139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.029713</td>\n",
       "      <td>0.091881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted  original\n",
       "0   0.048163  0.031267\n",
       "1   0.044359  0.047498\n",
       "2   0.039392 -0.004005\n",
       "3   0.038825 -0.035486\n",
       "4   0.042503  0.137470\n",
       "5   0.032046  0.075139\n",
       "6   0.029713  0.091881"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#multi\n",
    "yhat = modelCNN.predict(X_test, verbose=0)\n",
    "\n",
    "predicted = []\n",
    "original = []\n",
    "if len(ycolumns) > 1:\n",
    "    results = yhat.reshape(len(y_test), int(yhat.shape[1]/X_test.shape[2]), len(transformed.columns))\n",
    "    for i in range(0,len(results)):\n",
    "        predicted.append(pd.DataFrame(results[i])[0][0])\n",
    "        original.append(pd.DataFrame(y_test[i])[0][0])\n",
    "        #print(pd.DataFrame(results[i])[0][0])\n",
    "        #print(pd.DataFrame(y_test[i])[0][0])\n",
    "else:\n",
    "    results = yhat\n",
    "    for i in range(0,len(results)):\n",
    "        predicted.append(results[i])\n",
    "        original.append(y_test[i])\n",
    "        #print(pd.DataFrame(results[i]))\n",
    "        #print(pd.DataFrame(y_test[i]))\n",
    "        \n",
    "plt.scatter(scaler.mean_[0]+scaler.scale_[0]*pd.DataFrame(predicted),scaler.mean_[0]+scaler.scale_[0]*pd.DataFrame(original))\n",
    "temp = pd.concat([pd.DataFrame(scaler.mean_[0]+scaler.scale_[0]*pd.DataFrame(predicted)),pd.DataFrame(scaler.mean_[0]+scaler.scale_[0]*pd.DataFrame(original))],axis=1)\n",
    "temp.columns = [\"predicted\", \"original\"]\n",
    "display(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8229628-eed4-4b76-831d-1de033240347",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.DataFrame(best_model.coef_).set_index(X_inter_train.columns)\n",
    "\n",
    "a_coef = abs(coef)\n",
    "a_coef.sort_values(by=[0],ascending=False,inplace=True)\n",
    "chosen_few = a_coef[a_coef>0].dropna().index.values\n",
    "\n",
    "scaler_ = preprocessing.StandardScaler().fit(transformed)\n",
    "\n",
    "#\n",
    "train_ = pd.DataFrame(scaler_.transform(transformed))\n",
    "train_.columns = transformed.columns\n",
    "train_.index = transformed.index  \n",
    "\n",
    "X_inter_train_ = pd.DataFrame(interaction.fit_transform(train_.iloc[:,1:]), columns=interaction.get_feature_names(input_features=pd.DataFrame(train_.iloc[:,1:]).columns))\n",
    "\n",
    "max_pvalue = 1\n",
    "New_Names = X_inter_train.columns\n",
    "X_b = X_inter_train_[chosen_few]\n",
    "while (max_pvalue > .05):\n",
    "        \n",
    "    trf = zca.ZCA().fit(X_b)\n",
    "        \n",
    "    X_b_z = pd.DataFrame(trf.transform(X_b))\n",
    "    X_b_z.columns=pd.DataFrame(X_b).columns\n",
    "    X_b_z.index = train_.index\n",
    "\n",
    "    model_ = sm.OLS(train_.iloc[:,0],sm.tools.tools.add_constant(X_b_z, prepend=True, has_constant='skip'))        \n",
    "    #model_ = sm.OLS(pd.DataFrame(pd.concat([train_.iloc[:,0],X_b_z],axis=1),sm.tools.tools.add_constant(X_b_z, prepend=True, has_constant='skip'))        \n",
    "    results_ = model_.fit()\n",
    "\n",
    "    set_ = X_b.columns.tolist()\n",
    "    \n",
    "    max_pvalue = max(results_.pvalues[1:])\n",
    "    if (max_pvalue > .05):\n",
    "        print(max_pvalue)\n",
    "        max_pname = (results_.pvalues[1:]).idxmax(axis=1)\n",
    "        set_.remove(max_pname)\n",
    "        New_Names = set_\n",
    "    \n",
    "        X_b = X_inter_train_[New_Names]\n",
    "        X_b.index = X_inter_train_.index\n",
    "\n",
    "#from statsmodels.formula.api import ols\n",
    "#lm = ols(pd.DataFrame(train_.iloc[:,0]) ~ sm.tools.tools.add_constant(X_b_z, prepend=True, has_constant='skip')).fit()\n",
    "#table = sm.stats.anova_lm(model_, type=3)\n",
    "#print(table)\n",
    "print(results_.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35e428c-cce9-46e3-b145-754fc9e4c576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findNaNCols(df_):\n",
    "    for col in df_:        \n",
    "        num_NaNs = df_[col].isnull().sum()\n",
    "        if num_NaNs > 0:\n",
    "            print(f\"Column: {col}\")\n",
    "            print(f\"Number of NaNs: {num_NaNs}\")\n",
    "\n",
    "findNaNCols(X_b_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d4e220-4ac2-4945-9e3a-4b8ff1355a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d940860-86d6-4768-81a0-63f9127143a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linear_plot = Plot.LinearRegressionResidualPlot(X_b_z, pd.DataFrame(train_.iloc[:,0]))\n",
    "lm = linear_plot.fit()\n",
    "summary, diag_res = linear_plot.diagnostic_plots(lm)\n",
    "print(\"Summary of Regression\\n:{}\".format(summary))\n",
    "print(\"Diagnostic Tests of Regression\\n:{}\".format(diag_res))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#sns.pairplot(pd.concat([pd.DataFrame(train[Y]),X_b_z],axis=1), hue=Y, height=2);\n",
    "\n",
    "pd.concat([pd.DataFrame(train[Y]),X_b_z],axis=1).hist()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "model_s = sklearn.linear_model.LinearRegression()\n",
    "model_s.fit(X_b_z, pd.DataFrame(train_[Y]))\n",
    "\n",
    "shap.initjs()\n",
    "e = shap.explainers.Linear(model_s, X_b_z)\n",
    "\n",
    "shap_values = e.shap_values(X_b_z)\n",
    "shap.summary_plot(shap_values, X_b_z)\n",
    "shap.plots.heatmap(e(X_b_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53b64b8-ca00-46d1-ba16-91f3adb00065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4871c2-4418-491a-8e5c-5776d42e4381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f\n",
    "\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "residuals_normalized = lm.get_influence().resid_studentized_internal\n",
    "cooks = lm.get_influence().cooks_distance[0]\n",
    "cooks = np.round(f.pdf(cooks,len(lm.tvalues)+1, len(lm.fittedvalues)-len(lm.tvalues)-1),2)\n",
    "\n",
    "res_std = lm.get_influence().resid_std\n",
    "\n",
    "leverage = lm.get_influence().hat_matrix_diag\n",
    "\n",
    "plt.hist(pd.DataFrame(leverage))\n",
    "plt.show()\n",
    "\n",
    "plt.hist(pd.DataFrame(cooks))\n",
    "plt.show()\n",
    "\n",
    "plt.hist(pd.DataFrame(residuals_normalized))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "testNormal(residuals_normalized)\n",
    "\n",
    "w = res_std\n",
    "x = cooks\n",
    "y = leverage\n",
    "z = residuals_normalized\n",
    "\n",
    "fitted_y = lm.fittedvalues\n",
    "\n",
    "labels_ = fitted_y.index\n",
    "\n",
    "outlier_check = pd.concat([pd.DataFrame(x),pd.DataFrame(y),pd.DataFrame(z),pd.DataFrame(w)],axis=1).set_index(labels_)\n",
    "\n",
    "outlier_check.columns =  ['cooks', 'leverage', 'tsres', 'sres']\n",
    "\n",
    "qq = ProbPlot(residuals_normalized)\n",
    "\n",
    "c_thresh = .1\n",
    "l_thresh = (2*(len(lm.tvalues)-1)/len(lm.fittedvalues))\n",
    "s_thresh = max(qq.theoretical_quantiles)\n",
    "\n",
    "print(\"Outlier threshold's\")\n",
    "print(\"Cooks distance: > .1+\")\n",
    "print(\"Leverage: > \" + str(l_thresh) + \" to \" + str(3 * (len(lm.tvalues)-1)/len(fitted_y)))\n",
    "print(\"Studentized residuals: > \" + str(s_thresh))\n",
    "print()\n",
    "\n",
    "flag = []\n",
    "\n",
    "for i in range(0,len(outlier_check)):\n",
    "    if( (outlier_check.iloc[i][0] >= c_thresh) or (outlier_check.iloc[i][1] >= l_thresh) or (abs(outlier_check.iloc[i][2]) >= s_thresh) ):\n",
    "        print(outlier_check.iloc[i])\n",
    "        print()\n",
    "        flag.append(True)\n",
    "    else:\n",
    "        flag.append(False)\n",
    "\n",
    "outlier_check = pd.concat([outlier_check,pd.DataFrame(flag).set_index(labels_)],axis=1)\n",
    "\n",
    "outlier_check.columns =  ['cooks', 'leverage', 'tsres', 'sres', 'flagged']\n",
    "\n",
    "print(np.flip(np.argsort(cooks), 0))\n",
    "#print(outlier_check)\n",
    "\n",
    "search = outlier_check[outlier_check['flagged']==1].index.to_list()\n",
    "\n",
    "rows = []\n",
    "\n",
    "for i in search:\n",
    "    v = outlier_check.index.to_list().index(i)\n",
    "    rows.append(v)\n",
    "\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b2b196-7761-4420-a145-a5411053a625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_style(row):\n",
    "\n",
    "    color = 'white'\n",
    "    if bool(row.flagged) == True:\n",
    "        color = 'orange'\n",
    "\n",
    "    return ['background-color: %s' % color]*len(row.values)\n",
    "\n",
    "all_data[set(all_data.columns) & set(New_Names)]\n",
    "\n",
    "outlier_check.style.apply(custom_style, axis=1).apply(custom_style, axis=1).background_gradient(cmap ='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da39b86-0ac2-4470-9457-8e999918d47c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6b8430-ac88-4358-88c1-e6c5400fe7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = y_train.columns.to_list()\n",
    "df2 = list(set(set(all_data.columns) & set(New_Names)))\n",
    "\n",
    "flattened = [] \n",
    "for sublist in df1,df2: \n",
    "    for val in sublist: \n",
    "        flattened.append(val) \n",
    "\n",
    "all_data.iloc[rows][flattened].style.background_gradient(cmap ='viridis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
