{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b3139d-1ac0-4486-80f0-e54d08259ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipywidgets import IntSlider\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee726465-0b88-46f7-877f-5aee84616ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import shap\n",
    "import numpy as np\n",
    "import ZCA as zca\n",
    "import statsmodels.api as sm\n",
    "import matplotlib as plt\n",
    "\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import IPython\n",
    "\n",
    "import os\n",
    "os.environ['R_HOME'] = '/mnt/distvol/R/4.0.5/lib64/R/'\n",
    "import rpy2.robjects as R\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import arange\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import shap\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import seaborn as sns\n",
    "from ModelDiagnostics import Plot\n",
    "from sklearn.cluster import DBSCAN\n",
    "from clustergram import Clustergram\n",
    "import urbangrammar_graphics as ugg\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy import stats\n",
    "from scipy.special import boxcox, inv_boxcox\n",
    "from scipy.stats import f\n",
    "\n",
    "import dtale\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bf8827-4f34-413b-9a4d-bd6565e33372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#power = PowerTransformer(method='box-cox')\n",
    "\n",
    "def testNormal (x):    \n",
    "    \n",
    "    k2, p = stats.normaltest(x)\n",
    "    alpha = .001\n",
    "    #print(\"p = {:g}\".format(p))    \n",
    "    if p < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "        #print(p)\n",
    "        #print(alpha)\n",
    "        print(\"The null hypothesis can be rejected\")\n",
    "        xt, _ = stats.yeojohnson(x)\n",
    "        #xt, _ = stats.boxcox(x)        \n",
    "        print(_)\n",
    "        xt = pd.DataFrame(xt)\n",
    "        \n",
    "        return _, pd.DataFrame(xt).set_index(x.index)\n",
    "    else:\n",
    "        print(\"The null hypothesis cannot be rejected\")    \n",
    "        return 1, pd.DataFrame(x)\n",
    "\n",
    "def inverse_boxcox (data, lambdas):\n",
    "    return inv_boxcox(data, lambdas.values)\n",
    "    \n",
    "def transform_boxcox_l(data, l_):\n",
    "    transformed = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data.columns)):\n",
    "        #print(i)\n",
    "        if l_.iloc[i].values == 1:\n",
    "            inner_scale = data.iloc[:,i]            \n",
    "        else:\n",
    "            inner_scale = pd.DataFrame(stats.boxcox((data.iloc[:,i]), lmbda=l_.iloc[i].values))\n",
    "            \n",
    "        inner_scale.index = data.index\n",
    "        transformed = pd.concat([transformed,inner_scale],axis=1)\n",
    "        \n",
    "    transformed.columns = data.columns\n",
    "    return transformed\n",
    "\n",
    "def transform_boxcox (data):\n",
    "    transformed = pd.DataFrame()\n",
    "    transformed_lambdas = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data.columns)):\n",
    "        l, inner_scale = testNormal(data.iloc[:,i])\n",
    "        inner_scale.set_index(data.index)\n",
    "\n",
    "        transformed_lambdas = pd.concat([transformed_lambdas,pd.DataFrame(pd.Series(l))],axis=0)\n",
    "        transformed = pd.concat([transformed,inner_scale],axis=1)\n",
    "        \n",
    "    transformed.columns = data.columns\n",
    "    return transformed, transformed_lambdas\n",
    "\n",
    "def revert_boxcox (data, lambdas):\n",
    "    reverted = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data.columns)):        \n",
    "        if lambdas.iloc[i].values == 1 :\n",
    "            revert = data.iloc[:,i]\n",
    "        else:\n",
    "            revert = pd.DataFrame(inv_boxcox(data.iloc[:,i].values, lambdas.iloc[i].values))            \n",
    "        revert.index = data.index\n",
    "        reverted = pd.concat([reverted,revert],axis=1)\n",
    "        \n",
    "    reverted.columns = data.columns\n",
    "    return reverted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec9d431-186e-4171-8a8a-378ab2ab2e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_deltas(data):\n",
    "\n",
    "    R.r('''\n",
    "               f <- function(values) {\n",
    "                        #system(\"which openssl\")\n",
    "\n",
    "                        library(snpEnrichment)\n",
    "                        library(arfima)\n",
    "                        library(parallel)\n",
    "                        library(forecast)                    \n",
    "\n",
    "                        dset <- lapply(1:ncol(values),function(x)\n",
    "                        {\n",
    "                            column = values[,x]\n",
    "\n",
    "\n",
    "                            #tryCatch(invisible(capture.output(suppressMessages(suppressWarnings(\n",
    "                            #{\n",
    "                              varvefd = arfima(column)\n",
    "                              d = summary(varvefd)$coef[[1]][1]\n",
    "                              return(d)\n",
    "                            #}\n",
    "                           #)\n",
    "                           #))),\n",
    "                            #error=function(e)\n",
    "                              #{\n",
    "                                #d = 1\n",
    "                                #return(d)\n",
    "                              #})\n",
    "\n",
    "                        })    \n",
    "\n",
    "                        unlist(dset)\n",
    "\n",
    "                }\n",
    "                ''')\n",
    "\n",
    "    r_f = R.globalenv['f']\n",
    "    d=R.conversion.rpy2py((r_f(R.conversion.py2rpy(data.dropna()))))\n",
    "    return(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a133da3-b0fd-4741-a0aa-db8cc75f878d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_weights(d, num_k):\n",
    "    r\"\"\"Calculate weights ($w$) for each lag ($k$) through\n",
    "    $w_k = -w_{k-1} \\frac{d - k + 1}{k}$.\n",
    "    \n",
    "    Args:\n",
    "        d (int): differencing value.\n",
    "        num_k (int): number of lags (typically length of timeseries) to calculate w.\n",
    "    \"\"\"\n",
    "    w_k = np.array([1])\n",
    "    \n",
    "    for k in range(1, num_k):\n",
    "        w_k = np.append(w_k, -w_k[-1] * ((d - k + 1)) / k)\n",
    "        \n",
    "    w_k = w_k.reshape(-1, 1) \n",
    "    \n",
    "    return w_k\n",
    "\n",
    "def get_weights_floored(d, num_k, floor=1e-3):\n",
    "    r\"\"\"Calculate weights ($w$) for each lag ($k$) through\n",
    "    $w_k = -w_{k-1} \\frac{d - k + 1}{k}$ provided weight above a minimum value\n",
    "    (floor) for the weights to prevent computation of weights for the entire\n",
    "    time series.\n",
    "    \n",
    "    Args:\n",
    "        d (int): differencing value.\n",
    "        num_k (int): number of lags (typically length of timeseries) to calculate w.\n",
    "        floor (float): minimum value for the weights for computational efficiency.\n",
    "    \"\"\"\n",
    "    w_k = np.array([1])\n",
    "    k = 1\n",
    "    \n",
    "    while k < num_k:\n",
    "        w_k_latest = -w_k[-1] * ((d - k + 1)) / k\n",
    "        if abs(w_k_latest) <= floor:\n",
    "            break\n",
    "\n",
    "        w_k = np.append(w_k, w_k_latest)\n",
    "        \n",
    "        k += 1\n",
    "\n",
    "    w_k = w_k.reshape(-1, 1) \n",
    "    \n",
    "    return w_k\n",
    "\n",
    "def frac_diff(df, d, floor=1e-3):\n",
    "    r\"\"\"Fractionally difference time series via CPU.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe of raw time series values.\n",
    "        d (float): differencing value from 0 to 1 where > 1 has no FD.\n",
    "        floor (float): minimum value of weights, ignoring anything smaller.\n",
    "    \"\"\"\n",
    "    # Get weights window\n",
    "    weights = get_weights_floored(d=d, num_k=len(df), floor=floor)\n",
    "    weights_window_size = len(weights)\n",
    "    \n",
    "    # Reverse weights\n",
    "    weights = weights[::-1]\n",
    "    \n",
    "    # Blank fractionally differenced series to be filled\n",
    "    df_fd = []\n",
    "\n",
    "    # Slide window of time series, to calculated fractionally differenced values\n",
    "    # per window\n",
    "    for idx in range(weights_window_size, df.shape[0]):\n",
    "        # Dot product of weights and original values\n",
    "        # to get fractionally differenced values\n",
    "        date_idx = df.index[idx]\n",
    "        df_fd.append(np.dot(weights.T, df.iloc[idx - weights_window_size:idx]).item())\n",
    "    \n",
    "    # Return FD values and weights\n",
    "    df_fd = pd.DataFrame(df_fd)\n",
    "    \n",
    "    return df_fd, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e53d3-2864-4d69-a45a-ce48217e4fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d949ef06-ae96-4828-b02b-21a92a11b29f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e6233b-8abf-4f78-83f5-a3e7a2e26fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_data = pd.read_csv('/mnt/distvol/combined_set.csv')\n",
    "all_data.index = all_data.iloc[:,0]\n",
    "all_data = all_data.iloc[:,1:]\n",
    "\n",
    "filter_ = all_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2b9636-4857-4aaa-b13d-e2077e957c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f3(Y):\n",
    "    \n",
    "    #Y = x\n",
    "    #output_slider_variable.value\n",
    "    internalFilter = filter_.copy()\n",
    "    internalFilter.remove(Y)\n",
    "    all_data_ = pd.concat([all_data[Y],all_data[internalFilter]], axis=1)    \n",
    "    #print(all_data_.describe())\n",
    "    display(all_data_.describe())\n",
    "    x_ticks = all_data_.index[np.arange(0, len(all_data.index), 5)]\n",
    "    plt.plot(all_data_[Y])\n",
    "    plt.xticks(x_ticks, rotation = 45)\n",
    "    plt.show()        \n",
    "    plt.hist(all_data_[Y], bins='auto')\n",
    "    plt.show()\n",
    "    diff = pd.DataFrame((all_data_[Y]-all_data_[Y].shift(-1))).dropna()\n",
    "    plt.hist(diff, bins='auto')\n",
    "    plt.show()\n",
    "    return(all_data_)\n",
    "    \n",
    "out = interactive(f3, Y=filter_)\n",
    "\n",
    "#output_slider_variable.observe(f4, 'value')\n",
    "\n",
    "print(\"choose Y\")\n",
    "display(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e1c5c4-9718-4cbb-a820-9fd94e3fc482",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = get_deltas(out.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f492f94d-cba1-455a-b1d4-157a346f6d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ = dtale.show(out.result)\n",
    "d_.open_browser()\n",
    "d_._url  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4273fdd8-d805-4928-b7dd-bda427cf51fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DoneAndNotDoneFutures(done={<Future at 0x7f2f36260040 state=finished returned ndarray>, <Future at 0x7f2f36260070 state=finished returned ndarray>, <Future at 0x7f2f362620d0 state=finished returned ndarray>, <Future at 0x7f2f36262100 state=finished returned ndarray>, <Future at 0x7f2f36262130 state=finished returned ndarray>, <Future at 0x7f2f3625a160 state=finished returned ndarray>, <Future at 0x7f2f362a62e0 state=finished returned ndarray>, <Future at 0x7f2f36262310 state=finished returned ndarray>, <Future at 0x7f2f3625a340 state=finished returned ndarray>, <Future at 0x7f2f36262370 state=finished returned ndarray>, <Future at 0x7f2f36260490 state=finished returned ndarray>, <Future at 0x7f2f3625a490 state=finished returned ndarray>, <Future at 0x7f2f362604c0 state=finished returned ndarray>, <Future at 0x7f2f3625a4c0 state=finished returned ndarray>, <Future at 0x7f2f36260550 state=finished returned ndarray>, <Future at 0x7f2f362ac5e0 state=finished returned ndarray>, <Future at 0x7f2f362605e0 state=finished returned ndarray>, <Future at 0x7f2f362626a0 state=finished returned ndarray>, <Future at 0x7f2f36262730 state=finished returned ndarray>, <Future at 0x7f2f36262760 state=finished returned ndarray>, <Future at 0x7f2f362628b0 state=finished returned ndarray>, <Future at 0x7f2f362608e0 state=finished returned ndarray>, <Future at 0x7f2f366049d0 state=finished returned ndarray>, <Future at 0x7f2f3625a9d0 state=finished returned ndarray>, <Future at 0x7f2f3625aa00 state=finished returned ndarray>, <Future at 0x7f2f3625aa60 state=finished returned ndarray>, <Future at 0x7f2f362acac0 state=finished returned ndarray>, <Future at 0x7f2f3625aac0 state=finished returned ndarray>, <Future at 0x7f2f364a2b20 state=finished returned ndarray>, <Future at 0x7f2f3625ab20 state=finished returned ndarray>, <Future at 0x7f2f362acb50 state=finished returned ndarray>, <Future at 0x7f2f36260bb0 state=finished returned ndarray>, <Future at 0x7f2f362acbe0 state=finished returned ndarray>, <Future at 0x7f2f36262be0 state=finished returned ndarray>, <Future at 0x7f2f36260be0 state=finished returned ndarray>, <Future at 0x7f2f36262c10 state=finished returned ndarray>, <Future at 0x7f2f36260c10 state=finished returned ndarray>, <Future at 0x7f2f362a6c70 state=finished returned ndarray>, <Future at 0x7f2f362acca0 state=finished returned ndarray>, <Future at 0x7f2f36262cd0 state=finished returned ndarray>, <Future at 0x7f2f36260d00 state=finished returned ndarray>, <Future at 0x7f2f58182d30 state=finished returned ndarray>, <Future at 0x7f2f36262d30 state=finished returned ndarray>, <Future at 0x7f2f36262d90 state=finished returned ndarray>, <Future at 0x7f3031764df0 state=finished returned ndarray>, <Future at 0x7f2f3625ae20 state=finished returned ndarray>, <Future at 0x7f2f362a8e80 state=finished returned ndarray>, <Future at 0x7f2f3625ae80 state=finished returned ndarray>, <Future at 0x7f2f36262eb0 state=finished returned ndarray>, <Future at 0x7f2f3625aee0 state=finished returned ndarray>, <Future at 0x7f2f362a8fa0 state=finished returned ndarray>, <Future at 0x7f2f365a6fa0 state=finished returned ndarray>, <Future at 0x7f2f36257040 state=finished returned ndarray>, <Future at 0x7f2f4b5c10a0 state=finished returned ndarray>, <Future at 0x7f2f3625d0d0 state=finished returned ndarray>, <Future at 0x7f2f362bb130 state=finished returned ndarray>, <Future at 0x7f2f4b54f220 state=finished returned ndarray>, <Future at 0x7f2f362bb220 state=finished returned ndarray>, <Future at 0x7f2f3629f2b0 state=finished returned ndarray>, <Future at 0x7f2f362572e0 state=finished returned ndarray>, <Future at 0x7f2f3625d310 state=finished returned ndarray>, <Future at 0x7f2f36257370 state=finished returned ndarray>, <Future at 0x7f2f362a7430 state=finished returned ndarray>, <Future at 0x7f2f3625d4f0 state=finished returned ndarray>, <Future at 0x7f2f3625d5e0 state=finished returned ndarray>, <Future at 0x7f2f3625d610 state=finished returned ndarray>, <Future at 0x7f2f3629f700 state=finished returned ndarray>, <Future at 0x7f2f36257730 state=finished returned ndarray>, <Future at 0x7f2f36257820 state=finished returned ndarray>, <Future at 0x7f2f362bb850 state=finished returned ndarray>, <Future at 0x7f2f36257880 state=finished returned ndarray>, <Future at 0x7f2f3625d8b0 state=finished returned ndarray>, <Future at 0x7f2f363038e0 state=finished returned ndarray>, <Future at 0x7f2f36257970 state=finished returned ndarray>, <Future at 0x7f2f3625d9d0 state=finished returned ndarray>, <Future at 0x7f2f3625da30 state=finished returned ndarray>, <Future at 0x7f2f362bba60 state=finished returned ndarray>, <Future at 0x7f2f36257a60 state=finished returned ndarray>, <Future at 0x7f2f4b599b20 state=finished returned ndarray>, <Future at 0x7f2f362a7b20 state=finished returned ndarray>, <Future at 0x7f2f362b3b20 state=finished returned ndarray>, <Future at 0x7f2f3625dc10 state=finished returned ndarray>, <Future at 0x7f2f362bbc40 state=finished returned ndarray>, <Future at 0x7f2f36257d60 state=finished returned ndarray>, <Future at 0x7f2f3625de20 state=finished returned ndarray>, <Future at 0x7f2f362a7eb0 state=finished returned ndarray>, <Future at 0x7f2f3625deb0 state=finished returned ndarray>, <Future at 0x7f2f362a7ee0 state=finished returned ndarray>, <Future at 0x7f2f36257f10 state=finished returned ndarray>, <Future at 0x7f2f4b5b9f70 state=finished returned ndarray>, <Future at 0x7f2f3629ffd0 state=finished returned ndarray>}, not_done=set())"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "from concurrent.futures import wait, ALL_COMPLETED\n",
    "from fracdiff import fdiff\n",
    "\n",
    "cores = int(len(os.sched_getaffinity(0)))\n",
    "\n",
    "def getDifferenced(i):\n",
    "    #v = d[[i]]\n",
    "    #gquant_gpu, weights = frac_diff(all_data.iloc[:, i], d=d[[i]], floor=5e-5)\n",
    "    \n",
    "    a = np.array(out.result.iloc[:, i])\n",
    "    \n",
    "    return fdiff(a, n=d[i], axis=0)\n",
    "    #gquant_gpu, weights = frac_diff(all_data.iloc[:, i]), d=v, floor=5e-5)\n",
    "\n",
    "pool01 = concurrent.futures.ProcessPoolExecutor(cores)\n",
    "\n",
    "futures01 = [pool01.submit(getDifferenced, args) for args in range(0,len(d))]\n",
    "\n",
    "wait(futures01, timeout=None, return_when=ALL_COMPLETED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "acbfa758-3cf3-4410-bfc6-85105b37a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Differenced_Set = pd.DataFrame()\n",
    "for f in range(0,len(futures01)):\n",
    "    value = pd.DataFrame(futures01[f].result())\n",
    "    Differenced_Set = pd.concat([Differenced_Set,value],axis=1)\n",
    "    \n",
    "Differenced_Set.columns = out.result.columns\n",
    "Differenced_Set.index = out.result.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0e2820-110a-4786-9035-98543c301b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for f in range(0,len(futures01)):\n",
    "        #print(f)\n",
    "        #print(len(futures01[f].result()))\n",
    "        plt.hist(Differenced_Set.iloc[:,f], bins='auto')  # arguments are passed to np.histogram\n",
    "        plt.show()\n",
    "        Differenced_Set.iloc[:,1].plot()\n",
    "        plt.show()\n",
    "        plt.hist(all_data.iloc[:,f], bins='auto')  # arguments are passed to np.histogram\n",
    "        plt.show()\n",
    "        all_data.iloc[:,1].plot()\n",
    "        plt.show()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce862ad-f7fc-4f0b-b376-c29d32d01281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b6b7d-d0c5-4077-b822-d79e626067b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d49f670-bbdb-42a8-b9e3-e75e1b60e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = out.result.corr()\n",
    "#.abs()\n",
    "s = c.unstack()\n",
    "so = s.sort_values(kind=\"quicksort\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0016982-6857-424e-868a-da44b16ff66b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece4be0-8244-434e-b66e-9c1f39a7c2c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4a92b7-e5b3-49ed-b31f-5959f90e8fca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "def critical_r(n, alpha = .05 ):\n",
    "    df = n - 2\n",
    "    critical_t = scipy.stats.t.isf(alpha / 2, df)\n",
    "    critical_r = np.sqrt( (critical.t^2) / ( (critical.t^2) + df ) )\n",
    "    return(critical_r)\n",
    "\n",
    "def xcorr(x, y, maxlags=10):\n",
    "    Nx = len(x)\n",
    "    if Nx != len(y):\n",
    "        raise ValueError('x and y must be equal length')\n",
    "\n",
    "    c = np.correlate(x, y, mode=2)\n",
    "\n",
    "    if maxlags is None:\n",
    "        maxlags = Nx - 1\n",
    "\n",
    "    if maxlags >= Nx or maxlags < 1:\n",
    "        raise ValueError('maxlags must be None or strictly positive < %d' % Nx)\n",
    "\n",
    "    c = c[Nx - 1 - maxlags:Nx + maxlags]\n",
    "\n",
    "    return c\n",
    "\n",
    "def getLagged_Set(set_, og):\n",
    "\n",
    "    #set_.index = all_data.index\n",
    "\n",
    "    maxl = 5\n",
    "    Lagged_Differenced_Set = pd.DataFrame()\n",
    "    Lagged_Set = pd.DataFrame()\n",
    "    #TrainO_Lagged_Set = pd.DataFrame()\n",
    "    lags = []\n",
    "    lagcorrs = []\n",
    "    ogcorrs = []\n",
    "\n",
    "    for f in range(1,len(set_.columns)):\n",
    "        #print(f)\n",
    "        #print(len(futures01[f].result()))\n",
    "\n",
    "        data_1 = set_.iloc[:,0]\n",
    "        data_2 = set_.iloc[:,f]\n",
    "\n",
    "        ogc = np.array(pd.concat([data_1 - np.mean(data_1),data_2 - np.mean(data_2)],axis=1).corr())[1,0]    \n",
    "        ogcorrs.append(ogc)\n",
    "\n",
    "        #corr = xcorr(data_1 - np.mean(data_1), data_2 - np.mean(data_2),maxlags=5)\n",
    "\n",
    "        set1 = data_1 - np.mean(data_1)\n",
    "        set2 = data_2 - np.mean(data_2)\n",
    "\n",
    "        corrs_ = []\n",
    "        for i in range(0,maxl):\n",
    "            c = np.array((pd.concat([set1,set2.shift(i)],axis=1).dropna()).corr())[0,1]\n",
    "            corrs_.append(c)\n",
    "\n",
    "        #corr = np.correlate(data_1 - np.mean(data_1), data_2 - np.mean(data_2),mode='full')\n",
    "        #plt.plot(corr)\n",
    "        #plt.show()\n",
    "\n",
    "        #lag = corr.argmax() - (len(data_1) - 1)\n",
    "        lag = abs(pd.Series(corrs_)).idxmax()\n",
    "\n",
    "        #print(corr)\n",
    "        lagc = np.array(pd.concat([data_1 - np.mean(data_1),(data_2 - np.mean(data_2)).shift(lag)],axis=1).corr())[1,0]\n",
    "\n",
    "        #print(lag)\n",
    "\n",
    "        #print(ogc)\n",
    "        #print(lagc)\n",
    "\n",
    "        #print(lag)\n",
    "        #plt.plot(data_1, 'r*')\n",
    "        #plt.plot(data_2, 'b*')\n",
    "\n",
    "        lag_merged = pd.concat([data_1 - np.mean(data_1),(data_2 - np.mean(data_2)).shift(lag)],axis=1)\n",
    "\n",
    "        x_ticks = all_data.index[np.arange(0, len(all_data.index), 5)]\n",
    "        #plt.xticks(x_ticks, rotation = 45)    \n",
    "        #plt.show()\n",
    "\n",
    "        #plt.scatter(data_2.shift(lag),data_1)\n",
    "        #plt.show()\n",
    "\n",
    "        #plot_acf(data_2.shift(lag))\n",
    "        #plt.show()\n",
    "\n",
    "        #plot_pacf(data_2.shift(lag))\n",
    "        #plt.show()\n",
    "\n",
    "        y = data_1\n",
    "        X = data_2\n",
    "        #reg = LinearRegression().fit(X, y)\n",
    "\n",
    "        #print(reg.score(X, y),reg.coef_,reg.intercept_)\n",
    "\n",
    "        model = sm.OLS(y,X)\n",
    "        results = model.fit()\n",
    "        #print(results.summary())\n",
    "\n",
    "        Lagged_Differenced_Set = pd.concat([Lagged_Differenced_Set,data_2.shift(lag)],axis=1)\n",
    "        #TrainO_Lagged_Set = pd.concat([TrainO_Lagged_Set,all_data.iloc[:,f].shift(lag)],axis=1)\n",
    "        #if lag>0:\n",
    "            #lag = 0\n",
    "\n",
    "        Lagged_Set = pd.concat([Lagged_Set,og.iloc[:,f].shift(lag)],axis=1)\n",
    "\n",
    "        lagcorrs.append(lagc)\n",
    "\n",
    "        lags.append(lag)\n",
    "\n",
    "    stats = pd.concat([pd.DataFrame(set_.columns[1:]),pd.DataFrame(lags),pd.DataFrame(lagcorrs),pd.DataFrame(ogcorrs)],axis=1)\n",
    "        \n",
    "    return stats, pd.concat([data_1,Lagged_Set],axis=1),  pd.concat([data_1,Lagged_Differenced_Set],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3e80173c-962f-4b0e-b170-8186d5f9b635",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lagged_Set = pd.DataFrame()\n",
    "Lagged_Differenced_Set = pd.DataFrame()\n",
    "\n",
    "ls_stats, Lagged_Set, Lagged_Differenced_Set = getLagged_Set(Differenced_Set, out.result)\n",
    "lso_stats, Lagged_Set_offset, p = getLagged_Set(pd.concat([Differenced_Set.iloc[:,0].shift(-1),Differenced_Set.iloc[:,1:]],axis=1), out.result)\n",
    "                \n",
    "Lagged_Set_offset.dropna(inplace= True)\n",
    "\n",
    "Lagged_Differenced_Set.dropna(inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "29c83e18-ed0b-446d-89a3-86ea42e5672c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^SP500TR</th>\n",
       "      <th>DGS10</th>\n",
       "      <th>DTB3</th>\n",
       "      <th>DGS3MO</th>\n",
       "      <th>MORTGAGE30US</th>\n",
       "      <th>DFII10</th>\n",
       "      <th>T5YIFR</th>\n",
       "      <th>BAMLHYH0A0HYM2TRIV</th>\n",
       "      <th>BAMLCC0A1AAATRIV</th>\n",
       "      <th>DGS1</th>\n",
       "      <th>...</th>\n",
       "      <th>MRK</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NKE</th>\n",
       "      <th>PG</th>\n",
       "      <th>TRV</th>\n",
       "      <th>UNH</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WMT</th>\n",
       "      <th>WBA</th>\n",
       "      <th>DIS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-12-31</th>\n",
       "      <td>0.029813</td>\n",
       "      <td>-0.209582</td>\n",
       "      <td>-0.143322</td>\n",
       "      <td>-0.196890</td>\n",
       "      <td>-0.238385</td>\n",
       "      <td>-0.146843</td>\n",
       "      <td>0.071432</td>\n",
       "      <td>0.014314</td>\n",
       "      <td>-0.064610</td>\n",
       "      <td>-0.080019</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.419629</td>\n",
       "      <td>0.038491</td>\n",
       "      <td>0.280214</td>\n",
       "      <td>0.022363</td>\n",
       "      <td>-0.417227</td>\n",
       "      <td>0.488772</td>\n",
       "      <td>0.046662</td>\n",
       "      <td>0.063807</td>\n",
       "      <td>-0.084918</td>\n",
       "      <td>-0.425913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-31</th>\n",
       "      <td>-0.003927</td>\n",
       "      <td>-0.094569</td>\n",
       "      <td>-0.063216</td>\n",
       "      <td>-0.092153</td>\n",
       "      <td>-0.176987</td>\n",
       "      <td>0.018920</td>\n",
       "      <td>-0.058079</td>\n",
       "      <td>-0.078306</td>\n",
       "      <td>-0.095842</td>\n",
       "      <td>-0.143484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114315</td>\n",
       "      <td>0.044313</td>\n",
       "      <td>-0.169209</td>\n",
       "      <td>-0.005276</td>\n",
       "      <td>-0.049315</td>\n",
       "      <td>0.066219</td>\n",
       "      <td>-0.502920</td>\n",
       "      <td>-0.168305</td>\n",
       "      <td>-0.043674</td>\n",
       "      <td>-0.035121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-06-30</th>\n",
       "      <td>0.040415</td>\n",
       "      <td>0.034497</td>\n",
       "      <td>0.175482</td>\n",
       "      <td>0.174566</td>\n",
       "      <td>0.074665</td>\n",
       "      <td>-0.039422</td>\n",
       "      <td>-0.028531</td>\n",
       "      <td>-0.183151</td>\n",
       "      <td>-0.034573</td>\n",
       "      <td>0.534713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104362</td>\n",
       "      <td>-0.244349</td>\n",
       "      <td>-0.306826</td>\n",
       "      <td>-0.001629</td>\n",
       "      <td>-0.226610</td>\n",
       "      <td>0.006567</td>\n",
       "      <td>-0.037643</td>\n",
       "      <td>-0.385707</td>\n",
       "      <td>0.057429</td>\n",
       "      <td>-0.337017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-30</th>\n",
       "      <td>0.009843</td>\n",
       "      <td>-0.116746</td>\n",
       "      <td>0.417131</td>\n",
       "      <td>0.441517</td>\n",
       "      <td>-0.123821</td>\n",
       "      <td>0.106593</td>\n",
       "      <td>0.017749</td>\n",
       "      <td>0.111420</td>\n",
       "      <td>-0.057027</td>\n",
       "      <td>0.127960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119629</td>\n",
       "      <td>-0.107946</td>\n",
       "      <td>0.035736</td>\n",
       "      <td>0.021776</td>\n",
       "      <td>-0.496634</td>\n",
       "      <td>-0.025885</td>\n",
       "      <td>-0.134964</td>\n",
       "      <td>0.100708</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>-0.272541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-31</th>\n",
       "      <td>0.048335</td>\n",
       "      <td>0.012751</td>\n",
       "      <td>0.357139</td>\n",
       "      <td>0.360686</td>\n",
       "      <td>-0.083115</td>\n",
       "      <td>0.139952</td>\n",
       "      <td>-0.026122</td>\n",
       "      <td>-0.152739</td>\n",
       "      <td>-0.092185</td>\n",
       "      <td>0.177989</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004691</td>\n",
       "      <td>0.174493</td>\n",
       "      <td>0.109139</td>\n",
       "      <td>0.012636</td>\n",
       "      <td>0.165258</td>\n",
       "      <td>0.245652</td>\n",
       "      <td>-0.307749</td>\n",
       "      <td>0.087371</td>\n",
       "      <td>0.164231</td>\n",
       "      <td>0.589502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>-0.004005</td>\n",
       "      <td>-0.551885</td>\n",
       "      <td>0.127970</td>\n",
       "      <td>0.127001</td>\n",
       "      <td>0.066825</td>\n",
       "      <td>-8.529080</td>\n",
       "      <td>-0.021766</td>\n",
       "      <td>-0.006429</td>\n",
       "      <td>-0.080974</td>\n",
       "      <td>0.067255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027259</td>\n",
       "      <td>0.019542</td>\n",
       "      <td>0.326357</td>\n",
       "      <td>0.115950</td>\n",
       "      <td>-0.102080</td>\n",
       "      <td>0.464894</td>\n",
       "      <td>0.193353</td>\n",
       "      <td>-0.001888</td>\n",
       "      <td>-0.173549</td>\n",
       "      <td>-0.070563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31</th>\n",
       "      <td>-0.035486</td>\n",
       "      <td>0.498149</td>\n",
       "      <td>-0.000396</td>\n",
       "      <td>-0.015396</td>\n",
       "      <td>-0.184049</td>\n",
       "      <td>-5.188405</td>\n",
       "      <td>-0.056763</td>\n",
       "      <td>-0.125250</td>\n",
       "      <td>0.039167</td>\n",
       "      <td>-0.105110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055179</td>\n",
       "      <td>0.030804</td>\n",
       "      <td>-0.226553</td>\n",
       "      <td>0.042054</td>\n",
       "      <td>0.209116</td>\n",
       "      <td>0.053867</td>\n",
       "      <td>-0.300709</td>\n",
       "      <td>-0.242613</td>\n",
       "      <td>-0.299459</td>\n",
       "      <td>-0.143466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-30</th>\n",
       "      <td>0.137470</td>\n",
       "      <td>-0.664078</td>\n",
       "      <td>-0.077253</td>\n",
       "      <td>-0.097197</td>\n",
       "      <td>-0.143067</td>\n",
       "      <td>2.416002</td>\n",
       "      <td>-0.042915</td>\n",
       "      <td>-0.221372</td>\n",
       "      <td>0.117749</td>\n",
       "      <td>-0.174665</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046507</td>\n",
       "      <td>0.222298</td>\n",
       "      <td>-0.079000</td>\n",
       "      <td>-0.013429</td>\n",
       "      <td>0.545097</td>\n",
       "      <td>0.036271</td>\n",
       "      <td>0.017509</td>\n",
       "      <td>0.324998</td>\n",
       "      <td>0.088858</td>\n",
       "      <td>0.914602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-30</th>\n",
       "      <td>0.075139</td>\n",
       "      <td>-2.894166</td>\n",
       "      <td>-0.208416</td>\n",
       "      <td>-0.244525</td>\n",
       "      <td>-0.139473</td>\n",
       "      <td>0.742130</td>\n",
       "      <td>-0.104181</td>\n",
       "      <td>0.625756</td>\n",
       "      <td>0.020280</td>\n",
       "      <td>-0.272824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>0.104864</td>\n",
       "      <td>0.756145</td>\n",
       "      <td>-0.022134</td>\n",
       "      <td>-0.070802</td>\n",
       "      <td>0.176244</td>\n",
       "      <td>0.245615</td>\n",
       "      <td>0.164708</td>\n",
       "      <td>0.151925</td>\n",
       "      <td>-0.096800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>0.091881</td>\n",
       "      <td>-0.662843</td>\n",
       "      <td>-0.292731</td>\n",
       "      <td>-0.345182</td>\n",
       "      <td>0.094026</td>\n",
       "      <td>-0.103203</td>\n",
       "      <td>-0.057047</td>\n",
       "      <td>0.031575</td>\n",
       "      <td>-0.124713</td>\n",
       "      <td>-0.199931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027301</td>\n",
       "      <td>0.269657</td>\n",
       "      <td>0.508836</td>\n",
       "      <td>0.145954</td>\n",
       "      <td>-0.406186</td>\n",
       "      <td>0.182110</td>\n",
       "      <td>0.046098</td>\n",
       "      <td>0.149416</td>\n",
       "      <td>-0.160600</td>\n",
       "      <td>-0.116222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ^SP500TR     DGS10      DTB3    DGS3MO  MORTGAGE30US    DFII10  \\\n",
       "2004-12-31  0.029813 -0.209582 -0.143322 -0.196890     -0.238385 -0.146843   \n",
       "2005-03-31 -0.003927 -0.094569 -0.063216 -0.092153     -0.176987  0.018920   \n",
       "2005-06-30  0.040415  0.034497  0.175482  0.174566      0.074665 -0.039422   \n",
       "2005-09-30  0.009843 -0.116746  0.417131  0.441517     -0.123821  0.106593   \n",
       "2005-12-31  0.048335  0.012751  0.357139  0.360686     -0.083115  0.139952   \n",
       "...              ...       ...       ...       ...           ...       ...   \n",
       "2019-12-31 -0.004005 -0.551885  0.127970  0.127001      0.066825 -8.529080   \n",
       "2020-03-31 -0.035486  0.498149 -0.000396 -0.015396     -0.184049 -5.188405   \n",
       "2020-06-30  0.137470 -0.664078 -0.077253 -0.097197     -0.143067  2.416002   \n",
       "2020-09-30  0.075139 -2.894166 -0.208416 -0.244525     -0.139473  0.742130   \n",
       "2020-12-31  0.091881 -0.662843 -0.292731 -0.345182      0.094026 -0.103203   \n",
       "\n",
       "              T5YIFR  BAMLHYH0A0HYM2TRIV  BAMLCC0A1AAATRIV      DGS1  ...  \\\n",
       "2004-12-31  0.071432            0.014314         -0.064610 -0.080019  ...   \n",
       "2005-03-31 -0.058079           -0.078306         -0.095842 -0.143484  ...   \n",
       "2005-06-30 -0.028531           -0.183151         -0.034573  0.534713  ...   \n",
       "2005-09-30  0.017749            0.111420         -0.057027  0.127960  ...   \n",
       "2005-12-31 -0.026122           -0.152739         -0.092185  0.177989  ...   \n",
       "...              ...                 ...               ...       ...  ...   \n",
       "2019-12-31 -0.021766           -0.006429         -0.080974  0.067255  ...   \n",
       "2020-03-31 -0.056763           -0.125250          0.039167 -0.105110  ...   \n",
       "2020-06-30 -0.042915           -0.221372          0.117749 -0.174665  ...   \n",
       "2020-09-30 -0.104181            0.625756          0.020280 -0.272824  ...   \n",
       "2020-12-31 -0.057047            0.031575         -0.124713 -0.199931  ...   \n",
       "\n",
       "                 MRK      MSFT       NKE        PG       TRV       UNH  \\\n",
       "2004-12-31 -0.419629  0.038491  0.280214  0.022363 -0.417227  0.488772   \n",
       "2005-03-31  0.114315  0.044313 -0.169209 -0.005276 -0.049315  0.066219   \n",
       "2005-06-30  0.104362 -0.244349 -0.306826 -0.001629 -0.226610  0.006567   \n",
       "2005-09-30 -0.119629 -0.107946  0.035736  0.021776 -0.496634 -0.025885   \n",
       "2005-12-31 -0.004691  0.174493  0.109139  0.012636  0.165258  0.245652   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2019-12-31  0.027259  0.019542  0.326357  0.115950 -0.102080  0.464894   \n",
       "2020-03-31 -0.055179  0.030804 -0.226553  0.042054  0.209116  0.053867   \n",
       "2020-06-30 -0.046507  0.222298 -0.079000 -0.013429  0.545097  0.036271   \n",
       "2020-09-30  0.061538  0.104864  0.756145 -0.022134 -0.070802  0.176244   \n",
       "2020-12-31 -0.027301  0.269657  0.508836  0.145954 -0.406186  0.182110   \n",
       "\n",
       "                  VZ       WMT       WBA       DIS  \n",
       "2004-12-31  0.046662  0.063807 -0.084918 -0.425913  \n",
       "2005-03-31 -0.502920 -0.168305 -0.043674 -0.035121  \n",
       "2005-06-30 -0.037643 -0.385707  0.057429 -0.337017  \n",
       "2005-09-30 -0.134964  0.100708  0.007481 -0.272541  \n",
       "2005-12-31 -0.307749  0.087371  0.164231  0.589502  \n",
       "...              ...       ...       ...       ...  \n",
       "2019-12-31  0.193353 -0.001888 -0.173549 -0.070563  \n",
       "2020-03-31 -0.300709 -0.242613 -0.299459 -0.143466  \n",
       "2020-06-30  0.017509  0.324998  0.088858  0.914602  \n",
       "2020-09-30  0.245615  0.164708  0.151925 -0.096800  \n",
       "2020-12-31  0.046098  0.149416 -0.160600 -0.116222  \n",
       "\n",
       "[65 rows x 91 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.DataFrame()\n",
    "temp = pd.concat([out.result.iloc[:,0].pct_change().shift(-1),Lagged_Differenced_Set_offset.iloc[:,1:].pct_change()],axis=1).copy().dropna()\n",
    "Lagged_Differenced_Set_offset = pd.DataFrame()\n",
    "Lagged_Differenced_Set_offset = temp.copy()\n",
    "Lagged_Differenced_Set.dropna(inplace= True)\n",
    "Lagged_Differenced_Set_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfbc252-b567-48e9-86f9-9e57df0ac45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ls_stats)\n",
    "print(lso_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aa28e7-3712-466f-96fd-7bbf115714ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb40926-6979-4f9f-ad09-ed1f93c25a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed, lambdas = transform_boxcox(Lagged_Differenced_Set.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1422b2e-d8e4-43aa-a691-8c54392a6291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Difference (only if not using differenced)\n",
    "#transformed = (transformed - transformed.shift(-1)).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c72722f-fbff-4bff-92b8-26b19888e415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "8cc90237-f851-4afb-86f8-2dca0b41123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbd = True\n",
    "ic = True\n",
    "\n",
    "# evaluate an elastic net model on the dataset\n",
    "tsize = .20\n",
    "train, test = train_test_split(Lagged_Differenced_Set_offset.iloc[:,0:], test_size=tsize, shuffle=False)\n",
    "\n",
    "interaction = PolynomialFeatures(degree=2, include_bias=False, interaction_only=ic)\n",
    "\n",
    "#train_t, lambdas_t = transform_boxcox(train)\n",
    "\n",
    "#disabled boxcox\n",
    "if cbd:\n",
    "    train_t = train\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(train_t)\n",
    "\n",
    "#\n",
    "train_s = pd.DataFrame(scaler.transform(train_t))\n",
    "train_s.columns = train.columns\n",
    "train_s.index = train.index  \n",
    "\n",
    "train_t = train_s\n",
    "\n",
    "#test_t = transform_boxcox_l(test, lambdas_t)\n",
    "\n",
    "#disabled boxcox\n",
    "if cbd:\n",
    "    test_t = test\n",
    "\n",
    "test_s = pd.DataFrame(scaler.transform(test_t))\n",
    "test_s.columns = test.columns\n",
    "test_s.index = test.index\n",
    "\n",
    "test_t = test_s\n",
    "\n",
    "y_train = pd.DataFrame(train_t.iloc[:,0])\n",
    "\n",
    "#exclude y\n",
    "\n",
    "X_inter_train = pd.DataFrame(interaction.fit_transform(train_t.iloc[:,1:]), columns=interaction.get_feature_names(input_features=pd.DataFrame(train_t.iloc[:,1:]).columns))\n",
    "\n",
    "    #apply ZCA each time a set of factors are removed (i.e. iteratively)\n",
    " #trf = zca.ZCA().fit(X_inter_train)\n",
    "  #trf = zca.ZCA().fit(X_train)\n",
    "\n",
    " #X_train = pd.DataFrame(trf.transform(X_inter_train))\n",
    "  #X_train = pd.DataFrame(trf.transform(X_train))\n",
    " #X_train.columns=X_inter_train.columns\n",
    "  #X_train.columns=X_train.columns\n",
    "  #X_train.index = train.index\n",
    "\n",
    "#X_inter_alt = X_train.iloc[:, np.array(range(0,len(all_data.iloc[:,2:].columns)))]\n",
    "#print(X_inter_alt.head(3))\n",
    "\n",
    "y_test = pd.DataFrame(test_t.iloc[:,0])\n",
    "\n",
    "X_inter_test = pd.DataFrame(interaction.fit_transform(test_t.iloc[:,1:]), columns=interaction.get_feature_names(input_features=pd.DataFrame(test_t.iloc[:,1:]).columns))\n",
    "\n",
    " #X_test = pd.DataFrame(trf.transform(X_inter_test))\n",
    "  #X_test = pd.DataFrame(trf.transform(X_test))\n",
    "\n",
    " #X_test.columns=X_inter_test.columns\n",
    "  #X_test.columns=X_test.columns\n",
    "  #X_test.index = test.index\n",
    "\n",
    "#X_inter_t_alt = X_test.iloc[:, np.array(range(0,len(all_data.iloc[:,2:].columns)))]\n",
    "#X_inter_t_alt.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "edcf46d0-1162-46d6-a166-0461b321e0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: -0.682\n",
      "Config: {'alpha': 10.0, 'l1_ratio': 0.17}\n",
      "ElasticNet(alpha=10.0, l1_ratio=0.17)\n"
     ]
    }
   ],
   "source": [
    "# define model evaluation method\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define model\n",
    "ratios = arange(0, 1, 0.01)\n",
    "alphas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.0, 1.0, 10.0, 100.0]\n",
    "\n",
    " #model = ElasticNetCV(l1_ratio=ratios, alphas=alphas, cv=cv, n_jobs=4, verbose=0, precompute='auto')\n",
    "\n",
    "model = ElasticNet()\n",
    "grid = dict()\n",
    "# fit model\n",
    "\n",
    "grid['alpha'] = alphas\n",
    "grid['l1_ratio'] = ratios\n",
    "\n",
    "#search = HalvingRandomSearchCV(model, grid,resource='n_samples',max_resources=10,random_state=0)\n",
    "\n",
    "search = GridSearchCV(model, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    " #results = search.fit(X_inter_train, y_train)\n",
    "#results = search.fit(X_train, y_train)\n",
    "\n",
    "results = search.fit(X_inter_train, y_train)\n",
    "\n",
    " #model.fit(X_inter_train, y_train)\n",
    "# summarize chosen configuration\n",
    "\n",
    "print('MAE: %.3f' % results.best_score_)\n",
    "print('Config: %s' % results.best_params_)\n",
    "\n",
    "print(results.best_estimator_)\n",
    "best_model = ElasticNet(alpha=results.best_estimator_.alpha, l1_ratio = results.best_estimator_.l1_ratio)\n",
    "\n",
    "#pd.concat([all_data[Y],all_data_int],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "3ebb7965-c50b-4f1e-bd5e-05504a69192f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "-0.07670119860984714\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_inter_train,train_t.iloc[:,0])\n",
    "\n",
    "trainScore = best_model.score(X_inter_train, y_train, sample_weight=None)\n",
    "testScore = best_model.score(X_inter_test, y_test, sample_weight=None)\n",
    "print(trainScore)\n",
    "print(testScore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb694fa2-0e07-4a01-8648-2d6615a70b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "093a64f9-522d-4761-adf1-f55d566a1b70",
   "metadata": {},
   "source": [
    "pd.DataFrame(best_model.predict(X_inter_test))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "922b12fd-2b69-4243-909a-6f828aa43b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-12-31</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-31</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-06-30</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-30</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-31</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-31</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-06-30</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-09-30</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-31</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-03-31</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-06-30</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-30</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-31</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-31</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-06-30</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-09-30</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-12-31</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-03-31</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-30</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-09-30</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-12-31</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-09-30</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-31</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-03-31</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-30</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-30</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-31</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-31</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-30</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-31</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-09-30</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-31</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-31</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-30</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "2004-12-31  1\n",
       "2005-03-31  0\n",
       "2005-06-30  1\n",
       "2005-09-30  1\n",
       "2005-12-31  1\n",
       "2006-03-31  1\n",
       "2006-06-30  1\n",
       "2006-09-30  1\n",
       "2006-12-31  1\n",
       "2007-03-31  1\n",
       "2007-06-30  0\n",
       "2007-09-30  1\n",
       "2007-12-31  0\n",
       "2008-03-31  1\n",
       "2008-06-30  0\n",
       "2008-09-30  0\n",
       "2008-12-31  0\n",
       "2009-03-31  1\n",
       "2009-06-30  1\n",
       "2009-09-30  1\n",
       "2009-12-31  1\n",
       "2010-03-31  1\n",
       "2010-06-30  0\n",
       "2010-09-30  1\n",
       "2010-12-31  1\n",
       "2011-03-31  1\n",
       "2011-06-30  0\n",
       "2011-09-30  1\n",
       "2011-12-31  1\n",
       "2012-03-31  1\n",
       "2012-06-30  1\n",
       "2012-09-30  1\n",
       "2012-12-31  1\n",
       "2013-03-31  1\n",
       "2013-06-30  1\n",
       "2013-09-30  1\n",
       "2013-12-31  1\n",
       "2014-03-31  1\n",
       "2014-06-30  1"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "0e86999a-16ba-4505-b5ec-843d219ac62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "14400790-a56a-4084-8c56-cf73697546e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82 accuracy with a standard deviation of 0.16\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "interaction = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import random\n",
    "\n",
    "#pd.DataFrame(Lagged_Set.iloc[:,0].shift(-1)).hist()\n",
    "#Lagged_Differenced_Set = (all_data - all_data.shift(-1)).dropna()\n",
    "#Lagged_Differenced_Set_f = pd.concat([Lagged_Differenced_Set.iloc[:,0].shift(-1),Lagged_Differenced_Set.iloc[:,1:]],axis=1)\n",
    "\n",
    "set_ = pd.DataFrame()\n",
    "set_ = Lagged_Differenced_Set_offset.copy()\n",
    "\n",
    "X, y = set_.iloc[:,1:],  set_.iloc[:,0]\n",
    "\n",
    "y = pd.DataFrame(np.where(y > 0, 1, 0))\n",
    "y.index = set_.index\n",
    "\n",
    "train_size = .7\n",
    "test_size = 1-train_size\n",
    "\n",
    "#test_I = random.sample(list(X.index), int(np.round(test_size*len(X))))\n",
    "#train_I set(test_I) ! set()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, shuffle=False)\n",
    "#df.sample(frac=0.5, replace=True, random_state=1)\n",
    "#class balance\n",
    "one = y_train[y_train==0].dropna().sample(len(X_train), replace=True, random_state=1)\n",
    "two = y_train[y_train==1].dropna().sample(len(X_train), replace=True, random_state=1)\n",
    "train_index = []\n",
    "train_index = np.append(one.index,two.index)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train.loc[train_index])\n",
    "\n",
    "X_train_transformed = pd.DataFrame(scaler.transform(X_train.loc[train_index]))\n",
    "X_train_transformed.columns = X_train.columns\n",
    "\n",
    "X_inter_train = X_train_transformed\n",
    "\n",
    "#X_inter_train = pd.DataFrame(interaction.fit_transform(X_train_transformed), columns=interaction.get_feature_names(input_features=pd.DataFrame(X_train_transformed).columns))\n",
    "\n",
    "#trf = zca.ZCA().fit(X_inter_train)\n",
    "\n",
    "#X_inter_train = pd.DataFrame(trf.transform(X_inter_train))\n",
    "#X_inter_train.columns=pd.DataFrame(X_inter_train).columns\n",
    "#X_inter_train.index = X_train.index\n",
    "\n",
    "clf = svm.SVC(kernel='sigmoid', C=1, random_state=42)\n",
    "\n",
    "scores = cross_val_score(clf, X_inter_train, y_train.loc[train_index], cv=10)\n",
    "\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "clf = svm.SVC(C=1).fit(X_inter_train, y_train.loc[train_index])\n",
    "\n",
    "X_test_transformed = pd.DataFrame(scaler.transform(X_test))\n",
    "X_test_transformed.columns = X_test.columns\n",
    "X_test_transformed.index = X_test.index\n",
    "\n",
    "X_inter_test = X_test_transformed\n",
    "\n",
    "#X_inter_test = pd.DataFrame(interaction.fit_transform(X_test_transformed), columns=interaction.get_feature_names(input_features=pd.DataFrame(X_test_transformed).columns))\n",
    "\n",
    "#X_inter_test = pd.DataFrame(trf.transform(X_inter_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "7672895b-f442-45b4-8cb1-3257e8c830a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-0.7337521644115618, pvalue=0.46583921573122944)"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "a = set_.iloc[:,0].loc[X_train.index]\n",
    "b = set_.iloc[:,0].loc[X_test.index]\n",
    "plt.hist(a)\n",
    "plt.show()\n",
    "plt.hist(b)\n",
    "plt.show()\n",
    "stats.ttest_ind(a,b, equal_var = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "644b63d8-9f6e-453e-b896-0ee262d1242e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['2004-12-31', '2005-03-31', '2005-06-30', '2005-09-30', '2005-12-31',\n",
       "       '2006-03-31', '2006-06-30', '2006-09-30', '2006-12-31', '2007-03-31',\n",
       "       '2007-06-30', '2007-09-30', '2007-12-31', '2008-03-31', '2008-06-30',\n",
       "       '2008-09-30', '2008-12-31', '2009-03-31', '2009-06-30', '2009-09-30',\n",
       "       '2009-12-31', '2010-03-31', '2010-06-30', '2010-09-30', '2010-12-31',\n",
       "       '2011-03-31', '2011-06-30', '2011-09-30', '2011-12-31', '2012-03-31',\n",
       "       '2012-06-30', '2012-09-30', '2012-12-31', '2013-03-31', '2013-06-30',\n",
       "       '2013-09-30', '2013-12-31', '2014-03-31', '2014-06-30'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "e560215f-9b7d-4d76-ac61-dbf96d2cfd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "predicted = clf.predict(X_inter_test)\n",
    "#predicted.index = y_test.index\n",
    "\n",
    "clf.score(X_inter_test, y_test)\n",
    "\n",
    "#clf.predict(X_test)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "6ce0671f-8931-4f7e-936b-51adcb52dab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 3}\n",
      "0.7964285714285715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7692307692307693"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV#create new a knn model\n",
    "knn2 = KNeighborsClassifier(metric='euclidean',weights='distance')#create a dictionary of all values we want to test for n_neighbors\n",
    "param_grid = {'n_neighbors': np.arange(1, 25)}#use gridsearch to test all values for n_neighbors\n",
    "knn_gscv = GridSearchCV(knn2, param_grid, cv=5)#fit model to data\n",
    "knn_gscv.fit(X_inter_train, y_train)\n",
    "#check top performing n_neighbors value\n",
    "print(knn_gscv.best_params_)\n",
    "#check mean score for the top performing value of n_neighbors\n",
    "print(knn_gscv.best_score_)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = knn_gscv.best_params_['n_neighbors'],metric='euclidean',weights='distance')\n",
    "knn.fit(X_inter_train,y_train)\n",
    "knn.predict(X_inter_test)\n",
    "knn.score(X_inter_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43107e46-54bb-4837-a798-af32efaccadb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "e55c7caf-0c3b-4911-ba58-8313a7ba85ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.000\n",
      "Config: {'alpha': 0.01668100537200059, 'l1_ratio': 0.08}\n"
     ]
    }
   ],
   "source": [
    "#logistic\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
    "# define model\n",
    "ratios = arange(0, 1, 0.01)\n",
    "alphas = (10 ** np.linspace(-1, 1, 10))/10\n",
    "alphas = np.append(alphas,[10.0, 100.0])\n",
    "\n",
    "model = SGDClassifier(loss=\"log\", penalty=\"elasticnet\")\n",
    "grid = dict()\n",
    "# fit model\n",
    "\n",
    "grid['alpha'] = alphas\n",
    "grid['l1_ratio'] = ratios\n",
    "\n",
    "search_l = GridSearchCV(model, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "results_l = search_l.fit(X_inter_train, y_train.loc[train_index])\n",
    "\n",
    " #model.fit(X_inter_train, y_train)\n",
    "# summarize chosen configuration\n",
    "\n",
    "print('MAE: %.3f' % results_l.best_score_)\n",
    "print('Config: %s' % results_l.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4b9087-fe22-4d54-b152-a40e48784774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "7015d3fd-f35c-4f6c-b8e9-f66c92514715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.01668100537200059, l1_ratio=0.08, loss='log',\n",
      "              penalty='elasticnet')\n",
      "                     0\n",
      "DGS10        -0.247222\n",
      "DTB3         -0.079110\n",
      "DGS3MO       -0.194978\n",
      "MORTGAGE30US  0.044664\n",
      "DFII10       -0.553962\n",
      "...                ...\n",
      "UNH           0.410737\n",
      "VZ            0.581737\n",
      "WMT           0.170714\n",
      "WBA           0.103710\n",
      "DIS          -0.106363\n",
      "\n",
      "[90 rows x 1 columns]\n",
      "1.0\n",
      "0.7307692307692307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1])"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "print(results_l.best_estimator_)\n",
    "best_model_l = SGDClassifier(alpha=results_l.best_estimator_.alpha, l1_ratio = results_l.best_estimator_.l1_ratio)\n",
    "\n",
    "#calibrator = CalibratedClassifierCV(best_model_l, cv='prefit')\n",
    "#model=calibrator.fit(X_inter_train, y_train)\n",
    "\n",
    "best_model_l.fit(X_inter_train,y_train.loc[train_index])\n",
    "\n",
    "#sgd = SGDClassifier()\n",
    "\n",
    "#sgd.partial_fit(X_inter_train,y_train, classes=[0,1])\n",
    "\n",
    "print(pd.DataFrame(np.transpose(best_model_l.coef_)).set_index(X_inter_train.columns))\n",
    "\n",
    "trainScore_l = best_model_l.score(X_inter_train, y_train.loc[train_index], sample_weight=None)\n",
    "testScore_l = best_model_l.score(X_inter_test, y_test, sample_weight=None)\n",
    "print(trainScore_l)\n",
    "print(testScore_l)\n",
    "\n",
    "#print(help(KNeighborsClassifier))\n",
    "best_model_l.predict(X_inter_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dd1212-7817-4f74-95d6-0493d68c9658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4dfc37-ab80-427f-bc37-edb9a212c4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate output multi-step 1d cnn example\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Dense, SimpleRNN, GRU, LSTM\n",
    "from keras.optimizers import SGD\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Lagged_Differenced_Set = (all_data - all_data.shift(-1)).dropna()\n",
    "\n",
    "def plot_learning_curves(loss, val_loss):\n",
    "    plt.plot(np.arange(len(loss)) + 0.5, loss, \"b.\", label=\"Training loss\")\n",
    "    plt.plot(np.arange(len(val_loss)) + 1, val_loss, \"r-\", label=\"Validation loss\")\n",
    "    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out, xcolumns, ycolumns):\n",
    "    \n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, xcolumns], sequences[end_ix:out_end_ix, ycolumns]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    \n",
    "    return array(X), array(y)\n",
    "\n",
    "#n_steps_in = int(np.floor(len(train)*.8))\n",
    "print(len(Lagged_Differenced_Set))\n",
    "n_steps_in = int(np.round(len(Lagged_Differenced_Set)/2))\n",
    "print(len(Lagged_Differenced_Set) - n_steps_in)\n",
    "print(n_steps_in)\n",
    "#n_steps_out = int(len(train)-n_steps_in)\n",
    "n_steps_out = 1\n",
    "print(n_steps_out)\n",
    "\n",
    "#ycolumns = range(0,len(transformed.columns))\n",
    "ycolumns = range(0,len(Lagged_Differenced_Set.columns[0:1].values))\n",
    "xcolumns = range(1,len(Lagged_Differenced_Set.columns[1:]))\n",
    "\n",
    "#trainInner, valid = train_test_split(trainOuter, test_size=0.15, shuffle=False)\n",
    "#trainInner_whitened = pd.DataFrame(trf.transform(trainInner.iloc[:,1:])).set_index(trainInner.index)\n",
    "#valid_whitened = pd.DataFrame(trf.transform(valid.iloc[:,1:])).set_index(valid.index)\n",
    "#test_whitened = pd.DataFrame(trf.transform(test.iloc[:,1:])).set_index(test.index)\n",
    "\n",
    "trainOuter_whitened=pd.DataFrame(trf.transform(trainOuter.iloc[:,1:])).set_index(trainOuter.index)\n",
    "\n",
    "X, y = split_sequences(np.array(Lagged_Differenced_Set), n_steps_in, n_steps_out, xcolumns, ycolumns)\n",
    "\n",
    "#for i in range(len(X)):\n",
    "#    print(X[i], y[i])\n",
    "    \n",
    "#flatten output\n",
    "\n",
    "if len(ycolumns) > 0:\n",
    "    n_output = y.shape[1] * y.shape[2]\n",
    "    y = y.reshape((y.shape[0], n_output))\n",
    "\n",
    "n_features = X.shape[2]\n",
    "\n",
    "# define model\n",
    "modelCNN = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.MaxPooling1D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(50, activation='relu'),\n",
    "    keras.layers.Dense(n_output)\n",
    "])\n",
    "\n",
    "# fit model\n",
    "#model.fit(X, y, epochs=7000, verbose=0)\n",
    "\n",
    "epochs_ = 200\n",
    "batch_size_ = 25\n",
    "\n",
    "#np.random.seed(42)\n",
    "#tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "#model.compile(optimizer='adam', loss='mse')\n",
    "modelCNN.compile(loss=\"MAPE\", optimizer=\"rmsprop\",metrics=['MAPE'])\n",
    "\n",
    "#model6.compile(loss=\"MAPE\", optimizer=\"rmsprop\",metrics=['MAPE'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    shuffle = False)\n",
    "                                                    #random_state=42)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "X_train_transformed = pd.DataFrame(scaler.transform(X_train))\n",
    "X_train_transformed.columns = X_train.columns\n",
    "\n",
    "X_test_transformed = pd.DataFrame(scaler.transform(X_test))\n",
    "X_test_transformed.columns = X_test.columns\n",
    "X_test_transformed.index = X_test.index\n",
    "\n",
    "    #new_series = pd.DataFrame(ts_train_scaled).append(pd.DataFrame(ts_valid_scaled)).append(pd.DataFrame(ts_test_scaled))\n",
    "\n",
    "    #series_reshaped = np.array([new_series[i:i + (n_steps+n_ahead)].copy() for i in range(len(data) - (n_steps+n_ahead))])  \n",
    "    \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train,\n",
    "                                                    test_size=0.33,\n",
    "                                                    shuffle = False)\n",
    "                                                    #random_state=42)    \n",
    "\n",
    "#model6.compile(loss=\"MAPE\", optimizer=\"rmsprop\",metrics=['MAPE'])\n",
    "historyCNN = modelCNN.fit(X_train, y_train, epochs=epochs_,batch_size=batch_size_,validation_data=(X_valid, y_valid), verbose=0)\n",
    "#history6 = model6.fit(X_train, y_train, epochs=epochs_,batch_size=batch_size_,validation_data=(X_valid, y_valid), verbose=0)\n",
    "#history = model.fit(X_train, y_train, epochs=epochs_,batch_size=batch_size_,verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8f7e2d-3603-4ba1-8457-4fd9918498a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "plot_learning_curves(historyCNN.history[\"loss\"], history.history[\"val_loss\"])\n",
    "plt.show()\n",
    "#plot_learning_curves(history6.history[\"loss\"], history.history[\"val_loss\"])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799f6d94-9757-4baa-b095-8937fbba5857",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee4c952-450d-43d4-86c1-2a37673a58d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cbc3da-fa1f-4e57-9d84-f4e5f8872af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#multi\n",
    "yhat = modelCNN.predict(X_test, verbose=0)\n",
    "\n",
    "predicted = []\n",
    "original = []\n",
    "if len(ycolumns) > 1:\n",
    "    results = yhat.reshape(len(y_test), int(yhat.shape[1]/X_test.shape[2]), len(transformed.columns))\n",
    "    for i in range(0,len(results)):\n",
    "        predicted.append(pd.DataFrame(results[i])[0][0])\n",
    "        original.append(pd.DataFrame(y_test[i])[0][0])\n",
    "        #print(pd.DataFrame(results[i])[0][0])\n",
    "        #print(pd.DataFrame(y_test[i])[0][0])\n",
    "else:\n",
    "    results = yhat\n",
    "    for i in range(0,len(results)):\n",
    "        predicted.append(results[i])\n",
    "        original.append(y_test[i])\n",
    "        #print(pd.DataFrame(results[i]))\n",
    "        #print(pd.DataFrame(y_test[i]))\n",
    "        \n",
    "plt.scatter(predicted,original)\n",
    "\n",
    "pd.concat([pd.DataFrame(predicted),pd.DataFrame(original)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8229628-eed4-4b76-831d-1de033240347",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.DataFrame(best_model.coef_).set_index(X_inter_train.columns)\n",
    "\n",
    "a_coef = abs(coef)\n",
    "a_coef.sort_values(by=[0],ascending=False,inplace=True)\n",
    "chosen_few = a_coef[a_coef>0].dropna().index.values\n",
    "\n",
    "scaler_ = preprocessing.StandardScaler().fit(transformed)\n",
    "\n",
    "#\n",
    "train_ = pd.DataFrame(scaler_.transform(transformed))\n",
    "train_.columns = transformed.columns\n",
    "train_.index = transformed.index  \n",
    "\n",
    "X_inter_train_ = pd.DataFrame(interaction.fit_transform(train_.iloc[:,1:]), columns=interaction.get_feature_names(input_features=pd.DataFrame(train_.iloc[:,1:]).columns))\n",
    "\n",
    "max_pvalue = 1\n",
    "New_Names = X_inter_train.columns\n",
    "X_b = X_inter_train_[chosen_few]\n",
    "while (max_pvalue > .05):\n",
    "        \n",
    "    trf = zca.ZCA().fit(X_b)\n",
    "        \n",
    "    X_b_z = pd.DataFrame(trf.transform(X_b))\n",
    "    X_b_z.columns=pd.DataFrame(X_b).columns\n",
    "    X_b_z.index = train_.index\n",
    "\n",
    "    model_ = sm.OLS(train_.iloc[:,0],sm.tools.tools.add_constant(X_b_z, prepend=True, has_constant='skip'))        \n",
    "    #model_ = sm.OLS(pd.DataFrame(pd.concat([train_.iloc[:,0],X_b_z],axis=1),sm.tools.tools.add_constant(X_b_z, prepend=True, has_constant='skip'))        \n",
    "    results_ = model_.fit()\n",
    "\n",
    "    set_ = X_b.columns.tolist()\n",
    "    \n",
    "    max_pvalue = max(results_.pvalues[1:])\n",
    "    if (max_pvalue > .05):\n",
    "        print(max_pvalue)\n",
    "        max_pname = (results_.pvalues[1:]).idxmax(axis=1)\n",
    "        set_.remove(max_pname)\n",
    "        New_Names = set_\n",
    "    \n",
    "        X_b = X_inter_train_[New_Names]\n",
    "        X_b.index = X_inter_train_.index\n",
    "\n",
    "#from statsmodels.formula.api import ols\n",
    "#lm = ols(pd.DataFrame(train_.iloc[:,0]) ~ sm.tools.tools.add_constant(X_b_z, prepend=True, has_constant='skip')).fit()\n",
    "#table = sm.stats.anova_lm(model_, type=3)\n",
    "#print(table)\n",
    "print(results_.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35e428c-cce9-46e3-b145-754fc9e4c576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findNaNCols(df_):\n",
    "    for col in df_:        \n",
    "        num_NaNs = df_[col].isnull().sum()\n",
    "        if num_NaNs > 0:\n",
    "            print(f\"Column: {col}\")\n",
    "            print(f\"Number of NaNs: {num_NaNs}\")\n",
    "\n",
    "findNaNCols(X_b_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d4e220-4ac2-4945-9e3a-4b8ff1355a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d940860-86d6-4768-81a0-63f9127143a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linear_plot = Plot.LinearRegressionResidualPlot(X_b_z, pd.DataFrame(train_.iloc[:,0]))\n",
    "lm = linear_plot.fit()\n",
    "summary, diag_res = linear_plot.diagnostic_plots(lm)\n",
    "print(\"Summary of Regression\\n:{}\".format(summary))\n",
    "print(\"Diagnostic Tests of Regression\\n:{}\".format(diag_res))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#sns.pairplot(pd.concat([pd.DataFrame(train[Y]),X_b_z],axis=1), hue=Y, height=2);\n",
    "\n",
    "pd.concat([pd.DataFrame(train[Y]),X_b_z],axis=1).hist()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "model_s = sklearn.linear_model.LinearRegression()\n",
    "model_s.fit(X_b_z, pd.DataFrame(train_[Y]))\n",
    "\n",
    "shap.initjs()\n",
    "e = shap.explainers.Linear(model_s, X_b_z)\n",
    "\n",
    "shap_values = e.shap_values(X_b_z)\n",
    "shap.summary_plot(shap_values, X_b_z)\n",
    "shap.plots.heatmap(e(X_b_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53b64b8-ca00-46d1-ba16-91f3adb00065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4871c2-4418-491a-8e5c-5776d42e4381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f\n",
    "\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "residuals_normalized = lm.get_influence().resid_studentized_internal\n",
    "cooks = lm.get_influence().cooks_distance[0]\n",
    "cooks = np.round(f.pdf(cooks,len(lm.tvalues)+1, len(lm.fittedvalues)-len(lm.tvalues)-1),2)\n",
    "\n",
    "res_std = lm.get_influence().resid_std\n",
    "\n",
    "leverage = lm.get_influence().hat_matrix_diag\n",
    "\n",
    "plt.hist(pd.DataFrame(leverage))\n",
    "plt.show()\n",
    "\n",
    "plt.hist(pd.DataFrame(cooks))\n",
    "plt.show()\n",
    "\n",
    "plt.hist(pd.DataFrame(residuals_normalized))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "testNormal(residuals_normalized)\n",
    "\n",
    "w = res_std\n",
    "x = cooks\n",
    "y = leverage\n",
    "z = residuals_normalized\n",
    "\n",
    "fitted_y = lm.fittedvalues\n",
    "\n",
    "labels_ = fitted_y.index\n",
    "\n",
    "outlier_check = pd.concat([pd.DataFrame(x),pd.DataFrame(y),pd.DataFrame(z),pd.DataFrame(w)],axis=1).set_index(labels_)\n",
    "\n",
    "outlier_check.columns =  ['cooks', 'leverage', 'tsres', 'sres']\n",
    "\n",
    "qq = ProbPlot(residuals_normalized)\n",
    "\n",
    "c_thresh = .1\n",
    "l_thresh = (2*(len(lm.tvalues)-1)/len(lm.fittedvalues))\n",
    "s_thresh = max(qq.theoretical_quantiles)\n",
    "\n",
    "print(\"Outlier threshold's\")\n",
    "print(\"Cooks distance: > .1+\")\n",
    "print(\"Leverage: > \" + str(l_thresh) + \" to \" + str(3 * (len(lm.tvalues)-1)/len(fitted_y)))\n",
    "print(\"Studentized residuals: > \" + str(s_thresh))\n",
    "print()\n",
    "\n",
    "flag = []\n",
    "\n",
    "for i in range(0,len(outlier_check)):\n",
    "    if( (outlier_check.iloc[i][0] >= c_thresh) or (outlier_check.iloc[i][1] >= l_thresh) or (abs(outlier_check.iloc[i][2]) >= s_thresh) ):\n",
    "        print(outlier_check.iloc[i])\n",
    "        print()\n",
    "        flag.append(True)\n",
    "    else:\n",
    "        flag.append(False)\n",
    "\n",
    "outlier_check = pd.concat([outlier_check,pd.DataFrame(flag).set_index(labels_)],axis=1)\n",
    "\n",
    "outlier_check.columns =  ['cooks', 'leverage', 'tsres', 'sres', 'flagged']\n",
    "\n",
    "print(np.flip(np.argsort(cooks), 0))\n",
    "#print(outlier_check)\n",
    "\n",
    "search = outlier_check[outlier_check['flagged']==1].index.to_list()\n",
    "\n",
    "rows = []\n",
    "\n",
    "for i in search:\n",
    "    v = outlier_check.index.to_list().index(i)\n",
    "    rows.append(v)\n",
    "\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b2b196-7761-4420-a145-a5411053a625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_style(row):\n",
    "\n",
    "    color = 'white'\n",
    "    if bool(row.flagged) == True:\n",
    "        color = 'orange'\n",
    "\n",
    "    return ['background-color: %s' % color]*len(row.values)\n",
    "\n",
    "all_data[set(all_data.columns) & set(New_Names)]\n",
    "\n",
    "outlier_check.style.apply(custom_style, axis=1).apply(custom_style, axis=1).background_gradient(cmap ='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da39b86-0ac2-4470-9457-8e999918d47c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6b8430-ac88-4358-88c1-e6c5400fe7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = y_train.columns.to_list()\n",
    "df2 = list(set(set(all_data.columns) & set(New_Names)))\n",
    "\n",
    "flattened = [] \n",
    "for sublist in df1,df2: \n",
    "    for val in sublist: \n",
    "        flattened.append(val) \n",
    "\n",
    "all_data.iloc[rows][flattened].style.background_gradient(cmap ='viridis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
