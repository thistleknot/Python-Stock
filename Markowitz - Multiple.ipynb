{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "91d47de7-c2b8-4db0-a0d9-f3e1d4f8c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/analytics-vidhya/modern-portfolio-theory-model-implementation-in-python-e416facabf46\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple\n",
    "from functools import cache # Python 3.9 required\n",
    "from IPython.display import display\n",
    "import yfinance as yf\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 12, 9\n",
    "\n",
    "TRADING_DAYS_PER_YEAR = 252.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c6bfef16-5a7f-4ad6-aa04-1cb16f49a0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-29\n",
      "2003-06-21\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import concurrent\n",
    "import pandas_datareader.data as web\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import concurrent.futures\n",
    "from concurrent.futures import wait, ALL_COMPLETED\n",
    "import urllib\n",
    "import urllib.request\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "from ipywidgets import interactive\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "frequency = \"D\"\n",
    "\n",
    "w=117*8\n",
    "end_date = datetime.date.today()\n",
    "\n",
    "start_date = end_date - timedelta(weeks=w)\n",
    "\n",
    "pd.set_option('display.max_columns', None) #replace n with the number of columns you want to see completely\n",
    "pd.set_option('display.max_rows', None) #replace n with the number of rows you want to see completely\n",
    "\n",
    "cores = int(len(os.sched_getaffinity(0)))\n",
    "\n",
    "print(end_date)\n",
    "print(start_date)\n",
    "\n",
    "FRED_Indicators = ['DTB4WK','DTB3']\n",
    "\n",
    "def Fred_Data(name):\n",
    "    temp = web.DataReader(str(name), 'fred', start_date, end_date)\n",
    "    temp.index = pd.to_datetime(temp.index)\n",
    "    temp = temp.resample(frequency).mean().dropna()\n",
    "    return(temp)\n",
    "\n",
    "FRED_set = []\n",
    "FRED_completed = []\n",
    "for i in FRED_Indicators:\n",
    "    FRED_completed.append(i)\n",
    "    FRED_set.append(Fred_Data(i))\n",
    "\n",
    "\n",
    "FRED_pvt = pd.DataFrame()\n",
    "\n",
    "for x in range(0,len(FRED_completed)):\n",
    "    values = FRED_set[x]\n",
    "    #values.index = pd.to_datetime(FRED_set[\"DATE\"])\n",
    "    #values = values.resample(frequency).mean().dropna()\n",
    "    #values['Symbol'] = x\n",
    "    values = values.loc[~values.index.duplicated(keep='last')]\n",
    "    #values = values.reset_index()\n",
    "\n",
    "    FRED_pvt = pd.concat([FRED_pvt,values], axis=1)\n",
    "\n",
    "etf_indexes_and_Crypto_list = ['^SP500TR']\n",
    "\n",
    "commodities = []\n",
    "for sublist in [etf_indexes_and_Crypto_list]:\n",
    "    for val in sublist:\n",
    "        commodities.append(val)\n",
    "\n",
    "#pool2 = concurrent.futures.ProcessPoolExecutor(cores)\n",
    "\n",
    "completed = []\n",
    "def dl(name):\n",
    "    subset = yf.download(name, start=start_date, end=end_date, auto_adjust=True).iloc[:, :6].dropna(axis=0, how='any')\n",
    "    subset = subset[start_date.strftime('%Y-%m-%d'):end_date.strftime('%Y-%m-%d')]\n",
    "    #sleep(4)\n",
    "    if len(subset) != 0:\n",
    "        completed.append(name)\n",
    "        return (subset)\n",
    "\n",
    "futures2 = []\n",
    "\n",
    "for i in commodities:\n",
    "    futures2.append(dl(i))\n",
    "\n",
    "commodities_ = pd.DataFrame()\n",
    "\n",
    "for x in range(0,len(completed)):\n",
    "    values = futures2[x]\n",
    "    values.index = pd.to_datetime(values.index)\n",
    "    #values = values.resample(frequency).mean().dropna()\n",
    "    values['Symbol'] = x\n",
    "    values = values.loc[~values.index.duplicated(keep='last')]\n",
    "    values = values.reset_index()\n",
    "\n",
    "    commodities_ = pd.concat([commodities_,values], axis=0)\n",
    "\n",
    "commodities_pvt = pd.pivot_table(commodities_, values='Close', index=['Date'],columns=['Symbol'])\n",
    "commodities_pvt.columns = completed\n",
    "#commodities_pvt.to_csv(\"/mnt/distvol/commodities.csv\")\n",
    "\n",
    "def Fred_Data(name):\n",
    "    temp = web.DataReader(str(name), 'fred', start_date, end_date)\n",
    "    temp.index = pd.to_datetime(temp.index)\n",
    "    #temp = temp.resample(frequency).mean().dropna()\n",
    "    return(temp)\n",
    "\n",
    "FRED_set = []\n",
    "FRED_completed = []\n",
    "for i in FRED_Indicators:\n",
    "    FRED_completed.append(i)\n",
    "    FRED_set.append(Fred_Data(i))\n",
    "\n",
    "combined_set = pd.concat([FRED_pvt.set_index(FRED_pvt.index),commodities_pvt],axis=1)\n",
    "\n",
    "if True:\n",
    "    combined_set = combined_set.interpolate(method='linear', limit_direction='forward', axis=0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec85e0bc-07ec-47b0-805c-9a778f2f9266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "da4f8b46-5604-4067-971e-4253010e27c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TREASURY_BILL_RATE =  combined_set['DTB3'].values[-1]\n",
    "beatSP500 = pd.DataFrame(combined_set['^SP500TR']).resample('Y').mean().pct_change().dropna()\n",
    "#combined_set['^SP500TR'].pct_change[-1]\n",
    "#%, Jan 2021\n",
    "#FRED_pvt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4cf9f72e-aac8-471c-8ef3-aba02709ee1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "^SP500TR   0.10651\n",
       "dtype: float64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beatSP500.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "99d24b27-ade1-44fe-a86b-852aade3503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed for type hinting\n",
    "class Asset:\n",
    "  pass\n",
    "\n",
    "\n",
    "def get_log_period_returns(price_history: pd.DataFrame):\n",
    "  close = price_history['Close'] \n",
    "  return pd.DataFrame(close).pct_change().dropna().values.reshape(-1, 1)\n",
    "    #np.log(close[1:] / close[:-1]).reshape(-1, 1)\n",
    "\n",
    "\n",
    "# daily_price_history has to at least have a column, called 'Close'\n",
    "class Asset:\n",
    "  def __init__(self, name: str, daily_price_history: pd.DataFrame):\n",
    "    self.name = name\n",
    "    self.daily_returns = get_log_period_returns(daily_price_history)\n",
    "    self.expected_daily_return = np.mean(self.daily_returns)\n",
    "  \n",
    "  @property\n",
    "  def expected_return(self):\n",
    "    return TRADING_DAYS_PER_YEAR * self.expected_daily_return\n",
    "\n",
    "  def __repr__(self):\n",
    "    return f'<Asset name={self.name}, expected return={self.expected_return}>'\n",
    "\n",
    "  @staticmethod\n",
    "  @cache\n",
    "  def covariance_matrix(assets: Tuple[Asset]):  # tuple for hashing in the cache\n",
    "    product_expectation = np.zeros((len(assets), len(assets)))\n",
    "    for i in range(len(assets)):\n",
    "      for j in range(len(assets)):\n",
    "        if i == j:\n",
    "          product_expectation[i][j] = np.mean(assets[i].daily_returns * assets[j].daily_returns)\n",
    "        else:\n",
    "          product_expectation[i][j] = np.mean(assets[i].daily_returns @ assets[j].daily_returns.T)\n",
    "    \n",
    "    product_expectation *= (TRADING_DAYS_PER_YEAR - 1) ** 2\n",
    "\n",
    "    expected_returns = np.array([asset.expected_return for asset in assets]).reshape(-1, 1)\n",
    "    product_of_expectations = expected_returns @ expected_returns.T\n",
    "\n",
    "    return product_expectation - product_of_expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dad431-1643-49b1-a0e1-cb9ba0721545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "120eea19-219e-4d01-93f0-2b3752549a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_weights(weight_count):\n",
    "    weights = np.random.random((weight_count, 1))\n",
    "    weights /= np.sum(weights)\n",
    "    return weights.reshape(-1, 1)\n",
    "\n",
    "\n",
    "class Portfolio:\n",
    "  def __init__(self, assets: Tuple[Asset]):\n",
    "    self.assets = assets\n",
    "    self.asset_expected_returns = np.array([asset.expected_return for asset in assets]).reshape(-1, 1)\n",
    "    self.covariance_matrix = Asset.covariance_matrix(assets)\n",
    "    self.weights = random_weights(len(assets))\n",
    "    \n",
    "  def unsafe_optimize_with_risk_tolerance(self, risk_tolerance: float):\n",
    "    res = minimize(\n",
    "      lambda w: self._variance(w) - risk_tolerance * self._expected_return(w),\n",
    "      random_weights(self.weights.size),\n",
    "      constraints=[\n",
    "        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
    "      ],\n",
    "      bounds=[(0., 1.) for i in range(self.weights.size)]\n",
    "    )\n",
    "\n",
    "    assert res.success, f'Optimization failed: {res.message}'\n",
    "    self.weights = res.x.reshape(-1, 1)\n",
    "  \n",
    "  def optimize_with_risk_tolerance(self, risk_tolerance: float):\n",
    "    assert risk_tolerance >= 0.\n",
    "    return self.unsafe_optimize_with_risk_tolerance(risk_tolerance)\n",
    "  \n",
    "  def optimize_with_expected_return(self, expected_portfolio_return: float):\n",
    "    res = minimize(\n",
    "      lambda w: self._variance(w),\n",
    "      random_weights(self.weights.size),\n",
    "      constraints=[\n",
    "        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
    "        {'type': 'eq', 'fun': lambda w: self._expected_return(w) - expected_portfolio_return},\n",
    "      ],\n",
    "      bounds=[(0., 1.) for i in range(self.weights.size)]\n",
    "    )\n",
    "\n",
    "    assert res.success, f'Optimization failed: {res.message}'\n",
    "    self.weights = res.x.reshape(-1, 1)\n",
    "\n",
    "  def optimize_sharpe_ratio(self):\n",
    "    # Maximize Sharpe ratio = minimize minus Sharpe ratio\n",
    "    res = minimize(\n",
    "      lambda w: -(self._expected_return(w) - TREASURY_BILL_RATE / 100) / np.sqrt(self._variance(w)),\n",
    "      random_weights(self.weights.size),\n",
    "      constraints=[\n",
    "        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
    "      ],\n",
    "      bounds=[(0., 1.) for i in range(self.weights.size)]\n",
    "    )\n",
    "\n",
    "    assert res.success, f'Optimization failed: {res.message}'\n",
    "    self.weights = res.x.reshape(-1, 1)\n",
    "\n",
    "  def _expected_return(self, w):\n",
    "    return (self.asset_expected_returns.T @ w.reshape(-1, 1))[0][0]\n",
    "  \n",
    "  def _variance(self, w):\n",
    "    return (w.reshape(-1, 1).T @ self.covariance_matrix @ w.reshape(-1, 1))[0][0]\n",
    "\n",
    "  @property\n",
    "  def expected_return(self):\n",
    "    return self._expected_return(self.weights)\n",
    "  \n",
    "  @property\n",
    "  def variance(self):\n",
    "    return self._variance(self.weights)\n",
    "\n",
    "  def __repr__(self):\n",
    "    return f'<Portfolio assets={[asset.name for asset in self.assets]}, expected return={self.expected_return}, variance={self.variance}>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "69317d88-81a1-4903-8a40-dbe9a2b0ed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yf_retrieve_data(tickers: List[str],p):\n",
    "  dataframes = []\n",
    "\n",
    "  for ticker_name in tickers:\n",
    "    ticker = yf.Ticker(ticker_name)\n",
    "    history = ticker.history(period=p,auto_adjust=True)\n",
    "\n",
    "    if history.isnull().any(axis=1).iloc[0]:  # the first row can have NaNs\n",
    "      history = history.iloc[1:]\n",
    "  \n",
    "    assert not history.isnull().any(axis=None), f'history has NaNs in {ticker_name}'\n",
    "    dataframes.append(history)\n",
    "  \n",
    "  return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "57c327e7-1fb8-4651-87bb-d55bf68245fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file exists\n",
      "Last Modified Time :  Sat May 29 10:08:12 2021\n",
      "equal dates, not redownloading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/pandas/core/strings.py:1954: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas_market_calendars as mcal\n",
    "import os.path\n",
    "from os import path\n",
    "import stat\n",
    "import re\n",
    "\n",
    "def unique(list1):\n",
    " \n",
    "    # intilize a null list\n",
    "    unique_list = []\n",
    "     \n",
    "    # traverse for all elements\n",
    "    for x in list1:\n",
    "        # check if exists in unique_list or not\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)\n",
    "\n",
    "    return(unique_list)\n",
    "\n",
    "pd.set_option('display.max_columns', None) #replace n with the number of columns you want to see completely\n",
    "pd.set_option('display.max_rows', None) #replace n with the number of rows you want to see completely\n",
    "\n",
    "cores = int(len(os.sched_getaffinity(0)))\n",
    "\n",
    "pool1 = concurrent.futures.ProcessPoolExecutor(cores)\n",
    "\n",
    "one_week_end = start_date\n",
    "one_week_start = one_week_end - timedelta(weeks=1)\n",
    "\n",
    "#need to do the two pass trick (i.e. find stocks fully populated a week 9 quarters back)\n",
    "\n",
    "nyse = mcal.get_calendar('NYSE')\n",
    "official_trading_dates= nyse.schedule(start_date=start_date, end_date=end_date)\n",
    "\n",
    "date_time_obj_start = start_date\n",
    "\n",
    "date_time_obj_end = end_date\n",
    "\n",
    "one_week_trading_dates = nyse.schedule(start_date=one_week_start, end_date=one_week_end)\n",
    "\n",
    "url = 'ftp://ftp.nasdaqtrader.com/symboldirectory/nasdaqtraded.txt'\n",
    "\n",
    "#should turn this into a function\n",
    "if path.exists(\"nasdaqtraded.txt\"):\n",
    "    print(\"file exists\")\n",
    "    \n",
    "    filePath = 'nasdaqtraded.txt'\n",
    "    fileStatsObj = os.stat ( filePath )\n",
    "    modificationTime = time.ctime ( fileStatsObj [ stat.ST_MTIME ] )\n",
    "\n",
    "    print(\"Last Modified Time : \", modificationTime )\n",
    "\n",
    "    a = datetime.datetime.strptime(modificationTime, \"%a %b %d %H:%M:%S %Y\")\n",
    "\n",
    "    if a.date() != datetime.date.today():\n",
    "        print(\"not same dates downloading\")\n",
    "        urllib.request.urlretrieve(url, 'nasdaqtraded.txt')\n",
    "        urllib.request.urlretrieve(url, 'mfundslist.txt')\n",
    "        urllib.request.urlretrieve(url, 'bonds.txt')\n",
    "    else:\n",
    "      print(\"equal dates, not redownloading\")\n",
    "    \n",
    "else:\n",
    "    print(\"downloading nasdaqtraded.txt\")\n",
    "    urllib.request.urlretrieve(url, 'nasdaqtraded.txt')\n",
    "    urllib.request.urlretrieve(url, 'mfundslist.txt')\n",
    "    urllib.request.urlretrieve(url, 'bonds.txt')\n",
    "    \n",
    "df1 = pd.read_csv('nasdaqtraded.txt', sep='|')[0:-1]\n",
    "df2 = pd.read_csv('mfundslist.txt', sep='|')[0:-1]\n",
    "df3 = pd.read_csv('bonds.txt', sep='|')[0:-1]\n",
    "\n",
    "#process symbols for bad characters\n",
    "BAD_CHARS = ['$','.']\n",
    "pat = '|'.join(['({})'.format(re.escape(c)) for c in BAD_CHARS])\n",
    "\n",
    "df1 = df1[~df1['Symbol'].str.contains(pat)]\n",
    "df2 = df2[~df2['Symbol'].str.contains(pat)]\n",
    "df3 = df3[~df3['Symbol'].str.contains(pat)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e4583315-90d5-47ae-9a12-abf4881f3984",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#choose size\n",
    "size=100\n",
    "#stocks = list(df1[\"Symbol\"].sample(n=int(size/3)))\n",
    "stocks = list(df1[\"Symbol\"].sample(n=int(size)))\n",
    "mfunds = list(df2[\"Symbol\"].sample(n=int(size/3)))\n",
    "bonds = list(df3[\"Symbol\"].sample(n=int(size/3)))\n",
    "#symbols = unique(stocks + mfunds + bonds)\n",
    "symbols = unique(stocks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5dbff656-da38-41b2-ad85-978e0ef514b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data exists\n",
      "Last Modified Time :  Fri May 28 20:36:09 2021\n",
      "not same dates downloading stocks\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- PCOM: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- ADEX: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- PPTY: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- KCAC: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- GMTA: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- EMHC: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CVCO: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "[*********************100%***********************]  1 of 1 completed- URTH: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "\n",
      "\n",
      "1 Failed download:\n",
      "- XBIOW: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "[*********************100%***********************]  1 of 1 completed6168000\n",
      "\n",
      "\n",
      "1 Failed download:\n",
      "\n",
      "\n",
      "1 Failed download:- FOREW: No data found for this date range, symbol may be delisted\n",
      "\n",
      "- TAK: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- FSM: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- IDYA: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- TPGY: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- FJNK: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- FMHI: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- MOO: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- FPA: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- PI: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- NUVB: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- RICE: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- HZON: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- OXBRW: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- GUNR: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "- KDFI: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "1 Failed download:\n",
      "\n",
      "- BIOX: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "- GPJA: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- PRT: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- ROM: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- IDEX: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- KRNT: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- PMVP: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- UJB: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- DIVS: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- IACA: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- PDBC: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed- OCSL: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "\n",
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "\n",
      "- ESSA: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "\n",
      "- EEH: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "\n",
      "- LHCG: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "1 Failed download:\n",
      "\n",
      "- NMZ: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- FEYE: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- FTCH: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- TLGA: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- HGLB: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- LINX: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- PEJ: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- ANEW: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- LJPC: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- EBND: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- DLTH: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "[*********************100%***********************]  1 of 1 completed- NMRK: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "\n",
      "\n",
      "1 Failed download:\n",
      "- ONEO: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- GAL: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- ACER: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- FDRR: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- SCVX: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- ITCI: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- BSMR: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "\n",
      "1 Failed download:\n",
      "- VTAQU: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed- FOREU: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "\n",
      "\n",
      "1 Failed download:\n",
      "- JFU: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- TACO: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- WK: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- JMIN: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- ANGO: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- WBII: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "\n",
      "1 Failed download:\n",
      "- LORL: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "\n",
      "- VSTO: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- KRA: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- YOLO: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- HTEC: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- ETWO: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- MEG: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- CNRG: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- GLPI: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- FDMT: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- IEUR: Data doesn't exist for startDate = 1055563200, endDate = 1056168000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def dl_one_week(stock):\n",
    "    subset = yf.download(stock, start=one_week_start, end=one_week_end, auto_adjust=True).iloc[:, :6].dropna(axis=0, how='any')\n",
    "    subset = subset[one_week_start.strftime('%Y-%m-%d'):one_week_end.strftime('%Y-%m-%d')]\n",
    "    if len(subset) != 0:\n",
    "        return (subset)\n",
    "\n",
    "def processStocks(symbols):\n",
    "\n",
    "    futures1 = [pool1.submit(dl_one_week, args) for args in symbols]\n",
    "    wait(futures1, timeout=None, return_when=ALL_COMPLETED)\n",
    "\n",
    "    symbols_data_one_week = pd.DataFrame()\n",
    "\n",
    "    for x in range(0,len(symbols)):\n",
    "        prices = pd.DataFrame(futures1[x].result())\n",
    "        prices['Symbol'] = symbols[x]\n",
    "        prices = prices.loc[~prices.index.duplicated(keep='last')]        \n",
    "        prices = prices.reset_index()\n",
    "\n",
    "        symbols_data_one_week = pd.concat([symbols_data_one_week,prices])\n",
    "\n",
    "    #symbols_data_one_week\n",
    "\n",
    "    #stocks that existed 9 quarters ago\n",
    "    vetted_symbols = list(symbols_data_one_week.Symbol.unique())\n",
    "\n",
    "    return(vetted_symbols)\n",
    "\n",
    "stocks = []\n",
    "\n",
    "if path.exists('symbols_data.csv'):\n",
    "    print(\"data exists\")\n",
    "    \n",
    "    filePath = 'symbols_data.csv'\n",
    "    fileStatsObj = os.stat ( filePath )\n",
    "    modificationTime = time.ctime ( fileStatsObj [ stat.ST_MTIME ] )\n",
    "\n",
    "    print(\"Last Modified Time : \", modificationTime )\n",
    "\n",
    "    a = datetime.datetime.strptime(modificationTime, \"%a %b %d %H:%M:%S %Y\")\n",
    "\n",
    "    if a.date() != datetime.date.today():\n",
    "        print(\"not same dates downloading stocks\")\n",
    "        \n",
    "        stocks = processStocks(symbols)\n",
    "        \n",
    "    else:\n",
    "        print(\"equal dates, not redownloading\")\n",
    "    \n",
    "else:\n",
    "    print(\"downloading symbols\")\n",
    "    stocks = processStocks(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894576f1-ef0d-4abc-8907-a70e0960ad43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "612e2be9-6ba5-4e02-a78a-c3748b13d555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# There are 2 tables on the Wikipedia page\n",
    "# we want the first table\n",
    "\n",
    "payload=pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "first_table = payload[0]\n",
    "second_table = payload[1]\n",
    "\n",
    "sp500 = first_table\n",
    "symbols_sp500 = sp500['Symbol'].values.tolist()\n",
    "\n",
    "\n",
    "payload=pd.read_html('https://en.wikipedia.org/wiki/Nasdaq-100#Components')\n",
    "table = payload[3]\n",
    "\n",
    "ns100 = table\n",
    "symbols_ns100 = ns100['Ticker'].values.tolist()\n",
    "\n",
    "\n",
    "payload=pd.read_html('https://en.wikipedia.org/wiki/S%26P_500_Dividend_Aristocrats#Index')\n",
    "dividendAristocraft = payload[2]['Ticker symbol']\n",
    "\n",
    "payload=pd.read_html('https://finance.yahoo.com/quote/SPY/holdings/')\n",
    "#dividendAristocraft = payload[2]['Ticker symbol']\n",
    "\n",
    "top10 = payload[0]['Symbol']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "01bffde0-8f30-46e0-8ac1-7f5420129b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MTG',\n",
       " 'PEAK',\n",
       " 'CLGX',\n",
       " 'MUR',\n",
       " 'KLAC',\n",
       " 'CMO',\n",
       " 'GIFI',\n",
       " 'BIO',\n",
       " 'FHN',\n",
       " 'IHC',\n",
       " 'HD',\n",
       " 'RDNT',\n",
       " 'IEV',\n",
       " 'CMT',\n",
       " 'HOG',\n",
       " 'SID',\n",
       " 'PEO',\n",
       " 'O',\n",
       " 'ARTW',\n",
       " 'CYBE',\n",
       " 'AMGN']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "e79ddd4e-d400-438f-b1f8-f6d6a10caa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AAPL', 'MSFT', 'AMZN', 'FB', 'GOOGL', 'GOOG', 'TSLA', 'BRK-B', 'JPM', 'JNJ']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks = top10\n",
    "\n",
    "#BAD_CHARS = ['$','.']\n",
    "#pat = '|'.join(['({})'.format(re.escape(c)) for c in BAD_CHARS])\n",
    "\n",
    "cleaned = []\n",
    "for i in range(0,len(stocks)):\n",
    "    print(i)\n",
    "    cleaned.append(stocks[i].replace('.','-'))\n",
    "    \n",
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd50ac12-8a14-4fef-908a-9620cb5614d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ^SP500TR\n",
      "2004-12-31   0.11642\n",
      "2005-12-31   0.08700\n",
      "2006-12-31   0.10609\n",
      "2007-12-31   0.14816\n",
      "2008-12-31  -0.15755\n",
      "2009-12-31  -0.20105\n",
      "2010-12-31   0.22730\n",
      "2011-12-31   0.13395\n",
      "2012-12-31   0.11270\n",
      "2013-12-31   0.21881\n",
      "2014-12-31   0.19953\n",
      "2015-12-31   0.08904\n",
      "2016-12-31   0.03901\n",
      "2017-12-31   0.19383\n",
      "2018-12-31   0.14305\n",
      "2019-12-31   0.08271\n",
      "2020-12-31   0.12636\n",
      "2021-12-31   0.25186\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p = '10y'\n",
    "r = beatSP500.values[-1]*1.25\n",
    "print(beatSP500)\n",
    "daily_dataframes = yf_retrieve_data(cleaned, p)\n",
    "assets = tuple([Asset(name, daily_df) for name, daily_df in zip(stocks, daily_dataframes)])\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Drawing random portfolios\n",
    "for i in range(3000):\n",
    "  portfolio = Portfolio(assets)\n",
    "  X.append(np.sqrt(portfolio.variance))\n",
    "  y.append(portfolio.expected_return)\n",
    "\n",
    "plt.scatter(X, y, label='Random portfolios')\n",
    "\n",
    "# Drawing the efficient frontier\n",
    "X = []\n",
    "y = []\n",
    "for rt in np.linspace(-300, 200, 1000):\n",
    "  portfolio.unsafe_optimize_with_risk_tolerance(rt)\n",
    "  X.append(np.sqrt(portfolio.variance))\n",
    "  y.append(portfolio.expected_return)\n",
    "\n",
    "plt.plot(X, y, 'k', linewidth=3, label='Efficient frontier')\n",
    "\n",
    "# Drawing optimized portfolios\n",
    "portfolio.optimize_with_risk_tolerance(0)\n",
    "plt.plot(np.sqrt(portfolio.variance), portfolio.expected_return, 'm+', markeredgewidth=5, markersize=20, label='optimize_with_risk_tolerance(0)')\n",
    "\n",
    "portfolio.optimize_with_risk_tolerance(20)\n",
    "plt.plot(np.sqrt(portfolio.variance), portfolio.expected_return, 'r+', markeredgewidth=5, markersize=20, label='optimize_with_risk_tolerance(20)')\n",
    "\n",
    "portfolio.optimize_with_expected_return(r)\n",
    "plt.plot(np.sqrt(portfolio.variance), portfolio.expected_return, 'g+', markeredgewidth=5, markersize=20, label='optimize_with_expected_return' + str(np.round(r,2)))\n",
    "\n",
    "portfolio.optimize_sharpe_ratio()\n",
    "plt.plot(np.sqrt(portfolio.variance), portfolio.expected_return, 'y+', markeredgewidth=5, markersize=20, label='optimize_sharpe_ratio()')\n",
    "\n",
    "plt.xlabel('Portfolio standard deviation')\n",
    "plt.ylabel('Portfolio expected return')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8cb2b8-e6a9-4aee-8cce-47568dd3261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = \"{:,.5f}\".format\n",
    "\n",
    "portfolio = Portfolio(assets)\n",
    "portfolio.optimize_with_risk_tolerance(0)\n",
    "riskless_weights = portfolio.weights.flatten()\n",
    "\n",
    "portfolio.optimize_with_risk_tolerance(20)\n",
    "weights_risk_tolerance = portfolio.weights.flatten()\n",
    "\n",
    "portfolio.optimize_with_expected_return(r)\n",
    "weights_return = portfolio.weights.flatten()\n",
    "\n",
    "portfolio.optimize_sharpe_ratio()\n",
    "weights_sharpe = portfolio.weights.flatten()\n",
    "\n",
    "display(\n",
    "  pd.DataFrame(\n",
    "    list(\n",
    "      zip(\n",
    "        [asset.name for asset in portfolio.assets],\n",
    "        riskless_weights,\n",
    "        weights_risk_tolerance,\n",
    "        weights_return,\n",
    "        weights_sharpe,\n",
    "      )\n",
    "    ),\n",
    "    columns=[\n",
    "      'asset',\n",
    "      'optimize_with_risk_tolerance(0)',\n",
    "      'optimize_with_risk_tolerance(20)',\n",
    "      'optimize_with_expected_return' + str(np.round(r,2)),\n",
    "      'optimize_sharpe_ratio()',\n",
    "    ],\n",
    "  ).sort_values(by=['optimize_sharpe_ratio()'],ascending=False)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
