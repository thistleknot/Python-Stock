{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "applied-samuel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numba yfinance pandas datetime cudf numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "spectacular-gamma",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "institutional-atlas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from datetime import date\n",
    "\n",
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "verified-throat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import numba\n",
    "from numba import cuda\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def compute_bin(x, n, xmin, xmax):\n",
    "    # special case to mirror NumPy behavior for last bin\n",
    "    if x == xmax:\n",
    "        return n - 1 # a_max always in last bin\n",
    "\n",
    "    # SPEEDTIP: Remove the float64 casts if you don't need to exactly reproduce NumPy\n",
    "    bin = np.int32(n * (np.float64(x) - np.float64(xmin)) / (np.float64(xmax) - np.float64(xmin)))\n",
    "\n",
    "    if bin < 0 or bin >= n:\n",
    "        return None\n",
    "    else:\n",
    "        return bin\n",
    "\n",
    "@cuda.jit\n",
    "def histogram(x, xmin, xmax, histogram_out):\n",
    "    nbins = histogram_out.shape[0]\n",
    "    bin_width = (xmax - xmin) / nbins\n",
    "\n",
    "    start = cuda.grid(1)\n",
    "    stride = cuda.gridsize(1)\n",
    "\n",
    "    for i in range(start, x.shape[0], stride):\n",
    "        # note that calling a numba.jit function from CUDA automatically\n",
    "        # compiles an equivalent CUDA device function!\n",
    "        bin_number = compute_bin(x[i], nbins, xmin, xmax)\n",
    "\n",
    "        if bin_number >= 0 and bin_number < histogram_out.shape[0]:\n",
    "            cuda.atomic.add(histogram_out, bin_number, 1)\n",
    "\n",
    "@cuda.jit\n",
    "def min_max(x, min_max_array):\n",
    "    nelements = x.shape[0]\n",
    "\n",
    "    start = cuda.grid(1)\n",
    "    stride = cuda.gridsize(1)\n",
    "\n",
    "    # Array already seeded with starting values appropriate for x's dtype\n",
    "    # Not a problem if this array has already been updated\n",
    "    local_min = min_max_array[0]\n",
    "    local_max = min_max_array[1]\n",
    "\n",
    "    for i in range(start, x.shape[0], stride):\n",
    "        element = x[i]\n",
    "        local_min = min(element, local_min)\n",
    "        local_max = max(element, local_max)\n",
    "\n",
    "    # Now combine each thread local min and max\n",
    "    cuda.atomic.min(min_max_array, 0, local_min)\n",
    "    cuda.atomic.max(min_max_array, 1, local_max)\n",
    "\n",
    "\n",
    "def dtype_min_max(dtype):\n",
    "    '''Get the min and max value for a numeric dtype'''\n",
    "    if np.issubdtype(dtype, np.integer):\n",
    "        info = np.iinfo(dtype)\n",
    "    else:\n",
    "        info = np.finfo(dtype)\n",
    "    return info.min, info.max\n",
    "\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def get_bin_edges(a, nbins, a_min, a_max):\n",
    "    bin_edges = np.empty((nbins+1,), dtype=np.float64)\n",
    "    delta = (a_max - a_min) / nbins\n",
    "    for i in range(bin_edges.shape[0]):\n",
    "        bin_edges[i] = a_min + i * delta\n",
    "\n",
    "    bin_edges[-1] = a_max  # Avoid roundoff error on last point\n",
    "    return bin_edges\n",
    "\n",
    "\n",
    "def numba_gpu_histogram(a, bins):\n",
    "    # Move data to GPU so we can do two operations on it\n",
    "    a_gpu = cuda.to_device(a)\n",
    "\n",
    "    ### Find min and max value in array\n",
    "    dtype_min, dtype_max = dtype_min_max(a.dtype)\n",
    "    # Put them in the array in reverse order so that they will be replaced by the first element in the array\n",
    "    min_max_array_gpu = cuda.to_device(np.array([dtype_max, dtype_min], dtype=a.dtype))\n",
    "    min_max[64, 64](a_gpu, min_max_array_gpu)\n",
    "    a_min, a_max = min_max_array_gpu.copy_to_host()\n",
    "\n",
    "    # SPEEDTIP: Skip this step if you don't need to reproduce the NumPy histogram edge array\n",
    "    bin_edges = get_bin_edges(a, bins, a_min, a_max) # Doing this on CPU for now\n",
    "\n",
    "    ### Bin the data into a histogram \n",
    "    histogram_out = cuda.to_device(np.zeros(shape=(bins,), dtype=np.int32))\n",
    "    histogram[64, 64](a_gpu, a_min, a_max, histogram_out)\n",
    "\n",
    "    return histogram_out.copy_to_host(), bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "planned-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_forward = 7\n",
    "name = 'BTC-USD'\n",
    "#name = 'GLD'\n",
    "#name = 'SPY'\n",
    "#name = 'GOOG'\n",
    "\n",
    "#strategy = \"EMA\"\n",
    "strategy = \"SMA\"\n",
    "#indicator = 'Close'\n",
    "indicator = 'VWP'\n",
    "\n",
    "w=117\n",
    "end_date = datetime.date.today()\n",
    "#end_date = datetime.date.today() - timedelta(weeks=w)\n",
    "end_date1 = end_date - timedelta(weeks=w)\n",
    "start_date = end_date1 - timedelta(weeks=w)\n",
    "\n",
    "benchName = \"^GSPC\"\n",
    "bench = yfinance.Ticker(benchName)\n",
    "#bench Data needs to be +1 because it ends the day before end_date\n",
    "\n",
    "benchData = bench.history(interval=\"1d\",start=start_date,end=end_date+timedelta(days=1), auto_adjust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "human-sector",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_returns = cp.ElementwiseKernel(\n",
    "   'float32 x, float32 y',\n",
    "   'float32 z',\n",
    "   'z = (x - y) / y',\n",
    "   'calc_returns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-suicide",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "adequate-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = cp.ndarray.get(calc_returns(cp.array(benchData['Close'],dtype=np.float32),cp.array(benchData['Close'].shift(+1),dtype=np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-chicago",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-cyprus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "large-nurse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 66.,   8.,   5.,   2.,   2.,   0.,   2.,   1.,   2.,   0.,   1.,\n",
       "           0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   1.,\n",
       "           0.,   0.,   0.,   0.,   2.,   0.,   0.,   0.,   1.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   2.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           1.],\n",
       "        [101.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "           0.]]),\n",
       " array([-1.19840555e-01,  1.72135785e+00,  3.56255626e+00,  5.40375466e+00,\n",
       "         7.24495307e+00,  9.08615147e+00,  1.09273499e+01,  1.27685483e+01,\n",
       "         1.46097467e+01,  1.64509451e+01,  1.82921435e+01,  2.01333419e+01,\n",
       "         2.19745403e+01,  2.38157387e+01,  2.56569371e+01,  2.74981355e+01,\n",
       "         2.93393339e+01,  3.11805323e+01,  3.30217307e+01,  3.48629292e+01,\n",
       "         3.67041276e+01,  3.85453260e+01,  4.03865244e+01,  4.22277228e+01,\n",
       "         4.40689212e+01,  4.59101196e+01,  4.77513180e+01,  4.95925164e+01,\n",
       "         5.14337148e+01,  5.32749132e+01,  5.51161116e+01,  5.69573100e+01,\n",
       "         5.87985084e+01,  6.06397068e+01,  6.24809052e+01,  6.43221036e+01,\n",
       "         6.61633020e+01,  6.80045005e+01,  6.98456989e+01,  7.16868973e+01,\n",
       "         7.35280957e+01,  7.53692941e+01,  7.72104925e+01,  7.90516909e+01,\n",
       "         8.08928893e+01,  8.27340877e+01,  8.45752861e+01,  8.64164845e+01,\n",
       "         8.82576829e+01,  9.00988813e+01,  9.19400797e+01,  9.37812781e+01,\n",
       "         9.56224765e+01,  9.74636749e+01,  9.93048733e+01,  1.01146072e+02,\n",
       "         1.02987270e+02,  1.04828469e+02,  1.06669667e+02,  1.08510865e+02,\n",
       "         1.10352064e+02,  1.12193262e+02,  1.14034461e+02,  1.15875659e+02,\n",
       "         1.17716857e+02,  1.19558056e+02,  1.21399254e+02,  1.23240453e+02,\n",
       "         1.25081651e+02,  1.26922849e+02,  1.28764048e+02,  1.30605246e+02,\n",
       "         1.32446445e+02,  1.34287643e+02,  1.36128841e+02,  1.37970040e+02,\n",
       "         1.39811238e+02,  1.41652437e+02,  1.43493635e+02,  1.45334833e+02,\n",
       "         1.47176032e+02,  1.49017230e+02,  1.50858429e+02,  1.52699627e+02,\n",
       "         1.54540826e+02,  1.56382024e+02,  1.58223222e+02,  1.60064421e+02,\n",
       "         1.61905619e+02,  1.63746818e+02,  1.65588016e+02,  1.67429214e+02,\n",
       "         1.69270413e+02,  1.71111611e+02,  1.72952810e+02,  1.74794008e+02,\n",
       "         1.76635206e+02,  1.78476405e+02,  1.80317603e+02,  1.82158802e+02,\n",
       "         1.84000000e+02]),\n",
       " <a list of 2 BarContainer objects>)"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "b = 100\n",
    "plt.hist(numba_gpu_histogram(returns,b), bins=b)  # arguments are passed to np.histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-trial",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-accommodation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-philip",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
